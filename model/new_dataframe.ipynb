{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings to allow all columns in dataframe to display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "np.random.seed(2)\n",
    "\n",
    "# Notebook display options\n",
    "desired_width = 320\n",
    "pd.set_option('display.width', desired_width)\n",
    "np.set_printoptions(linewidth=desired_width)\n",
    "pd.set_option('display.max_columns',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** The raw data has been successfully downloaded.\n",
      "** The raw data has been successfully cleaned.\n",
      "** Feature Engineering has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "# Import custom functions\n",
    "import api\n",
    "import data_cleaning as dc\n",
    "import feature_engineering as fe\n",
    "import train as tr\n",
    "\n",
    "# Importing the most recent data\n",
    "url = 'https://moneypuck.com/moneypuck/playerData/careers/gameByGame/all_teams.csv'\n",
    "rawData = api.api_call(url)\n",
    "print(\"** The raw data has been successfully downloaded.\")\n",
    "\n",
    "# Cleaning the rawData\n",
    "cleanData = dc.clean(rawData)\n",
    "print(\"** The raw data has been successfully cleaned.\")\n",
    "\n",
    "# Feature Engineering using the cleanData\n",
    "df = fe.fengine(cleanData)\n",
    "print(\"** Feature Engineering has been successfully completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playerTeam</th>\n",
       "      <th>opposingTeam</th>\n",
       "      <th>Shootout Game</th>\n",
       "      <th>OT Game</th>\n",
       "      <th>Win</th>\n",
       "      <th>Loss</th>\n",
       "      <th>home_or_away</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>xGoalsPercentage</th>\n",
       "      <th>corsiPercentage</th>\n",
       "      <th>fenwickPercentage</th>\n",
       "      <th>iceTime</th>\n",
       "      <th>xOnGoalFor</th>\n",
       "      <th>xGoalsFor</th>\n",
       "      <th>xReboundsFor</th>\n",
       "      <th>xFreezeFor</th>\n",
       "      <th>xPlayStoppedFor</th>\n",
       "      <th>xPlayContinuedInZoneFor</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor</th>\n",
       "      <th>flurryAdjustedxGoalsFor</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>shotsOnGoalFor</th>\n",
       "      <th>missedShotsFor</th>\n",
       "      <th>blockedShotAttemptsFor</th>\n",
       "      <th>shotAttemptsFor</th>\n",
       "      <th>goalsFor</th>\n",
       "      <th>reboundsFor</th>\n",
       "      <th>reboundGoalsFor</th>\n",
       "      <th>freezeFor</th>\n",
       "      <th>playStoppedFor</th>\n",
       "      <th>playContinuedInZoneFor</th>\n",
       "      <th>playContinuedOutsideZoneFor</th>\n",
       "      <th>savedShotsOnGoalFor</th>\n",
       "      <th>savedUnblockedShotAttemptsFor</th>\n",
       "      <th>penaltiesFor</th>\n",
       "      <th>penalityMinutesFor</th>\n",
       "      <th>faceOffsWonFor</th>\n",
       "      <th>hitsFor</th>\n",
       "      <th>takeawaysFor</th>\n",
       "      <th>giveawaysFor</th>\n",
       "      <th>lowDangerShotsFor</th>\n",
       "      <th>mediumDangerShotsFor</th>\n",
       "      <th>highDangerShotsFor</th>\n",
       "      <th>lowDangerxGoalsFor</th>\n",
       "      <th>mediumDangerxGoalsFor</th>\n",
       "      <th>highDangerxGoalsFor</th>\n",
       "      <th>lowDangerGoalsFor</th>\n",
       "      <th>mediumDangerGoalsFor</th>\n",
       "      <th>highDangerGoalsFor</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor</th>\n",
       "      <th>unblockedShotAttemptsFor</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor</th>\n",
       "      <th>dZoneGiveawaysFor</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor</th>\n",
       "      <th>reboundxGoalsFor</th>\n",
       "      <th>totalShotCreditFor</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor</th>\n",
       "      <th>xOnGoalAgainst</th>\n",
       "      <th>xGoalsAgainst</th>\n",
       "      <th>xReboundsAgainst</th>\n",
       "      <th>xFreezeAgainst</th>\n",
       "      <th>xPlayStoppedAgainst</th>\n",
       "      <th>xPlayContinuedInZoneAgainst</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>shotsOnGoalAgainst</th>\n",
       "      <th>missedShotsAgainst</th>\n",
       "      <th>blockedShotAttemptsAgainst</th>\n",
       "      <th>shotAttemptsAgainst</th>\n",
       "      <th>goalsAgainst</th>\n",
       "      <th>reboundsAgainst</th>\n",
       "      <th>reboundGoalsAgainst</th>\n",
       "      <th>freezeAgainst</th>\n",
       "      <th>playStoppedAgainst</th>\n",
       "      <th>playContinuedInZoneAgainst</th>\n",
       "      <th>playContinuedOutsideZoneAgainst</th>\n",
       "      <th>savedShotsOnGoalAgainst</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>penaltiesAgainst</th>\n",
       "      <th>penalityMinutesAgainst</th>\n",
       "      <th>faceOffsWonAgainst</th>\n",
       "      <th>hitsAgainst</th>\n",
       "      <th>takeawaysAgainst</th>\n",
       "      <th>giveawaysAgainst</th>\n",
       "      <th>lowDangerShotsAgainst</th>\n",
       "      <th>mediumDangerShotsAgainst</th>\n",
       "      <th>highDangerShotsAgainst</th>\n",
       "      <th>lowDangerxGoalsAgainst</th>\n",
       "      <th>mediumDangerxGoalsAgainst</th>\n",
       "      <th>highDangerxGoalsAgainst</th>\n",
       "      <th>lowDangerGoalsAgainst</th>\n",
       "      <th>mediumDangerGoalsAgainst</th>\n",
       "      <th>highDangerGoalsAgainst</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst</th>\n",
       "      <th>unblockedShotAttemptsAgainst</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>dZoneGiveawaysAgainst</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst</th>\n",
       "      <th>reboundxGoalsAgainst</th>\n",
       "      <th>totalShotCreditAgainst</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>playoffGame</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>home_or_away#</th>\n",
       "      <th>team#</th>\n",
       "      <th>opposingTeam#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3931</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020006</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NSH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3936</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020017</td>\n",
       "      <td>NYR</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>38.416</td>\n",
       "      <td>3.506</td>\n",
       "      <td>2.534</td>\n",
       "      <td>8.314</td>\n",
       "      <td>1.252</td>\n",
       "      <td>23.311</td>\n",
       "      <td>16.083</td>\n",
       "      <td>3.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>3.080</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1.506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.264</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1.232</td>\n",
       "      <td>1.232</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.879</td>\n",
       "      <td>2.828</td>\n",
       "      <td>31.020</td>\n",
       "      <td>3.224</td>\n",
       "      <td>2.194</td>\n",
       "      <td>6.727</td>\n",
       "      <td>0.995</td>\n",
       "      <td>18.767</td>\n",
       "      <td>13.093</td>\n",
       "      <td>3.201</td>\n",
       "      <td>3.222</td>\n",
       "      <td>3.199</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.842</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.726</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.707</td>\n",
       "      <td>3.706</td>\n",
       "      <td>3.677</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3941</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020029</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4291</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.495</td>\n",
       "      <td>2.940</td>\n",
       "      <td>2.036</td>\n",
       "      <td>5.373</td>\n",
       "      <td>0.783</td>\n",
       "      <td>12.523</td>\n",
       "      <td>11.345</td>\n",
       "      <td>2.877</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.014</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.795</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.831</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.163</td>\n",
       "      <td>1.163</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.389</td>\n",
       "      <td>2.358</td>\n",
       "      <td>42.802</td>\n",
       "      <td>3.911</td>\n",
       "      <td>2.944</td>\n",
       "      <td>10.152</td>\n",
       "      <td>1.470</td>\n",
       "      <td>24.936</td>\n",
       "      <td>17.588</td>\n",
       "      <td>3.715</td>\n",
       "      <td>3.789</td>\n",
       "      <td>3.596</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.711</td>\n",
       "      <td>1.472</td>\n",
       "      <td>0.728</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.500</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.215</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.915</td>\n",
       "      <td>3.628</td>\n",
       "      <td>3.507</td>\n",
       "      <td>3.378</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3951</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020057</td>\n",
       "      <td>NYR</td>\n",
       "      <td>EDM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3966</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020115</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CGY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  season name      gameId playerTeam opposingTeam  Shootout Game  OT Game  Win  Loss home_or_away   gameDate    position situation  xGoalsPercentage  corsiPercentage  fenwickPercentage  iceTime  xOnGoalFor  xGoalsFor  xReboundsFor  xFreezeFor  xPlayStoppedFor  xPlayContinuedInZoneFor  \\\n",
       "3931  NYR    2018  NYR  2018020006        NYR          NSH              0        0    0     1         HOME 2018-10-04  Team Level       all            0.6160           0.4874             0.5341   3600.0      34.472      2.984         2.224       7.267            1.042                   18.851   \n",
       "3936  NYR    2018  NYR  2018020017        NYR          BUF              0        0    0     1         AWAY 2018-10-06  Team Level       all            0.5210           0.5397             0.5500   3600.0      38.416      3.506         2.534       8.314            1.252                   23.311   \n",
       "3941  NYR    2018  NYR  2018020029        NYR          CAR              0        0    0     1         AWAY 2018-10-07  Team Level       all            0.4291           0.4080             0.3646   3600.0      25.495      2.940         2.036       5.373            0.783                   12.523   \n",
       "3951  NYR    2018  NYR  2018020057        NYR          EDM              0        0    0     1         HOME 2018-10-13  Team Level       all            0.4856           0.4811             0.4805   3600.0      25.878      2.211         1.592       6.131            0.881                   14.904   \n",
       "3966  NYR    2018  NYR  2018020115        NYR          CGY              0        0    0     1         HOME 2018-10-21  Team Level       all            0.6969           0.6016             0.6196   3600.0      40.474      4.494         2.873       8.911            1.356                   21.909   \n",
       "\n",
       "      xPlayContinuedOutsideZoneFor  flurryAdjustedxGoalsFor  scoreVenueAdjustedxGoalsFor  flurryScoreVenueAdjustedxGoalsFor  shotsOnGoalFor  missedShotsFor  blockedShotAttemptsFor  shotAttemptsFor  goalsFor  reboundsFor  reboundGoalsFor  freezeFor  playStoppedFor  playContinuedInZoneFor  playContinuedOutsideZoneFor  \\\n",
       "3931                        14.633                    2.948                        2.852                              2.818            36.0            11.0                    11.0             58.0       2.0          2.0              1.0        5.0             1.0                    22.0                         15.0   \n",
       "3936                        16.083                    3.082                        3.505                              3.080            44.0            11.0                    13.0             68.0       1.0          3.0              1.0       12.0             1.0                    21.0                         17.0   \n",
       "3941                        11.345                    2.877                        3.079                              3.014            24.0            11.0                    16.0             51.0       5.0          2.0              1.0        4.0             0.0                     5.0                         19.0   \n",
       "3951                        11.281                    2.099                        2.095                              1.992            24.0            13.0                    14.0             51.0       1.0          3.0              0.0        7.0             1.0                    12.0                         13.0   \n",
       "3966                        17.457                    4.192                        4.164                              3.886            45.0            12.0                    20.0             77.0       1.0          8.0              0.0       10.0             2.0                    17.0                         19.0   \n",
       "\n",
       "      savedShotsOnGoalFor  savedUnblockedShotAttemptsFor  penaltiesFor  penalityMinutesFor  faceOffsWonFor  hitsFor  takeawaysFor  giveawaysFor  lowDangerShotsFor  mediumDangerShotsFor  highDangerShotsFor  lowDangerxGoalsFor  mediumDangerxGoalsFor  highDangerxGoalsFor  lowDangerGoalsFor  mediumDangerGoalsFor  \\\n",
       "3931                 34.0                           45.0           2.0                 4.0            29.0     24.0          10.0          10.0               33.0                  11.0                 3.0               0.785                  1.412                0.787                0.0                   0.0   \n",
       "3936                 43.0                           54.0           7.0                17.0            37.0     18.0           2.0           4.0               42.0                   9.0                 4.0               1.089                  0.911                1.506                0.0                   0.0   \n",
       "3941                 19.0                           30.0           5.0                10.0            27.0     27.0           8.0          11.0               26.0                   7.0                 2.0               0.800                  0.977                1.163                0.0                   4.0   \n",
       "3951                 23.0                           36.0           4.0                 8.0            29.0     23.0           7.0          11.0               31.0                   4.0                 2.0               0.850                  0.514                0.848                1.0                   0.0   \n",
       "3966                 44.0                           56.0           3.0                 6.0            20.0     31.0           8.0          15.0               40.0                  10.0                 7.0               1.496                  1.155                1.843                1.0                   0.0   \n",
       "\n",
       "      highDangerGoalsFor  scoreAdjustedShotsAttemptsFor  unblockedShotAttemptsFor  scoreAdjustedUnblockedShotAttemptsFor  dZoneGiveawaysFor  xGoalsFromxReboundsOfShotsFor  xGoalsFromActualReboundsOfShotsFor  reboundxGoalsFor  totalShotCreditFor  scoreAdjustedTotalShotCreditFor  scoreFlurryAdjustedTotalShotCreditFor  \\\n",
       "3931                 2.0                         55.535                      47.0                                 45.081                2.0                          0.486                               0.521             0.521               2.949                            2.819                                  2.790   \n",
       "3936                 1.0                         66.264                      55.0                                 53.994                2.0                          0.606                               1.232             1.232               2.881                            2.879                                  2.828   \n",
       "3941                 1.0                         53.795                      35.0                                 36.831                6.0                          0.465                               1.163             1.163               2.242                            2.389                                  2.358   \n",
       "3951                 0.0                         49.361                      37.0                                 35.820                6.0                          0.340                               1.047             1.047               1.504                            1.446                                  1.435   \n",
       "3966                 0.0                         70.976                      57.0                                 52.475               15.0                          0.608                               1.690             1.690               3.411                            3.164                                  3.051   \n",
       "\n",
       "      xOnGoalAgainst  xGoalsAgainst  xReboundsAgainst  xFreezeAgainst  xPlayStoppedAgainst  xPlayContinuedInZoneAgainst  xPlayContinuedOutsideZoneAgainst  flurryAdjustedxGoalsAgainst  scoreVenueAdjustedxGoalsAgainst  flurryScoreVenueAdjustedxGoalsAgainst  shotsOnGoalAgainst  missedShotsAgainst  \\\n",
       "3931          29.403          1.860             1.845           7.090                0.898                       16.864                            12.443                        1.849                            1.953                                  1.941                33.0                 8.0   \n",
       "3936          31.020          3.224             2.194           6.727                0.995                       18.767                            13.093                        3.201                            3.222                                  3.199                29.0                16.0   \n",
       "3941          42.802          3.911             2.944          10.152                1.470                       24.936                            17.588                        3.715                            3.789                                  3.596                40.0                21.0   \n",
       "3951          28.237          2.342             1.791           6.929                0.959                       16.066                            11.912                        2.254                            2.441                                  2.348                27.0                13.0   \n",
       "3966          24.688          1.955             1.510           5.731                0.786                       13.542                            11.476                        1.925                            2.164                                  2.129                26.0                 9.0   \n",
       "\n",
       "      blockedShotAttemptsAgainst  shotAttemptsAgainst  goalsAgainst  reboundsAgainst  reboundGoalsAgainst  freezeAgainst  playStoppedAgainst  playContinuedInZoneAgainst  playContinuedOutsideZoneAgainst  savedShotsOnGoalAgainst  savedUnblockedShotAttemptsAgainst  penaltiesAgainst  penalityMinutesAgainst  \\\n",
       "3931                        20.0                 61.0           3.0              0.0                  0.0            8.0                 2.0                        12.0                             16.0                     30.0                               38.0               3.0                     6.0   \n",
       "3936                        13.0                 58.0           3.0              0.0                  0.0            6.0                 1.0                        16.0                             19.0                     26.0                               42.0               5.0                    13.0   \n",
       "3941                        13.0                 74.0           8.0              6.0                  2.0            7.0                 0.0                        14.0                             26.0                     32.0                               53.0               5.0                    10.0   \n",
       "3951                        15.0                 55.0           2.0              3.0                  1.0            8.0                 2.0                         9.0                             16.0                     25.0                               38.0               2.0                     4.0   \n",
       "3966                        16.0                 51.0           4.0              0.0                  0.0            2.0                 0.0                        14.0                             15.0                     22.0                               31.0               2.0                     4.0   \n",
       "\n",
       "      faceOffsWonAgainst  hitsAgainst  takeawaysAgainst  giveawaysAgainst  lowDangerShotsAgainst  mediumDangerShotsAgainst  highDangerShotsAgainst  lowDangerxGoalsAgainst  mediumDangerxGoalsAgainst  highDangerxGoalsAgainst  lowDangerGoalsAgainst  mediumDangerGoalsAgainst  highDangerGoalsAgainst  \\\n",
       "3931                32.0         21.0              16.0               9.0                   33.0                       7.0                     1.0                   0.893                      0.736                    0.231                    2.0                       0.0                     1.0   \n",
       "3936                34.0         18.0               5.0               6.0                   33.0                       9.0                     3.0                   0.842                      1.043                    1.339                    0.0                       2.0                     1.0   \n",
       "3941                38.0         30.0              13.0              18.0                   47.0                      11.0                     3.0                   1.711                      1.472                    0.728                    3.0                       3.0                     2.0   \n",
       "3951                26.0         31.0               6.0              10.0                   33.0                       4.0                     3.0                   0.610                      0.583                    1.148                    0.0                       0.0                     2.0   \n",
       "3966                31.0         23.0               8.0               6.0                   27.0                       6.0                     2.0                   0.556                      0.768                    0.631                    1.0                       1.0                     2.0   \n",
       "\n",
       "      scoreAdjustedShotsAttemptsAgainst  unblockedShotAttemptsAgainst  scoreAdjustedUnblockedShotAttemptsAgainst  dZoneGiveawaysAgainst  xGoalsFromxReboundsOfShotsAgainst  xGoalsFromActualReboundsOfShotsAgainst  reboundxGoalsAgainst  totalShotCreditAgainst  scoreAdjustedTotalShotCreditAgainst  \\\n",
       "3931                             64.070                          41.0                                     42.797                    4.0                              0.384                                   0.000                 0.000                   2.244                                2.357   \n",
       "3936                             59.726                          45.0                                     46.105                    3.0                              0.483                                   0.000                 0.000                   3.707                                3.706   \n",
       "3941                             71.500                          61.0                                     59.215                    9.0                              0.632                                   0.915                 0.915                   3.628                                3.507   \n",
       "3951                             57.029                          40.0                                     41.294                    3.0                              0.392                                   0.942                 0.942                   1.792                                1.849   \n",
       "3966                             56.055                          35.0                                     38.101                    4.0                              0.326                                   0.000                 0.000                   2.281                                2.517   \n",
       "\n",
       "      scoreFlurryAdjustedTotalShotCreditAgainst  playoffGame  year  month  day  home_or_away#  team#  opposingTeam#  \n",
       "3931                                      2.342            0  2018     10    4              1     19             17  \n",
       "3936                                      3.677            0  2018     10    6              0     19              3  \n",
       "3941                                      3.378            0  2018     10    7              0     19              4  \n",
       "3951                                      1.842            0  2018     10   13              1     19             11  \n",
       "3966                                      2.479            0  2018     10   21              1     19              6  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Team Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playerTeam</th>\n",
       "      <th>opposingTeam</th>\n",
       "      <th>Shootout Game</th>\n",
       "      <th>OT Game</th>\n",
       "      <th>Win</th>\n",
       "      <th>Loss</th>\n",
       "      <th>home_or_away</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>xGoalsPercentage</th>\n",
       "      <th>corsiPercentage</th>\n",
       "      <th>fenwickPercentage</th>\n",
       "      <th>iceTime</th>\n",
       "      <th>xOnGoalFor</th>\n",
       "      <th>xGoalsFor</th>\n",
       "      <th>xReboundsFor</th>\n",
       "      <th>xFreezeFor</th>\n",
       "      <th>xPlayStoppedFor</th>\n",
       "      <th>xPlayContinuedInZoneFor</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor</th>\n",
       "      <th>flurryAdjustedxGoalsFor</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>shotsOnGoalFor</th>\n",
       "      <th>missedShotsFor</th>\n",
       "      <th>blockedShotAttemptsFor</th>\n",
       "      <th>shotAttemptsFor</th>\n",
       "      <th>goalsFor</th>\n",
       "      <th>reboundsFor</th>\n",
       "      <th>reboundGoalsFor</th>\n",
       "      <th>freezeFor</th>\n",
       "      <th>playStoppedFor</th>\n",
       "      <th>playContinuedInZoneFor</th>\n",
       "      <th>playContinuedOutsideZoneFor</th>\n",
       "      <th>savedShotsOnGoalFor</th>\n",
       "      <th>savedUnblockedShotAttemptsFor</th>\n",
       "      <th>penaltiesFor</th>\n",
       "      <th>penalityMinutesFor</th>\n",
       "      <th>faceOffsWonFor</th>\n",
       "      <th>hitsFor</th>\n",
       "      <th>takeawaysFor</th>\n",
       "      <th>giveawaysFor</th>\n",
       "      <th>lowDangerShotsFor</th>\n",
       "      <th>mediumDangerShotsFor</th>\n",
       "      <th>highDangerShotsFor</th>\n",
       "      <th>lowDangerxGoalsFor</th>\n",
       "      <th>mediumDangerxGoalsFor</th>\n",
       "      <th>highDangerxGoalsFor</th>\n",
       "      <th>lowDangerGoalsFor</th>\n",
       "      <th>mediumDangerGoalsFor</th>\n",
       "      <th>highDangerGoalsFor</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor</th>\n",
       "      <th>unblockedShotAttemptsFor</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor</th>\n",
       "      <th>dZoneGiveawaysFor</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor</th>\n",
       "      <th>reboundxGoalsFor</th>\n",
       "      <th>totalShotCreditFor</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor</th>\n",
       "      <th>xOnGoalAgainst</th>\n",
       "      <th>xGoalsAgainst</th>\n",
       "      <th>xReboundsAgainst</th>\n",
       "      <th>xFreezeAgainst</th>\n",
       "      <th>xPlayStoppedAgainst</th>\n",
       "      <th>xPlayContinuedInZoneAgainst</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>shotsOnGoalAgainst</th>\n",
       "      <th>missedShotsAgainst</th>\n",
       "      <th>blockedShotAttemptsAgainst</th>\n",
       "      <th>shotAttemptsAgainst</th>\n",
       "      <th>goalsAgainst</th>\n",
       "      <th>reboundsAgainst</th>\n",
       "      <th>reboundGoalsAgainst</th>\n",
       "      <th>freezeAgainst</th>\n",
       "      <th>playStoppedAgainst</th>\n",
       "      <th>playContinuedInZoneAgainst</th>\n",
       "      <th>playContinuedOutsideZoneAgainst</th>\n",
       "      <th>savedShotsOnGoalAgainst</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>penaltiesAgainst</th>\n",
       "      <th>penalityMinutesAgainst</th>\n",
       "      <th>faceOffsWonAgainst</th>\n",
       "      <th>hitsAgainst</th>\n",
       "      <th>takeawaysAgainst</th>\n",
       "      <th>giveawaysAgainst</th>\n",
       "      <th>lowDangerShotsAgainst</th>\n",
       "      <th>mediumDangerShotsAgainst</th>\n",
       "      <th>highDangerShotsAgainst</th>\n",
       "      <th>lowDangerxGoalsAgainst</th>\n",
       "      <th>mediumDangerxGoalsAgainst</th>\n",
       "      <th>highDangerxGoalsAgainst</th>\n",
       "      <th>lowDangerGoalsAgainst</th>\n",
       "      <th>mediumDangerGoalsAgainst</th>\n",
       "      <th>highDangerGoalsAgainst</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst</th>\n",
       "      <th>unblockedShotAttemptsAgainst</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>dZoneGiveawaysAgainst</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst</th>\n",
       "      <th>reboundxGoalsAgainst</th>\n",
       "      <th>totalShotCreditAgainst</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>playoffGame</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>home_or_away#</th>\n",
       "      <th>team#</th>\n",
       "      <th>opposingTeam#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3931</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020006</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NSH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3951</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020057</td>\n",
       "      <td>NYR</td>\n",
       "      <td>EDM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3966</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020115</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CGY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3971</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020122</td>\n",
       "      <td>NYR</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>22.224</td>\n",
       "      <td>2.478</td>\n",
       "      <td>1.631</td>\n",
       "      <td>5.106</td>\n",
       "      <td>0.704</td>\n",
       "      <td>12.374</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.443</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.732</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.055</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.217</td>\n",
       "      <td>2.621</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.585</td>\n",
       "      <td>33.062</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>7.885</td>\n",
       "      <td>1.071</td>\n",
       "      <td>18.013</td>\n",
       "      <td>13.885</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.625</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.795</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020208</td>\n",
       "      <td>NYR</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>23.294</td>\n",
       "      <td>2.513</td>\n",
       "      <td>1.427</td>\n",
       "      <td>5.496</td>\n",
       "      <td>0.729</td>\n",
       "      <td>13.058</td>\n",
       "      <td>10.777</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.506</td>\n",
       "      <td>2.493</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.562</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.918</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.781</td>\n",
       "      <td>38.112</td>\n",
       "      <td>2.189</td>\n",
       "      <td>3.016</td>\n",
       "      <td>8.649</td>\n",
       "      <td>1.378</td>\n",
       "      <td>24.378</td>\n",
       "      <td>15.391</td>\n",
       "      <td>2.139</td>\n",
       "      <td>2.207</td>\n",
       "      <td>2.157</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.124</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.599</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4001</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020216</td>\n",
       "      <td>NYR</td>\n",
       "      <td>MTL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>29.327</td>\n",
       "      <td>2.903</td>\n",
       "      <td>1.910</td>\n",
       "      <td>6.883</td>\n",
       "      <td>0.928</td>\n",
       "      <td>16.006</td>\n",
       "      <td>12.371</td>\n",
       "      <td>2.860</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.766</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.605</td>\n",
       "      <td>1.309</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.399</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.042</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.627</td>\n",
       "      <td>2.718</td>\n",
       "      <td>2.641</td>\n",
       "      <td>2.629</td>\n",
       "      <td>30.763</td>\n",
       "      <td>3.480</td>\n",
       "      <td>1.882</td>\n",
       "      <td>7.336</td>\n",
       "      <td>1.193</td>\n",
       "      <td>18.895</td>\n",
       "      <td>13.215</td>\n",
       "      <td>3.344</td>\n",
       "      <td>3.605</td>\n",
       "      <td>3.466</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.706</td>\n",
       "      <td>2.086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.551</td>\n",
       "      <td>46.0</td>\n",
       "      <td>48.784</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.427</td>\n",
       "      <td>3.544</td>\n",
       "      <td>3.649</td>\n",
       "      <td>3.521</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4016</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020260</td>\n",
       "      <td>NYR</td>\n",
       "      <td>VAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>23.511</td>\n",
       "      <td>2.236</td>\n",
       "      <td>1.853</td>\n",
       "      <td>4.955</td>\n",
       "      <td>0.742</td>\n",
       "      <td>12.466</td>\n",
       "      <td>9.748</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.203</td>\n",
       "      <td>2.069</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>1.204</td>\n",
       "      <td>0.483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.327</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.651</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.483</td>\n",
       "      <td>2.174</td>\n",
       "      <td>2.134</td>\n",
       "      <td>2.049</td>\n",
       "      <td>29.152</td>\n",
       "      <td>1.135</td>\n",
       "      <td>1.779</td>\n",
       "      <td>7.292</td>\n",
       "      <td>0.963</td>\n",
       "      <td>16.834</td>\n",
       "      <td>12.998</td>\n",
       "      <td>1.127</td>\n",
       "      <td>1.189</td>\n",
       "      <td>1.180</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.759</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1.486</td>\n",
       "      <td>1.554</td>\n",
       "      <td>1.543</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4026</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020296</td>\n",
       "      <td>NYR</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-17</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.322</td>\n",
       "      <td>3.144</td>\n",
       "      <td>1.736</td>\n",
       "      <td>5.254</td>\n",
       "      <td>0.715</td>\n",
       "      <td>12.991</td>\n",
       "      <td>10.160</td>\n",
       "      <td>3.123</td>\n",
       "      <td>3.127</td>\n",
       "      <td>3.105</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.309</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.349</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.220</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.523</td>\n",
       "      <td>3.501</td>\n",
       "      <td>3.475</td>\n",
       "      <td>39.945</td>\n",
       "      <td>3.268</td>\n",
       "      <td>2.609</td>\n",
       "      <td>8.747</td>\n",
       "      <td>1.223</td>\n",
       "      <td>24.031</td>\n",
       "      <td>18.121</td>\n",
       "      <td>3.185</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.199</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.243</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.214</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.310</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.082</td>\n",
       "      <td>3.814</td>\n",
       "      <td>3.832</td>\n",
       "      <td>3.732</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4031</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020309</td>\n",
       "      <td>NYR</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>19.763</td>\n",
       "      <td>1.623</td>\n",
       "      <td>1.308</td>\n",
       "      <td>4.682</td>\n",
       "      <td>0.672</td>\n",
       "      <td>11.700</td>\n",
       "      <td>9.015</td>\n",
       "      <td>1.607</td>\n",
       "      <td>1.583</td>\n",
       "      <td>1.567</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.628</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.965</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.896</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.832</td>\n",
       "      <td>19.310</td>\n",
       "      <td>1.850</td>\n",
       "      <td>1.179</td>\n",
       "      <td>4.300</td>\n",
       "      <td>0.573</td>\n",
       "      <td>10.421</td>\n",
       "      <td>8.677</td>\n",
       "      <td>1.824</td>\n",
       "      <td>1.880</td>\n",
       "      <td>1.853</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.703</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.324</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.920</td>\n",
       "      <td>1.944</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4036</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020320</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NYI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5595</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.166</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.889</td>\n",
       "      <td>5.454</td>\n",
       "      <td>0.830</td>\n",
       "      <td>13.478</td>\n",
       "      <td>10.006</td>\n",
       "      <td>2.243</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.283</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.786</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.134</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.234</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.251</td>\n",
       "      <td>2.519</td>\n",
       "      <td>2.566</td>\n",
       "      <td>2.491</td>\n",
       "      <td>31.569</td>\n",
       "      <td>1.844</td>\n",
       "      <td>1.976</td>\n",
       "      <td>7.388</td>\n",
       "      <td>1.014</td>\n",
       "      <td>19.273</td>\n",
       "      <td>14.505</td>\n",
       "      <td>1.805</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.754</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.312</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.252</td>\n",
       "      <td>2.189</td>\n",
       "      <td>2.144</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  season name      gameId playerTeam opposingTeam  Shootout Game  OT Game  Win  Loss home_or_away   gameDate    position situation  xGoalsPercentage  corsiPercentage  fenwickPercentage  iceTime  xOnGoalFor  xGoalsFor  xReboundsFor  xFreezeFor  xPlayStoppedFor  xPlayContinuedInZoneFor  \\\n",
       "3931  NYR    2018  NYR  2018020006        NYR          NSH              0        0    0     1         HOME 2018-10-04  Team Level       all            0.6160           0.4874             0.5341   3600.0      34.472      2.984         2.224       7.267            1.042                   18.851   \n",
       "3951  NYR    2018  NYR  2018020057        NYR          EDM              0        0    0     1         HOME 2018-10-13  Team Level       all            0.4856           0.4811             0.4805   3600.0      25.878      2.211         1.592       6.131            0.881                   14.904   \n",
       "3966  NYR    2018  NYR  2018020115        NYR          CGY              0        0    0     1         HOME 2018-10-21  Team Level       all            0.6969           0.6016             0.6196   3600.0      40.474      4.494         2.873       8.911            1.356                   21.909   \n",
       "3971  NYR    2018  NYR  2018020122        NYR          FLA              0        0    1     0         HOME 2018-10-23  Team Level       all            0.4654           0.4286             0.4026   3600.0      22.224      2.478         1.631       5.106            0.704                   12.374   \n",
       "3996  NYR    2018  NYR  2018020208        NYR          BUF              0        0    1     0         HOME 2018-11-04  Team Level       all            0.5345           0.3739             0.3820   3600.0      23.294      2.513         1.427       5.496            0.729                   13.058   \n",
       "4001  NYR    2018  NYR  2018020216        NYR          MTL              0        0    1     0         HOME 2018-11-06  Team Level       all            0.4548           0.4872             0.4713   3600.0      29.327      2.903         1.910       6.883            0.928                   16.006   \n",
       "4016  NYR    2018  NYR  2018020260        NYR          VAN              0        0    1     0         HOME 2018-11-12  Team Level       all            0.6633           0.4510             0.4384   3600.0      23.511      2.236         1.853       4.955            0.742                   12.466   \n",
       "4026  NYR    2018  NYR  2018020296        NYR          FLA              0        0    1     0         HOME 2018-11-17  Team Level       all            0.4903           0.3730             0.3696   3600.0      25.322      3.144         1.736       5.254            0.715                   12.991   \n",
       "4031  NYR    2018  NYR  2018020309        NYR          DAL              0        0    1     0         HOME 2018-11-19  Team Level       all            0.4673           0.4706             0.5179   3600.0      19.763      1.623         1.308       4.682            0.672                   11.700   \n",
       "4036  NYR    2018  NYR  2018020320        NYR          NYI              0        0    1     0         HOME 2018-11-21  Team Level       all            0.5595           0.4215             0.4250   3600.0      25.166      2.342         1.889       5.454            0.830                   13.478   \n",
       "\n",
       "      xPlayContinuedOutsideZoneFor  flurryAdjustedxGoalsFor  scoreVenueAdjustedxGoalsFor  flurryScoreVenueAdjustedxGoalsFor  shotsOnGoalFor  missedShotsFor  blockedShotAttemptsFor  shotAttemptsFor  goalsFor  reboundsFor  reboundGoalsFor  freezeFor  playStoppedFor  playContinuedInZoneFor  playContinuedOutsideZoneFor  \\\n",
       "3931                        14.633                    2.948                        2.852                              2.818            36.0            11.0                    11.0             58.0       2.0          2.0              1.0        5.0             1.0                    22.0                         15.0   \n",
       "3951                        11.281                    2.099                        2.095                              1.992            24.0            13.0                    14.0             51.0       1.0          3.0              0.0        7.0             1.0                    12.0                         13.0   \n",
       "3966                        17.457                    4.192                        4.164                              3.886            45.0            12.0                    20.0             77.0       1.0          8.0              0.0       10.0             2.0                    17.0                         19.0   \n",
       "3971                         8.706                    2.443                        2.474                              2.439            22.0             9.0                    17.0             48.0       5.0          3.0              0.0        6.0             0.0                     8.0                          9.0   \n",
       "3996                        10.777                    2.500                        2.506                              2.493            22.0            12.0                     9.0             43.0       3.0          0.0              0.0        7.0             0.0                    12.0                         12.0   \n",
       "4001                        12.371                    2.860                        2.805                              2.766            32.0             9.0                    16.0             57.0       5.0          2.0              1.0        6.0             0.0                    10.0                         18.0   \n",
       "4016                         9.748                    2.102                        2.203                              2.069            27.0             5.0                    14.0             46.0       2.0          2.0              1.0        5.0             2.0                     9.0                         12.0   \n",
       "4026                        10.160                    3.123                        3.127                              3.105            24.0            10.0                    13.0             47.0       4.0          0.0              0.0        7.0             1.0                     8.0                         14.0   \n",
       "4031                         9.015                    1.607                        1.583                              1.567            23.0             6.0                    11.0             40.0       2.0          0.0              0.0        3.0             0.0                    10.0                         14.0   \n",
       "4036                        10.006                    2.243                        2.382                              2.283            27.0             7.0                    17.0             51.0       5.0          1.0              0.0        0.0             1.0                    11.0                         16.0   \n",
       "\n",
       "      savedShotsOnGoalFor  savedUnblockedShotAttemptsFor  penaltiesFor  penalityMinutesFor  faceOffsWonFor  hitsFor  takeawaysFor  giveawaysFor  lowDangerShotsFor  mediumDangerShotsFor  highDangerShotsFor  lowDangerxGoalsFor  mediumDangerxGoalsFor  highDangerxGoalsFor  lowDangerGoalsFor  mediumDangerGoalsFor  \\\n",
       "3931                 34.0                           45.0           2.0                 4.0            29.0     24.0          10.0          10.0               33.0                  11.0                 3.0               0.785                  1.412                0.787                0.0                   0.0   \n",
       "3951                 23.0                           36.0           4.0                 8.0            29.0     23.0           7.0          11.0               31.0                   4.0                 2.0               0.850                  0.514                0.848                1.0                   0.0   \n",
       "3966                 44.0                           56.0           3.0                 6.0            20.0     31.0           8.0          15.0               40.0                  10.0                 7.0               1.496                  1.155                1.843                1.0                   0.0   \n",
       "3971                 17.0                           26.0           4.0                11.0            31.0     28.0           9.0          15.0               23.0                   7.0                 1.0               0.774                  0.796                0.908                4.0                   0.0   \n",
       "3996                 19.0                           31.0           4.0                 8.0            28.0     24.0          12.0          20.0               27.0                   4.0                 3.0               0.652                  0.547                1.315                2.0                   0.0   \n",
       "4001                 27.0                           36.0           9.0                18.0            35.0     14.0          13.0          14.0               31.0                   6.0                 4.0               0.988                  0.605                1.309                2.0                   1.0   \n",
       "4016                 25.0                           30.0           5.0                13.0            30.0     23.0          12.0          22.0               20.0                  10.0                 2.0               0.549                  1.204                0.483                1.0                   0.0   \n",
       "4026                 20.0                           30.0           4.0                 8.0            20.0     30.0          10.0          20.0               20.0                  10.0                 4.0               0.647                  1.188                1.309                3.0                   0.0   \n",
       "4031                 21.0                           27.0           4.0                 8.0            24.0     25.0          11.0          18.0               21.0                   7.0                 1.0               0.511                  0.900                0.212                2.0                   0.0   \n",
       "4036                 22.0                           29.0           3.0                 9.0            26.0     24.0          10.0          15.0               23.0                   9.0                 2.0               0.786                  1.055                0.501                3.0                   1.0   \n",
       "\n",
       "      highDangerGoalsFor  scoreAdjustedShotsAttemptsFor  unblockedShotAttemptsFor  scoreAdjustedUnblockedShotAttemptsFor  dZoneGiveawaysFor  xGoalsFromxReboundsOfShotsFor  xGoalsFromActualReboundsOfShotsFor  reboundxGoalsFor  totalShotCreditFor  scoreAdjustedTotalShotCreditFor  scoreFlurryAdjustedTotalShotCreditFor  \\\n",
       "3931                 2.0                         55.535                      47.0                                 45.081                2.0                          0.486                               0.521             0.521               2.949                            2.819                                  2.790   \n",
       "3951                 0.0                         49.361                      37.0                                 35.820                6.0                          0.340                               1.047             1.047               1.504                            1.446                                  1.435   \n",
       "3966                 0.0                         70.976                      57.0                                 52.475               15.0                          0.608                               1.690             1.690               3.411                            3.164                                  3.051   \n",
       "3971                 1.0                         48.732                      31.0                                 31.055                9.0                          0.359                               0.217             0.217               2.621                            2.614                                  2.585   \n",
       "3996                 1.0                         44.562                      34.0                                 34.918               18.0                          0.292                               0.000             0.000               2.805                            2.797                                  2.781   \n",
       "4001                 2.0                         54.399                      41.0                                 39.042                6.0                          0.442                               0.627             0.627               2.718                            2.641                                  2.629   \n",
       "4016                 1.0                         45.327                      32.0                                 31.651               14.0                          0.420                               0.483             0.483               2.174                            2.134                                  2.049   \n",
       "4026                 1.0                         47.349                      34.0                                 34.220               11.0                          0.378                               0.000             0.000               3.523                            3.501                                  3.475   \n",
       "4031                 0.0                         39.628                      29.0                                 28.965               10.0                          0.273                               0.000             0.000               1.896                            1.849                                  1.832   \n",
       "4036                 1.0                         55.134                      34.0                                 35.234                8.0                          0.428                               0.251             0.251               2.519                            2.566                                  2.491   \n",
       "\n",
       "      xOnGoalAgainst  xGoalsAgainst  xReboundsAgainst  xFreezeAgainst  xPlayStoppedAgainst  xPlayContinuedInZoneAgainst  xPlayContinuedOutsideZoneAgainst  flurryAdjustedxGoalsAgainst  scoreVenueAdjustedxGoalsAgainst  flurryScoreVenueAdjustedxGoalsAgainst  shotsOnGoalAgainst  missedShotsAgainst  \\\n",
       "3931          29.403          1.860             1.845           7.090                0.898                       16.864                            12.443                        1.849                            1.953                                  1.941                33.0                 8.0   \n",
       "3951          28.237          2.342             1.791           6.929                0.959                       16.066                            11.912                        2.254                            2.441                                  2.348                27.0                13.0   \n",
       "3966          24.688          1.955             1.510           5.731                0.786                       13.542                            11.476                        1.925                            2.164                                  2.129                26.0                 9.0   \n",
       "3971          33.062          2.847             2.299           7.885                1.071                       18.013                            13.885                        2.609                            2.916                                  2.667                38.0                 8.0   \n",
       "3996          38.112          2.189             3.016           8.649                1.378                       24.378                            15.391                        2.139                            2.207                                  2.157                40.0                15.0   \n",
       "4001          30.763          3.480             1.882           7.336                1.193                       18.895                            13.215                        3.344                            3.605                                  3.466                34.0                12.0   \n",
       "4016          29.152          1.135             1.779           7.292                0.963                       16.834                            12.998                        1.127                            1.189                                  1.180                26.0                15.0   \n",
       "4026          39.945          3.268             2.609           8.747                1.223                       24.031                            18.121                        3.185                            3.282                                  3.199                41.0                17.0   \n",
       "4031          19.310          1.850             1.179           4.300                0.573                       10.421                             8.677                        1.824                            1.880                                  1.853                17.0                10.0   \n",
       "4036          31.569          1.844             1.976           7.388                1.014                       19.273                            14.505                        1.805                            1.792                                  1.754                29.0                17.0   \n",
       "\n",
       "      blockedShotAttemptsAgainst  shotAttemptsAgainst  goalsAgainst  reboundsAgainst  reboundGoalsAgainst  freezeAgainst  playStoppedAgainst  playContinuedInZoneAgainst  playContinuedOutsideZoneAgainst  savedShotsOnGoalAgainst  savedUnblockedShotAttemptsAgainst  penaltiesAgainst  penalityMinutesAgainst  \\\n",
       "3931                        20.0                 61.0           3.0              0.0                  0.0            8.0                 2.0                        12.0                             16.0                     30.0                               38.0               3.0                     6.0   \n",
       "3951                        15.0                 55.0           2.0              3.0                  1.0            8.0                 2.0                         9.0                             16.0                     25.0                               38.0               2.0                     4.0   \n",
       "3966                        16.0                 51.0           4.0              0.0                  0.0            2.0                 0.0                        14.0                             15.0                     22.0                               31.0               2.0                     4.0   \n",
       "3971                        18.0                 64.0           2.0              2.0                  0.0            6.0                 0.0                        17.0                             19.0                     36.0                               44.0               7.0                    17.0   \n",
       "3996                        17.0                 72.0           1.0              1.0                  0.0            6.0                 1.0                        31.0                             15.0                     39.0                               54.0               1.0                     2.0   \n",
       "4001                        14.0                 60.0           3.0              2.0                  1.0           11.0                 3.0                         6.0                             21.0                     31.0                               43.0               7.0                    14.0   \n",
       "4016                        15.0                 56.0           1.0              2.0                  0.0            5.0                 0.0                        18.0                             15.0                     25.0                               40.0               7.0                    17.0   \n",
       "4026                        21.0                 79.0           2.0              1.0                  0.0            9.0                 0.0                        22.0                             24.0                     39.0                               56.0               3.0                     6.0   \n",
       "4031                        18.0                 45.0           1.0              1.0                  0.0            4.0                 0.0                        13.0                              8.0                     16.0                               26.0               1.0                     2.0   \n",
       "4036                        24.0                 70.0           0.0              0.0                  0.0            8.0                 2.0                        19.0                             17.0                     29.0                               46.0               5.0                    13.0   \n",
       "\n",
       "      faceOffsWonAgainst  hitsAgainst  takeawaysAgainst  giveawaysAgainst  lowDangerShotsAgainst  mediumDangerShotsAgainst  highDangerShotsAgainst  lowDangerxGoalsAgainst  mediumDangerxGoalsAgainst  highDangerxGoalsAgainst  lowDangerGoalsAgainst  mediumDangerGoalsAgainst  highDangerGoalsAgainst  \\\n",
       "3931                32.0         21.0              16.0               9.0                   33.0                       7.0                     1.0                   0.893                      0.736                    0.231                    2.0                       0.0                     1.0   \n",
       "3951                26.0         31.0               6.0              10.0                   33.0                       4.0                     3.0                   0.610                      0.583                    1.148                    0.0                       0.0                     2.0   \n",
       "3966                31.0         23.0               8.0               6.0                   27.0                       6.0                     2.0                   0.556                      0.768                    0.631                    1.0                       1.0                     2.0   \n",
       "3971                27.0         28.0              10.0              11.0                   37.0                       6.0                     3.0                   0.940                      0.839                    1.068                    1.0                       0.0                     1.0   \n",
       "3996                28.0         18.0               6.0              11.0                   47.0                       5.0                     3.0                   0.880                      0.558                    0.751                    0.0                       0.0                     1.0   \n",
       "4001                30.0         17.0               4.0               5.0                   34.0                       6.0                     6.0                   0.688                      0.706                    2.086                    1.0                       1.0                     1.0   \n",
       "4016                23.0         18.0               5.0               5.0                   40.0                       1.0                     0.0                   1.029                      0.106                    0.000                    1.0                       0.0                     0.0   \n",
       "4026                37.0         21.0               4.0              19.0                   48.0                       8.0                     2.0                   1.243                      0.962                    1.063                    1.0                       0.0                     1.0   \n",
       "4031                22.0         21.0              11.0              15.0                   22.0                       2.0                     3.0                   0.624                      0.303                    0.923                    0.0                       0.0                     1.0   \n",
       "4036                27.0         38.0               6.0              18.0                   42.0                       3.0                     1.0                   1.251                      0.321                    0.272                    0.0                       0.0                     0.0   \n",
       "\n",
       "      scoreAdjustedShotsAttemptsAgainst  unblockedShotAttemptsAgainst  scoreAdjustedUnblockedShotAttemptsAgainst  dZoneGiveawaysAgainst  xGoalsFromxReboundsOfShotsAgainst  xGoalsFromActualReboundsOfShotsAgainst  reboundxGoalsAgainst  totalShotCreditAgainst  scoreAdjustedTotalShotCreditAgainst  \\\n",
       "3931                             64.070                          41.0                                     42.797                    4.0                              0.384                                   0.000                 0.000                   2.244                                2.357   \n",
       "3951                             57.029                          40.0                                     41.294                    3.0                              0.392                                   0.942                 0.942                   1.792                                1.849   \n",
       "3966                             56.055                          35.0                                     38.101                    4.0                              0.326                                   0.000                 0.000                   2.281                                2.517   \n",
       "3971                             63.625                          46.0                                     46.135                    5.0                              0.503                                   0.517                 0.517                   2.833                                2.885   \n",
       "3996                             71.124                          55.0                                     54.481                    6.0                              0.684                                   0.243                 0.243                   2.630                                2.655   \n",
       "4001                             63.551                          46.0                                     48.784                    2.0                              0.491                                   0.427                 0.427                   3.544                                3.649   \n",
       "4016                             57.759                          41.0                                     42.294                    2.0                              0.396                                   0.045                 0.045                   1.486                                1.554   \n",
       "4026                             78.214                          58.0                                     57.310                   12.0                              0.627                                   0.082                 0.082                   3.814                                3.832   \n",
       "4031                             45.703                          27.0                                     27.324                    9.0                              0.287                                   0.218                 0.218                   1.920                                1.944   \n",
       "4036                             63.312                          46.0                                     44.101                    5.0                              0.408                                   0.000                 0.000                   2.252                                2.189   \n",
       "\n",
       "      scoreFlurryAdjustedTotalShotCreditAgainst  playoffGame  year  month  day  home_or_away#  team#  opposingTeam#  \n",
       "3931                                      2.342            0  2018     10    4              1     19             17  \n",
       "3951                                      1.842            0  2018     10   13              1     19             11  \n",
       "3966                                      2.479            0  2018     10   21              1     19              6  \n",
       "3971                                      2.795            0  2018     10   23              1     19             12  \n",
       "3996                                      2.599            0  2018     11    4              1     19              3  \n",
       "4001                                      3.521            0  2018     11    6              1     19             15  \n",
       "4016                                      1.543            0  2018     11   12              1     19             28  \n",
       "4026                                      3.732            0  2018     11   17              1     19             12  \n",
       "4031                                      1.908            0  2018     11   19              1     19              9  \n",
       "4036                                      2.144            0  2018     11   21              1     19             18  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_mask = df.home_or_away == 'HOME'\n",
    "home_df = pd.DataFrame()\n",
    "home_df = home_df.append(df.loc[home_mask])\n",
    "home_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Away Team Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playerTeam</th>\n",
       "      <th>opposingTeam</th>\n",
       "      <th>Shootout Game</th>\n",
       "      <th>OT Game</th>\n",
       "      <th>Win</th>\n",
       "      <th>Loss</th>\n",
       "      <th>home_or_away</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>xGoalsPercentage</th>\n",
       "      <th>corsiPercentage</th>\n",
       "      <th>fenwickPercentage</th>\n",
       "      <th>iceTime</th>\n",
       "      <th>xOnGoalFor</th>\n",
       "      <th>xGoalsFor</th>\n",
       "      <th>xReboundsFor</th>\n",
       "      <th>xFreezeFor</th>\n",
       "      <th>xPlayStoppedFor</th>\n",
       "      <th>xPlayContinuedInZoneFor</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor</th>\n",
       "      <th>flurryAdjustedxGoalsFor</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor</th>\n",
       "      <th>shotsOnGoalFor</th>\n",
       "      <th>missedShotsFor</th>\n",
       "      <th>blockedShotAttemptsFor</th>\n",
       "      <th>shotAttemptsFor</th>\n",
       "      <th>goalsFor</th>\n",
       "      <th>reboundsFor</th>\n",
       "      <th>reboundGoalsFor</th>\n",
       "      <th>freezeFor</th>\n",
       "      <th>playStoppedFor</th>\n",
       "      <th>playContinuedInZoneFor</th>\n",
       "      <th>playContinuedOutsideZoneFor</th>\n",
       "      <th>savedShotsOnGoalFor</th>\n",
       "      <th>savedUnblockedShotAttemptsFor</th>\n",
       "      <th>penaltiesFor</th>\n",
       "      <th>penalityMinutesFor</th>\n",
       "      <th>faceOffsWonFor</th>\n",
       "      <th>hitsFor</th>\n",
       "      <th>takeawaysFor</th>\n",
       "      <th>giveawaysFor</th>\n",
       "      <th>lowDangerShotsFor</th>\n",
       "      <th>mediumDangerShotsFor</th>\n",
       "      <th>highDangerShotsFor</th>\n",
       "      <th>lowDangerxGoalsFor</th>\n",
       "      <th>mediumDangerxGoalsFor</th>\n",
       "      <th>highDangerxGoalsFor</th>\n",
       "      <th>lowDangerGoalsFor</th>\n",
       "      <th>mediumDangerGoalsFor</th>\n",
       "      <th>highDangerGoalsFor</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor</th>\n",
       "      <th>unblockedShotAttemptsFor</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor</th>\n",
       "      <th>dZoneGiveawaysFor</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor</th>\n",
       "      <th>reboundxGoalsFor</th>\n",
       "      <th>totalShotCreditFor</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor</th>\n",
       "      <th>xOnGoalAgainst</th>\n",
       "      <th>xGoalsAgainst</th>\n",
       "      <th>xReboundsAgainst</th>\n",
       "      <th>xFreezeAgainst</th>\n",
       "      <th>xPlayStoppedAgainst</th>\n",
       "      <th>xPlayContinuedInZoneAgainst</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst</th>\n",
       "      <th>shotsOnGoalAgainst</th>\n",
       "      <th>missedShotsAgainst</th>\n",
       "      <th>blockedShotAttemptsAgainst</th>\n",
       "      <th>shotAttemptsAgainst</th>\n",
       "      <th>goalsAgainst</th>\n",
       "      <th>reboundsAgainst</th>\n",
       "      <th>reboundGoalsAgainst</th>\n",
       "      <th>freezeAgainst</th>\n",
       "      <th>playStoppedAgainst</th>\n",
       "      <th>playContinuedInZoneAgainst</th>\n",
       "      <th>playContinuedOutsideZoneAgainst</th>\n",
       "      <th>savedShotsOnGoalAgainst</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>penaltiesAgainst</th>\n",
       "      <th>penalityMinutesAgainst</th>\n",
       "      <th>faceOffsWonAgainst</th>\n",
       "      <th>hitsAgainst</th>\n",
       "      <th>takeawaysAgainst</th>\n",
       "      <th>giveawaysAgainst</th>\n",
       "      <th>lowDangerShotsAgainst</th>\n",
       "      <th>mediumDangerShotsAgainst</th>\n",
       "      <th>highDangerShotsAgainst</th>\n",
       "      <th>lowDangerxGoalsAgainst</th>\n",
       "      <th>mediumDangerxGoalsAgainst</th>\n",
       "      <th>highDangerxGoalsAgainst</th>\n",
       "      <th>lowDangerGoalsAgainst</th>\n",
       "      <th>mediumDangerGoalsAgainst</th>\n",
       "      <th>highDangerGoalsAgainst</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst</th>\n",
       "      <th>unblockedShotAttemptsAgainst</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst</th>\n",
       "      <th>dZoneGiveawaysAgainst</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst</th>\n",
       "      <th>reboundxGoalsAgainst</th>\n",
       "      <th>totalShotCreditAgainst</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst</th>\n",
       "      <th>playoffGame</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>home_or_away#</th>\n",
       "      <th>team#</th>\n",
       "      <th>opposingTeam#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3936</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020017</td>\n",
       "      <td>NYR</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>38.416</td>\n",
       "      <td>3.506</td>\n",
       "      <td>2.534</td>\n",
       "      <td>8.314</td>\n",
       "      <td>1.252</td>\n",
       "      <td>23.311</td>\n",
       "      <td>16.083</td>\n",
       "      <td>3.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>3.080</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1.506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.264</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1.232</td>\n",
       "      <td>1.232</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.879</td>\n",
       "      <td>2.828</td>\n",
       "      <td>31.020</td>\n",
       "      <td>3.224</td>\n",
       "      <td>2.194</td>\n",
       "      <td>6.727</td>\n",
       "      <td>0.995</td>\n",
       "      <td>18.767</td>\n",
       "      <td>13.093</td>\n",
       "      <td>3.201</td>\n",
       "      <td>3.222</td>\n",
       "      <td>3.199</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.842</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.726</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.707</td>\n",
       "      <td>3.706</td>\n",
       "      <td>3.677</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3941</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020029</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4291</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.495</td>\n",
       "      <td>2.940</td>\n",
       "      <td>2.036</td>\n",
       "      <td>5.373</td>\n",
       "      <td>0.783</td>\n",
       "      <td>12.523</td>\n",
       "      <td>11.345</td>\n",
       "      <td>2.877</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.014</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.795</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.831</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.163</td>\n",
       "      <td>1.163</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.389</td>\n",
       "      <td>2.358</td>\n",
       "      <td>42.802</td>\n",
       "      <td>3.911</td>\n",
       "      <td>2.944</td>\n",
       "      <td>10.152</td>\n",
       "      <td>1.470</td>\n",
       "      <td>24.936</td>\n",
       "      <td>17.588</td>\n",
       "      <td>3.715</td>\n",
       "      <td>3.789</td>\n",
       "      <td>3.596</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.711</td>\n",
       "      <td>1.472</td>\n",
       "      <td>0.728</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.500</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.215</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.915</td>\n",
       "      <td>3.628</td>\n",
       "      <td>3.507</td>\n",
       "      <td>3.378</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3976</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020139</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>21.705</td>\n",
       "      <td>1.878</td>\n",
       "      <td>1.762</td>\n",
       "      <td>5.367</td>\n",
       "      <td>0.820</td>\n",
       "      <td>12.352</td>\n",
       "      <td>8.822</td>\n",
       "      <td>1.857</td>\n",
       "      <td>1.933</td>\n",
       "      <td>1.911</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>1.003</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.873</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>1.636</td>\n",
       "      <td>1.673</td>\n",
       "      <td>1.667</td>\n",
       "      <td>33.917</td>\n",
       "      <td>3.925</td>\n",
       "      <td>2.724</td>\n",
       "      <td>6.968</td>\n",
       "      <td>1.054</td>\n",
       "      <td>18.741</td>\n",
       "      <td>14.587</td>\n",
       "      <td>3.724</td>\n",
       "      <td>3.911</td>\n",
       "      <td>3.709</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.145</td>\n",
       "      <td>1.325</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.402</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.441</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.488</td>\n",
       "      <td>1.031</td>\n",
       "      <td>3.488</td>\n",
       "      <td>3.463</td>\n",
       "      <td>3.319</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3981</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020159</td>\n",
       "      <td>NYR</td>\n",
       "      <td>LAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-28</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.489</td>\n",
       "      <td>1.070</td>\n",
       "      <td>1.596</td>\n",
       "      <td>6.057</td>\n",
       "      <td>0.824</td>\n",
       "      <td>15.048</td>\n",
       "      <td>12.405</td>\n",
       "      <td>1.058</td>\n",
       "      <td>1.130</td>\n",
       "      <td>1.117</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.427</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.544</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.492</td>\n",
       "      <td>1.476</td>\n",
       "      <td>35.607</td>\n",
       "      <td>3.087</td>\n",
       "      <td>2.359</td>\n",
       "      <td>8.984</td>\n",
       "      <td>1.182</td>\n",
       "      <td>19.836</td>\n",
       "      <td>15.552</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.017</td>\n",
       "      <td>2.924</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.964</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.483</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.258</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>1.186</td>\n",
       "      <td>1.186</td>\n",
       "      <td>2.417</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.311</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4021</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020277</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NYI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>34.341</td>\n",
       "      <td>3.615</td>\n",
       "      <td>2.475</td>\n",
       "      <td>7.976</td>\n",
       "      <td>1.113</td>\n",
       "      <td>21.095</td>\n",
       "      <td>13.726</td>\n",
       "      <td>3.541</td>\n",
       "      <td>3.651</td>\n",
       "      <td>3.576</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.537</td>\n",
       "      <td>2.314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.793</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.616</td>\n",
       "      <td>1.239</td>\n",
       "      <td>1.239</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.034</td>\n",
       "      <td>2.960</td>\n",
       "      <td>17.063</td>\n",
       "      <td>2.176</td>\n",
       "      <td>1.191</td>\n",
       "      <td>3.472</td>\n",
       "      <td>0.603</td>\n",
       "      <td>10.660</td>\n",
       "      <td>8.897</td>\n",
       "      <td>2.152</td>\n",
       "      <td>2.162</td>\n",
       "      <td>2.139</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.964</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.151</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.805</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.220</td>\n",
       "      <td>2.210</td>\n",
       "      <td>2.184</td>\n",
       "      <td>2.171</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4041</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020332</td>\n",
       "      <td>NYR</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.4021</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>28.106</td>\n",
       "      <td>2.080</td>\n",
       "      <td>1.797</td>\n",
       "      <td>6.474</td>\n",
       "      <td>0.808</td>\n",
       "      <td>14.686</td>\n",
       "      <td>12.221</td>\n",
       "      <td>2.049</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.072</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.230</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.163</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>2.068</td>\n",
       "      <td>2.081</td>\n",
       "      <td>2.049</td>\n",
       "      <td>40.486</td>\n",
       "      <td>4.591</td>\n",
       "      <td>2.789</td>\n",
       "      <td>9.731</td>\n",
       "      <td>1.315</td>\n",
       "      <td>19.662</td>\n",
       "      <td>17.108</td>\n",
       "      <td>4.315</td>\n",
       "      <td>4.552</td>\n",
       "      <td>4.278</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.877</td>\n",
       "      <td>1.529</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.086</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.117</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.624</td>\n",
       "      <td>3.426</td>\n",
       "      <td>3.388</td>\n",
       "      <td>3.291</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4056</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020384</td>\n",
       "      <td>NYR</td>\n",
       "      <td>OTT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>27.567</td>\n",
       "      <td>1.666</td>\n",
       "      <td>1.814</td>\n",
       "      <td>6.768</td>\n",
       "      <td>0.879</td>\n",
       "      <td>15.159</td>\n",
       "      <td>11.715</td>\n",
       "      <td>1.620</td>\n",
       "      <td>1.648</td>\n",
       "      <td>1.602</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.761</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.552</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2.019</td>\n",
       "      <td>1.996</td>\n",
       "      <td>1.941</td>\n",
       "      <td>36.283</td>\n",
       "      <td>3.017</td>\n",
       "      <td>2.392</td>\n",
       "      <td>9.013</td>\n",
       "      <td>1.104</td>\n",
       "      <td>19.823</td>\n",
       "      <td>13.651</td>\n",
       "      <td>2.956</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3.010</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.570</td>\n",
       "      <td>0.454</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.260</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.132</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.486</td>\n",
       "      <td>3.033</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4061</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020398</td>\n",
       "      <td>NYR</td>\n",
       "      <td>MTL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>26.072</td>\n",
       "      <td>2.073</td>\n",
       "      <td>1.487</td>\n",
       "      <td>6.079</td>\n",
       "      <td>0.826</td>\n",
       "      <td>15.119</td>\n",
       "      <td>11.481</td>\n",
       "      <td>2.055</td>\n",
       "      <td>2.060</td>\n",
       "      <td>2.041</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.415</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.876</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.340</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.295</td>\n",
       "      <td>36.577</td>\n",
       "      <td>3.587</td>\n",
       "      <td>2.566</td>\n",
       "      <td>8.404</td>\n",
       "      <td>1.257</td>\n",
       "      <td>19.664</td>\n",
       "      <td>16.523</td>\n",
       "      <td>3.402</td>\n",
       "      <td>3.632</td>\n",
       "      <td>3.445</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.758</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.680</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>3.264</td>\n",
       "      <td>3.304</td>\n",
       "      <td>3.183</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4076</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020463</td>\n",
       "      <td>NYR</td>\n",
       "      <td>TBL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>24.701</td>\n",
       "      <td>2.688</td>\n",
       "      <td>1.557</td>\n",
       "      <td>5.853</td>\n",
       "      <td>0.814</td>\n",
       "      <td>13.505</td>\n",
       "      <td>10.583</td>\n",
       "      <td>2.483</td>\n",
       "      <td>2.772</td>\n",
       "      <td>2.555</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.553</td>\n",
       "      <td>1.346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.424</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.450</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.829</td>\n",
       "      <td>2.221</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2.223</td>\n",
       "      <td>36.837</td>\n",
       "      <td>4.774</td>\n",
       "      <td>2.547</td>\n",
       "      <td>7.724</td>\n",
       "      <td>1.195</td>\n",
       "      <td>21.936</td>\n",
       "      <td>14.824</td>\n",
       "      <td>4.552</td>\n",
       "      <td>4.673</td>\n",
       "      <td>4.453</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.176</td>\n",
       "      <td>1.615</td>\n",
       "      <td>1.983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.912</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.235</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.764</td>\n",
       "      <td>4.569</td>\n",
       "      <td>4.498</td>\n",
       "      <td>4.291</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4096</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020552</td>\n",
       "      <td>NYR</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-12-22</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>32.424</td>\n",
       "      <td>2.237</td>\n",
       "      <td>1.982</td>\n",
       "      <td>7.734</td>\n",
       "      <td>1.063</td>\n",
       "      <td>19.430</td>\n",
       "      <td>14.554</td>\n",
       "      <td>2.152</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.165</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.335</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.235</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.152</td>\n",
       "      <td>2.170</td>\n",
       "      <td>2.112</td>\n",
       "      <td>37.340</td>\n",
       "      <td>4.906</td>\n",
       "      <td>2.398</td>\n",
       "      <td>8.744</td>\n",
       "      <td>1.286</td>\n",
       "      <td>20.670</td>\n",
       "      <td>15.997</td>\n",
       "      <td>4.784</td>\n",
       "      <td>4.904</td>\n",
       "      <td>4.782</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2.767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.586</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.496</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>4.530</td>\n",
       "      <td>4.529</td>\n",
       "      <td>4.431</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  season name      gameId playerTeam opposingTeam  Shootout Game  OT Game  Win  Loss home_or_away   gameDate    position situation  xGoalsPercentage  corsiPercentage  fenwickPercentage  iceTime  xOnGoalFor  xGoalsFor  xReboundsFor  xFreezeFor  xPlayStoppedFor  xPlayContinuedInZoneFor  \\\n",
       "3936  NYR    2018  NYR  2018020017        NYR          BUF              0        0    0     1         AWAY 2018-10-06  Team Level       all            0.5210           0.5397             0.5500   3600.0      38.416      3.506         2.534       8.314            1.252                   23.311   \n",
       "3941  NYR    2018  NYR  2018020029        NYR          CAR              0        0    0     1         AWAY 2018-10-07  Team Level       all            0.4291           0.4080             0.3646   3600.0      25.495      2.940         2.036       5.373            0.783                   12.523   \n",
       "3976  NYR    2018  NYR  2018020139        NYR          CHI              0        0    0     1         AWAY 2018-10-25  Team Level       all            0.3236           0.3853             0.3924   3600.0      21.705      1.878         1.762       5.367            0.820                   12.352   \n",
       "3981  NYR    2018  NYR  2018020159        NYR          LAK              0        0    0     1         AWAY 2018-10-28  Team Level       all            0.2574           0.4215             0.4205   3600.0      25.489      1.070         1.596       6.057            0.824                   15.048   \n",
       "4021  NYR    2018  NYR  2018020277        NYR          NYI              0        0    0     1         AWAY 2018-11-15  Team Level       all            0.6242           0.6095             0.6494   3600.0      34.341      3.615         2.475       7.976            1.113                   21.095   \n",
       "4041  NYR    2018  NYR  2018020332        NYR          PHI              0        0    0     1         AWAY 2018-11-23  Team Level       all            0.3118           0.3889             0.4021   3600.0      28.106      2.080         1.797       6.474            0.808                   14.686   \n",
       "4056  NYR    2018  NYR  2018020384        NYR          OTT              0        0    0     1         AWAY 2018-11-29  Team Level       all            0.3558           0.4630             0.4368   3600.0      27.567      1.666         1.814       6.768            0.879                   15.159   \n",
       "4061  NYR    2018  NYR  2018020398        NYR          MTL              0        0    0     1         AWAY 2018-12-01  Team Level       all            0.3663           0.4609             0.4222   3600.0      26.072      2.073         1.487       6.079            0.826                   15.119   \n",
       "4076  NYR    2018  NYR  2018020463        NYR          TBL              0        0    0     1         AWAY 2018-12-10  Team Level       all            0.3602           0.4182             0.3977   3600.0      24.701      2.688         1.557       5.853            0.814                   13.505   \n",
       "4096  NYR    2018  NYR  2018020552        NYR          TOR              0        0    0     1         AWAY 2018-12-22  Team Level       all            0.3132           0.4609             0.4653   3600.0      32.424      2.237         1.982       7.734            1.063                   19.430   \n",
       "\n",
       "      xPlayContinuedOutsideZoneFor  flurryAdjustedxGoalsFor  scoreVenueAdjustedxGoalsFor  flurryScoreVenueAdjustedxGoalsFor  shotsOnGoalFor  missedShotsFor  blockedShotAttemptsFor  shotAttemptsFor  goalsFor  reboundsFor  reboundGoalsFor  freezeFor  playStoppedFor  playContinuedInZoneFor  playContinuedOutsideZoneFor  \\\n",
       "3936                        16.083                    3.082                        3.505                              3.080            44.0            11.0                    13.0             68.0       1.0          3.0              1.0       12.0             1.0                    21.0                         17.0   \n",
       "3941                        11.345                    2.877                        3.079                              3.014            24.0            11.0                    16.0             51.0       5.0          2.0              1.0        4.0             0.0                     5.0                         19.0   \n",
       "3976                         8.822                    1.857                        1.933                              1.911            19.0            12.0                    11.0             42.0       1.0          3.0              1.0        3.0             0.0                    13.0                         11.0   \n",
       "3981                        12.405                    1.058                        1.130                              1.117            25.0            12.0                    14.0             51.0       3.0          0.0              0.0       10.0             1.0                    10.0                         13.0   \n",
       "4021                        13.726                    3.541                        3.651                              3.576            41.0             9.0                    14.0             64.0       5.0          4.0              1.0       10.0             2.0                    12.0                         17.0   \n",
       "4041                        12.221                    2.049                        2.104                              2.072            31.0             8.0                    10.0             49.0       0.0          1.0              0.0       10.0             1.0                    10.0                         17.0   \n",
       "4056                        11.715                    1.620                        1.648                              1.602            27.0            11.0                    12.0             50.0       0.0          1.0              0.0        4.0             1.0                    12.0                         20.0   \n",
       "4061                        11.481                    2.055                        2.060                              2.041            22.0            16.0                    15.0             53.0       2.0          0.0              0.0        3.0             2.0                    18.0                         13.0   \n",
       "4076                        10.583                    2.483                        2.772                              2.555            26.0             9.0                    11.0             46.0       3.0          3.0              1.0        4.0             3.0                     9.0                         13.0   \n",
       "4096                        14.554                    2.152                        2.251                              2.165            28.0            19.0                    12.0             59.0       3.0          1.0              1.0        5.0             1.0                    20.0                         17.0   \n",
       "\n",
       "      savedShotsOnGoalFor  savedUnblockedShotAttemptsFor  penaltiesFor  penalityMinutesFor  faceOffsWonFor  hitsFor  takeawaysFor  giveawaysFor  lowDangerShotsFor  mediumDangerShotsFor  highDangerShotsFor  lowDangerxGoalsFor  mediumDangerxGoalsFor  highDangerxGoalsFor  lowDangerGoalsFor  mediumDangerGoalsFor  \\\n",
       "3936                 43.0                           54.0           7.0                17.0            37.0     18.0           2.0           4.0               42.0                   9.0                 4.0               1.089                  0.911                1.506                0.0                   0.0   \n",
       "3941                 19.0                           30.0           5.0                10.0            27.0     27.0           8.0          11.0               26.0                   7.0                 2.0               0.800                  0.977                1.163                0.0                   4.0   \n",
       "3976                 18.0                           30.0           4.0                11.0            31.0     20.0           1.0           3.0               21.0                   9.0                 1.0               0.544                  1.003                0.330                0.0                   0.0   \n",
       "3981                 22.0                           34.0           4.0                11.0            29.0     20.0           3.0          10.0               35.0                   2.0                 0.0               0.833                  0.237                0.000                2.0                   1.0   \n",
       "4021                 36.0                           45.0           4.0                10.0            34.0     25.0           3.0          11.0               40.0                   5.0                 5.0               0.765                  0.537                2.314                1.0                   1.0   \n",
       "4041                 31.0                           39.0           2.0                 7.0            26.0     22.0           4.0           9.0               33.0                   4.0                 2.0               0.959                  0.565                0.556                0.0                   0.0   \n",
       "4056                 27.0                           38.0           1.0                 2.0            13.0     40.0           8.0          12.0               33.0                   4.0                 1.0               0.928                  0.522                0.216                0.0                   0.0   \n",
       "4061                 20.0                           36.0           3.0                 6.0            27.0     28.0           9.0          12.0               34.0                   2.0                 2.0               0.934                  0.246                0.893                1.0                   0.0   \n",
       "4076                 23.0                           32.0           7.0                17.0            28.0     29.0           4.0           4.0               25.0                   5.0                 5.0               0.789                  0.553                1.346                1.0                   0.0   \n",
       "4096                 25.0                           44.0           2.0                 4.0            19.0     27.0           6.0           9.0               40.0                   6.0                 1.0               0.982                  0.754                0.501                1.0                   1.0   \n",
       "\n",
       "      highDangerGoalsFor  scoreAdjustedShotsAttemptsFor  unblockedShotAttemptsFor  scoreAdjustedUnblockedShotAttemptsFor  dZoneGiveawaysFor  xGoalsFromxReboundsOfShotsFor  xGoalsFromActualReboundsOfShotsFor  reboundxGoalsFor  totalShotCreditFor  scoreAdjustedTotalShotCreditFor  scoreFlurryAdjustedTotalShotCreditFor  \\\n",
       "3936                 1.0                         66.264                      55.0                                 53.994                2.0                          0.606                               1.232             1.232               2.881                            2.879                                  2.828   \n",
       "3941                 1.0                         53.795                      35.0                                 36.831                6.0                          0.465                               1.163             1.163               2.242                            2.389                                  2.358   \n",
       "3976                 1.0                         41.873                      31.0                                 30.897                2.0                          0.373                               0.615             0.615               1.636                            1.673                                  1.667   \n",
       "3981                 0.0                         53.427                      37.0                                 38.544               10.0                          0.346                               0.000             0.000               1.416                            1.492                                  1.476   \n",
       "4021                 3.0                         63.793                      50.0                                 50.201                3.0                          0.616                               1.239             1.239               2.992                            3.034                                  2.960   \n",
       "4041                 0.0                         48.230                      39.0                                 38.163                5.0                          0.381                               0.328             0.328               2.068                            2.081                                  2.049   \n",
       "4056                 0.0                         46.761                      38.0                                 36.552                5.0                          0.368                               0.016             0.016               2.019                            1.996                                  1.941   \n",
       "4061                 1.0                         50.415                      38.0                                 36.876                9.0                          0.332                               0.000             0.000               2.340                            2.325                                  2.295   \n",
       "4076                 2.0                         46.424                      35.0                                 35.450                3.0                          0.362                               0.829             0.829               2.221                            2.261                                  2.223   \n",
       "4096                 1.0                         58.335                      47.0                                 46.235                6.0                          0.416                               0.501             0.501               2.152                            2.170                                  2.112   \n",
       "\n",
       "      xOnGoalAgainst  xGoalsAgainst  xReboundsAgainst  xFreezeAgainst  xPlayStoppedAgainst  xPlayContinuedInZoneAgainst  xPlayContinuedOutsideZoneAgainst  flurryAdjustedxGoalsAgainst  scoreVenueAdjustedxGoalsAgainst  flurryScoreVenueAdjustedxGoalsAgainst  shotsOnGoalAgainst  missedShotsAgainst  \\\n",
       "3936          31.020          3.224             2.194           6.727                0.995                       18.767                            13.093                        3.201                            3.222                                  3.199                29.0                16.0   \n",
       "3941          42.802          3.911             2.944          10.152                1.470                       24.936                            17.588                        3.715                            3.789                                  3.596                40.0                21.0   \n",
       "3976          33.917          3.925             2.724           6.968                1.054                       18.741                            14.587                        3.724                            3.911                                  3.709                37.0                11.0   \n",
       "3981          35.607          3.087             2.359           8.984                1.182                       19.836                            15.552                        2.993                            3.017                                  2.924                40.0                11.0   \n",
       "4021          17.063          2.176             1.191           3.472                0.603                       10.660                             8.897                        2.152                            2.162                                  2.139                24.0                 3.0   \n",
       "4041          40.486          4.591             2.789           9.731                1.315                       19.662                            17.108                        4.315                            4.552                                  4.278                46.0                12.0   \n",
       "4056          36.283          3.017             2.392           9.013                1.104                       19.823                            13.651                        2.956                            3.073                                  3.010                34.0                15.0   \n",
       "4061          36.577          3.587             2.566           8.404                1.257                       19.664                            16.523                        3.402                            3.632                                  3.445                41.0                11.0   \n",
       "4076          36.837          4.774             2.547           7.724                1.195                       21.936                            14.824                        4.552                            4.673                                  4.453                36.0                17.0   \n",
       "4096          37.340          4.906             2.398           8.744                1.286                       20.670                            15.997                        4.784                            4.904                                  4.782                36.0                18.0   \n",
       "\n",
       "      blockedShotAttemptsAgainst  shotAttemptsAgainst  goalsAgainst  reboundsAgainst  reboundGoalsAgainst  freezeAgainst  playStoppedAgainst  playContinuedInZoneAgainst  playContinuedOutsideZoneAgainst  savedShotsOnGoalAgainst  savedUnblockedShotAttemptsAgainst  penaltiesAgainst  penalityMinutesAgainst  \\\n",
       "3936                        13.0                 58.0           3.0              0.0                  0.0            6.0                 1.0                        16.0                             19.0                     26.0                               42.0               5.0                    13.0   \n",
       "3941                        13.0                 74.0           8.0              6.0                  2.0            7.0                 0.0                        14.0                             26.0                     32.0                               53.0               5.0                    10.0   \n",
       "3976                        19.0                 67.0           4.0              2.0                  1.0            4.0                 2.0                        13.0                             23.0                     33.0                               44.0               3.0                     9.0   \n",
       "3981                        19.0                 70.0           4.0              5.0                  2.0           10.0                 1.0                        11.0                             20.0                     36.0                               47.0               4.0                    11.0   \n",
       "4021                        14.0                 41.0           7.0              1.0                  1.0            5.0                 0.0                         7.0                              7.0                     17.0                               20.0               4.0                     8.0   \n",
       "4041                        19.0                 77.0           4.0              9.0                  1.0           11.0                 2.0                        13.0                             19.0                     42.0                               54.0               4.0                    11.0   \n",
       "4056                         9.0                 58.0           3.0              3.0                  0.0            5.0                 0.0                        17.0                             21.0                     31.0                               46.0               0.0                     0.0   \n",
       "4061                        10.0                 62.0           5.0              3.0                  1.0            5.0                 1.0                        14.0                             24.0                     36.0                               47.0               3.0                     6.0   \n",
       "4076                        11.0                 64.0           6.0              3.0                  0.0            3.0                 4.0                        21.0                             16.0                     30.0                               47.0               2.0                     7.0   \n",
       "4096                        15.0                 69.0           5.0              4.0                  1.0            9.0                 1.0                        17.0                             18.0                     31.0                               49.0               2.0                     4.0   \n",
       "\n",
       "      faceOffsWonAgainst  hitsAgainst  takeawaysAgainst  giveawaysAgainst  lowDangerShotsAgainst  mediumDangerShotsAgainst  highDangerShotsAgainst  lowDangerxGoalsAgainst  mediumDangerxGoalsAgainst  highDangerxGoalsAgainst  lowDangerGoalsAgainst  mediumDangerGoalsAgainst  highDangerGoalsAgainst  \\\n",
       "3936                34.0         18.0               5.0               6.0                   33.0                       9.0                     3.0                   0.842                      1.043                    1.339                    0.0                       2.0                     1.0   \n",
       "3941                38.0         30.0              13.0              18.0                   47.0                      11.0                     3.0                   1.711                      1.472                    0.728                    3.0                       3.0                     2.0   \n",
       "3976                29.0          9.0               6.0               7.0                   34.0                      11.0                     3.0                   1.145                      1.325                    1.454                    0.0                       2.0                     2.0   \n",
       "3981                32.0         24.0               2.0              15.0                   38.0                      10.0                     3.0                   0.964                      1.100                    1.023                    1.0                       1.0                     2.0   \n",
       "4021                37.0         22.0               1.0              11.0                   21.0                       4.0                     2.0                   0.809                      0.403                    0.964                    2.0                       3.0                     2.0   \n",
       "4041                37.0         26.0               8.0               5.0                   37.0                      15.0                     6.0                   1.185                      1.877                    1.529                    3.0                       1.0                     0.0   \n",
       "4056                21.0         26.0               9.0              21.0                   35.0                      12.0                     2.0                   0.993                      1.570                    0.454                    2.0                       0.0                     1.0   \n",
       "4061                31.0         36.0               6.0              12.0                   36.0                      12.0                     4.0                   1.055                      1.383                    1.149                    2.0                       2.0                     1.0   \n",
       "4076                31.0         25.0               4.0               7.0                   32.0                      16.0                     5.0                   1.176                      1.615                    1.983                    3.0                       1.0                     2.0   \n",
       "4096                32.0         13.0               9.0              14.0                   38.0                      10.0                     6.0                   0.938                      1.200                    2.767                    1.0                       1.0                     3.0   \n",
       "\n",
       "      scoreAdjustedShotsAttemptsAgainst  unblockedShotAttemptsAgainst  scoreAdjustedUnblockedShotAttemptsAgainst  dZoneGiveawaysAgainst  xGoalsFromxReboundsOfShotsAgainst  xGoalsFromActualReboundsOfShotsAgainst  reboundxGoalsAgainst  totalShotCreditAgainst  scoreAdjustedTotalShotCreditAgainst  \\\n",
       "3936                             59.726                          45.0                                     46.105                    3.0                              0.483                                   0.000                 0.000                   3.707                                3.706   \n",
       "3941                             71.500                          61.0                                     59.215                    9.0                              0.632                                   0.915                 0.915                   3.628                                3.507   \n",
       "3976                             67.402                          48.0                                     48.441                    5.0                              0.594                                   0.488                 1.031                   3.488                                3.463   \n",
       "3981                             67.483                          51.0                                     49.258                   13.0                              0.516                                   1.186                 1.186                   2.417                                2.336   \n",
       "4021                             41.151                          27.0                                     26.805                    7.0                              0.255                                   0.220                 0.220                   2.210                                2.184   \n",
       "4041                             78.086                          58.0                                     59.117                    5.0                              0.589                                   1.624                 1.624                   3.426                                3.388   \n",
       "4056                             62.260                          49.0                                     51.132                   16.0                              0.501                                   0.486                 0.486                   3.033                                3.079   \n",
       "4061                             65.758                          52.0                                     53.680                   11.0                              0.561                                   0.883                 0.883                   3.264                                3.304   \n",
       "4076                             62.912                          53.0                                     52.235                    2.0                              0.560                                   0.764                 0.764                   4.569                                4.498   \n",
       "4096                             70.586                          54.0                                     55.496                   12.0                              0.524                                   0.900                 0.900                   4.530                                4.529   \n",
       "\n",
       "      scoreFlurryAdjustedTotalShotCreditAgainst  playoffGame  year  month  day  home_or_away#  team#  opposingTeam#  \n",
       "3936                                      3.677            0  2018     10    6              0     19              3  \n",
       "3941                                      3.378            0  2018     10    7              0     19              4  \n",
       "3976                                      3.319            0  2018     10   25              0     19              7  \n",
       "3981                                      2.311            0  2018     10   28              0     19             13  \n",
       "4021                                      2.171            0  2018     11   15              0     19             18  \n",
       "4041                                      3.291            0  2018     11   23              0     19             21  \n",
       "4056                                      3.035            0  2018     11   29              0     19             20  \n",
       "4061                                      3.183            0  2018     12    1              0     19             15  \n",
       "4076                                      4.291            0  2018     12   10              0     19             26  \n",
       "4096                                      4.431            0  2018     12   22              0     19             27  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_mask = df.home_or_away == 'AWAY'\n",
    "away_df = pd.DataFrame()\n",
    "away_df = away_df.append(df.loc[away_mask])\n",
    "away_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home & Away Joined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataset together\n",
    "master = (pd.merge(home_df, away_df, on= 'gameId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_x</th>\n",
       "      <th>season_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playerTeam_x</th>\n",
       "      <th>opposingTeam_x</th>\n",
       "      <th>Shootout Game_x</th>\n",
       "      <th>OT Game_x</th>\n",
       "      <th>Win_x</th>\n",
       "      <th>Loss_x</th>\n",
       "      <th>home_or_away_x</th>\n",
       "      <th>gameDate_x</th>\n",
       "      <th>position_x</th>\n",
       "      <th>situation_x</th>\n",
       "      <th>xGoalsPercentage_x</th>\n",
       "      <th>corsiPercentage_x</th>\n",
       "      <th>fenwickPercentage_x</th>\n",
       "      <th>iceTime_x</th>\n",
       "      <th>xOnGoalFor_x</th>\n",
       "      <th>xGoalsFor_x</th>\n",
       "      <th>xReboundsFor_x</th>\n",
       "      <th>xFreezeFor_x</th>\n",
       "      <th>xPlayStoppedFor_x</th>\n",
       "      <th>xPlayContinuedInZoneFor_x</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor_x</th>\n",
       "      <th>flurryAdjustedxGoalsFor_x</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor_x</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor_x</th>\n",
       "      <th>shotsOnGoalFor_x</th>\n",
       "      <th>missedShotsFor_x</th>\n",
       "      <th>blockedShotAttemptsFor_x</th>\n",
       "      <th>shotAttemptsFor_x</th>\n",
       "      <th>goalsFor_x</th>\n",
       "      <th>reboundsFor_x</th>\n",
       "      <th>reboundGoalsFor_x</th>\n",
       "      <th>freezeFor_x</th>\n",
       "      <th>playStoppedFor_x</th>\n",
       "      <th>playContinuedInZoneFor_x</th>\n",
       "      <th>playContinuedOutsideZoneFor_x</th>\n",
       "      <th>savedShotsOnGoalFor_x</th>\n",
       "      <th>savedUnblockedShotAttemptsFor_x</th>\n",
       "      <th>penaltiesFor_x</th>\n",
       "      <th>penalityMinutesFor_x</th>\n",
       "      <th>faceOffsWonFor_x</th>\n",
       "      <th>hitsFor_x</th>\n",
       "      <th>takeawaysFor_x</th>\n",
       "      <th>giveawaysFor_x</th>\n",
       "      <th>lowDangerShotsFor_x</th>\n",
       "      <th>mediumDangerShotsFor_x</th>\n",
       "      <th>highDangerShotsFor_x</th>\n",
       "      <th>lowDangerxGoalsFor_x</th>\n",
       "      <th>mediumDangerxGoalsFor_x</th>\n",
       "      <th>highDangerxGoalsFor_x</th>\n",
       "      <th>lowDangerGoalsFor_x</th>\n",
       "      <th>mediumDangerGoalsFor_x</th>\n",
       "      <th>highDangerGoalsFor_x</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor_x</th>\n",
       "      <th>unblockedShotAttemptsFor_x</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor_x</th>\n",
       "      <th>dZoneGiveawaysFor_x</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor_x</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor_x</th>\n",
       "      <th>reboundxGoalsFor_x</th>\n",
       "      <th>totalShotCreditFor_x</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor_x</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor_x</th>\n",
       "      <th>xOnGoalAgainst_x</th>\n",
       "      <th>xGoalsAgainst_x</th>\n",
       "      <th>xReboundsAgainst_x</th>\n",
       "      <th>xFreezeAgainst_x</th>\n",
       "      <th>xPlayStoppedAgainst_x</th>\n",
       "      <th>xPlayContinuedInZoneAgainst_x</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst_x</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst_x</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst_x</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst_x</th>\n",
       "      <th>shotsOnGoalAgainst_x</th>\n",
       "      <th>missedShotsAgainst_x</th>\n",
       "      <th>blockedShotAttemptsAgainst_x</th>\n",
       "      <th>shotAttemptsAgainst_x</th>\n",
       "      <th>goalsAgainst_x</th>\n",
       "      <th>reboundsAgainst_x</th>\n",
       "      <th>reboundGoalsAgainst_x</th>\n",
       "      <th>freezeAgainst_x</th>\n",
       "      <th>playStoppedAgainst_x</th>\n",
       "      <th>playContinuedInZoneAgainst_x</th>\n",
       "      <th>playContinuedOutsideZoneAgainst_x</th>\n",
       "      <th>savedShotsOnGoalAgainst_x</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst_x</th>\n",
       "      <th>penaltiesAgainst_x</th>\n",
       "      <th>penalityMinutesAgainst_x</th>\n",
       "      <th>faceOffsWonAgainst_x</th>\n",
       "      <th>hitsAgainst_x</th>\n",
       "      <th>takeawaysAgainst_x</th>\n",
       "      <th>giveawaysAgainst_x</th>\n",
       "      <th>lowDangerShotsAgainst_x</th>\n",
       "      <th>mediumDangerShotsAgainst_x</th>\n",
       "      <th>highDangerShotsAgainst_x</th>\n",
       "      <th>lowDangerxGoalsAgainst_x</th>\n",
       "      <th>mediumDangerxGoalsAgainst_x</th>\n",
       "      <th>highDangerxGoalsAgainst_x</th>\n",
       "      <th>lowDangerGoalsAgainst_x</th>\n",
       "      <th>mediumDangerGoalsAgainst_x</th>\n",
       "      <th>highDangerGoalsAgainst_x</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst_x</th>\n",
       "      <th>unblockedShotAttemptsAgainst_x</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst_x</th>\n",
       "      <th>dZoneGiveawaysAgainst_x</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst_x</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst_x</th>\n",
       "      <th>reboundxGoalsAgainst_x</th>\n",
       "      <th>totalShotCreditAgainst_x</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst_x</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst_x</th>\n",
       "      <th>playoffGame_x</th>\n",
       "      <th>year_x</th>\n",
       "      <th>month_x</th>\n",
       "      <th>day_x</th>\n",
       "      <th>home_or_away#_x</th>\n",
       "      <th>team#_x</th>\n",
       "      <th>opposingTeam#_x</th>\n",
       "      <th>team_y</th>\n",
       "      <th>season_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>playerTeam_y</th>\n",
       "      <th>opposingTeam_y</th>\n",
       "      <th>Shootout Game_y</th>\n",
       "      <th>OT Game_y</th>\n",
       "      <th>Win_y</th>\n",
       "      <th>Loss_y</th>\n",
       "      <th>home_or_away_y</th>\n",
       "      <th>gameDate_y</th>\n",
       "      <th>position_y</th>\n",
       "      <th>situation_y</th>\n",
       "      <th>xGoalsPercentage_y</th>\n",
       "      <th>corsiPercentage_y</th>\n",
       "      <th>fenwickPercentage_y</th>\n",
       "      <th>iceTime_y</th>\n",
       "      <th>xOnGoalFor_y</th>\n",
       "      <th>xGoalsFor_y</th>\n",
       "      <th>xReboundsFor_y</th>\n",
       "      <th>xFreezeFor_y</th>\n",
       "      <th>xPlayStoppedFor_y</th>\n",
       "      <th>xPlayContinuedInZoneFor_y</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor_y</th>\n",
       "      <th>flurryAdjustedxGoalsFor_y</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor_y</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor_y</th>\n",
       "      <th>shotsOnGoalFor_y</th>\n",
       "      <th>missedShotsFor_y</th>\n",
       "      <th>blockedShotAttemptsFor_y</th>\n",
       "      <th>shotAttemptsFor_y</th>\n",
       "      <th>goalsFor_y</th>\n",
       "      <th>reboundsFor_y</th>\n",
       "      <th>reboundGoalsFor_y</th>\n",
       "      <th>freezeFor_y</th>\n",
       "      <th>playStoppedFor_y</th>\n",
       "      <th>playContinuedInZoneFor_y</th>\n",
       "      <th>playContinuedOutsideZoneFor_y</th>\n",
       "      <th>savedShotsOnGoalFor_y</th>\n",
       "      <th>savedUnblockedShotAttemptsFor_y</th>\n",
       "      <th>penaltiesFor_y</th>\n",
       "      <th>penalityMinutesFor_y</th>\n",
       "      <th>faceOffsWonFor_y</th>\n",
       "      <th>hitsFor_y</th>\n",
       "      <th>takeawaysFor_y</th>\n",
       "      <th>giveawaysFor_y</th>\n",
       "      <th>lowDangerShotsFor_y</th>\n",
       "      <th>mediumDangerShotsFor_y</th>\n",
       "      <th>highDangerShotsFor_y</th>\n",
       "      <th>lowDangerxGoalsFor_y</th>\n",
       "      <th>mediumDangerxGoalsFor_y</th>\n",
       "      <th>highDangerxGoalsFor_y</th>\n",
       "      <th>lowDangerGoalsFor_y</th>\n",
       "      <th>mediumDangerGoalsFor_y</th>\n",
       "      <th>highDangerGoalsFor_y</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor_y</th>\n",
       "      <th>unblockedShotAttemptsFor_y</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor_y</th>\n",
       "      <th>dZoneGiveawaysFor_y</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor_y</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor_y</th>\n",
       "      <th>reboundxGoalsFor_y</th>\n",
       "      <th>totalShotCreditFor_y</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor_y</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor_y</th>\n",
       "      <th>xOnGoalAgainst_y</th>\n",
       "      <th>xGoalsAgainst_y</th>\n",
       "      <th>xReboundsAgainst_y</th>\n",
       "      <th>xFreezeAgainst_y</th>\n",
       "      <th>xPlayStoppedAgainst_y</th>\n",
       "      <th>xPlayContinuedInZoneAgainst_y</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst_y</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst_y</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst_y</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst_y</th>\n",
       "      <th>shotsOnGoalAgainst_y</th>\n",
       "      <th>missedShotsAgainst_y</th>\n",
       "      <th>blockedShotAttemptsAgainst_y</th>\n",
       "      <th>shotAttemptsAgainst_y</th>\n",
       "      <th>goalsAgainst_y</th>\n",
       "      <th>reboundsAgainst_y</th>\n",
       "      <th>reboundGoalsAgainst_y</th>\n",
       "      <th>freezeAgainst_y</th>\n",
       "      <th>playStoppedAgainst_y</th>\n",
       "      <th>playContinuedInZoneAgainst_y</th>\n",
       "      <th>playContinuedOutsideZoneAgainst_y</th>\n",
       "      <th>savedShotsOnGoalAgainst_y</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst_y</th>\n",
       "      <th>penaltiesAgainst_y</th>\n",
       "      <th>penalityMinutesAgainst_y</th>\n",
       "      <th>faceOffsWonAgainst_y</th>\n",
       "      <th>hitsAgainst_y</th>\n",
       "      <th>takeawaysAgainst_y</th>\n",
       "      <th>giveawaysAgainst_y</th>\n",
       "      <th>lowDangerShotsAgainst_y</th>\n",
       "      <th>mediumDangerShotsAgainst_y</th>\n",
       "      <th>highDangerShotsAgainst_y</th>\n",
       "      <th>lowDangerxGoalsAgainst_y</th>\n",
       "      <th>mediumDangerxGoalsAgainst_y</th>\n",
       "      <th>highDangerxGoalsAgainst_y</th>\n",
       "      <th>lowDangerGoalsAgainst_y</th>\n",
       "      <th>mediumDangerGoalsAgainst_y</th>\n",
       "      <th>highDangerGoalsAgainst_y</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst_y</th>\n",
       "      <th>unblockedShotAttemptsAgainst_y</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst_y</th>\n",
       "      <th>dZoneGiveawaysAgainst_y</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst_y</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst_y</th>\n",
       "      <th>reboundxGoalsAgainst_y</th>\n",
       "      <th>totalShotCreditAgainst_y</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst_y</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst_y</th>\n",
       "      <th>playoffGame_y</th>\n",
       "      <th>year_y</th>\n",
       "      <th>month_y</th>\n",
       "      <th>day_y</th>\n",
       "      <th>home_or_away#_y</th>\n",
       "      <th>team#_y</th>\n",
       "      <th>opposingTeam#_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020006</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NSH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>NSH</td>\n",
       "      <td>2018</td>\n",
       "      <td>NSH</td>\n",
       "      <td>NSH</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020057</td>\n",
       "      <td>NYR</td>\n",
       "      <td>EDM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>EDM</td>\n",
       "      <td>2018</td>\n",
       "      <td>EDM</td>\n",
       "      <td>EDM</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020115</td>\n",
       "      <td>NYR</td>\n",
       "      <td>CGY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>CGY</td>\n",
       "      <td>2018</td>\n",
       "      <td>CGY</td>\n",
       "      <td>CGY</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020122</td>\n",
       "      <td>NYR</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>22.224</td>\n",
       "      <td>2.478</td>\n",
       "      <td>1.631</td>\n",
       "      <td>5.106</td>\n",
       "      <td>0.704</td>\n",
       "      <td>12.374</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.443</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.732</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.055</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.217</td>\n",
       "      <td>2.621</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.585</td>\n",
       "      <td>33.062</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>7.885</td>\n",
       "      <td>1.071</td>\n",
       "      <td>18.013</td>\n",
       "      <td>13.885</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.625</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.795</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>FLA</td>\n",
       "      <td>2018</td>\n",
       "      <td>FLA</td>\n",
       "      <td>FLA</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5974</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>33.062</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>7.885</td>\n",
       "      <td>1.071</td>\n",
       "      <td>18.013</td>\n",
       "      <td>13.885</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.625</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.795</td>\n",
       "      <td>22.224</td>\n",
       "      <td>2.478</td>\n",
       "      <td>1.631</td>\n",
       "      <td>5.106</td>\n",
       "      <td>0.704</td>\n",
       "      <td>12.374</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.443</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.732</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.055</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.217</td>\n",
       "      <td>2.621</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.585</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020208</td>\n",
       "      <td>NYR</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>23.294</td>\n",
       "      <td>2.513</td>\n",
       "      <td>1.427</td>\n",
       "      <td>5.496</td>\n",
       "      <td>0.729</td>\n",
       "      <td>13.058</td>\n",
       "      <td>10.777</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.506</td>\n",
       "      <td>2.493</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.562</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.918</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.781</td>\n",
       "      <td>38.112</td>\n",
       "      <td>2.189</td>\n",
       "      <td>3.016</td>\n",
       "      <td>8.649</td>\n",
       "      <td>1.378</td>\n",
       "      <td>24.378</td>\n",
       "      <td>15.391</td>\n",
       "      <td>2.139</td>\n",
       "      <td>2.207</td>\n",
       "      <td>2.157</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.124</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.599</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>BUF</td>\n",
       "      <td>2018</td>\n",
       "      <td>BUF</td>\n",
       "      <td>BUF</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>38.112</td>\n",
       "      <td>2.189</td>\n",
       "      <td>3.016</td>\n",
       "      <td>8.649</td>\n",
       "      <td>1.378</td>\n",
       "      <td>24.378</td>\n",
       "      <td>15.391</td>\n",
       "      <td>2.139</td>\n",
       "      <td>2.207</td>\n",
       "      <td>2.157</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.124</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.599</td>\n",
       "      <td>23.294</td>\n",
       "      <td>2.513</td>\n",
       "      <td>1.427</td>\n",
       "      <td>5.496</td>\n",
       "      <td>0.729</td>\n",
       "      <td>13.058</td>\n",
       "      <td>10.777</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.506</td>\n",
       "      <td>2.493</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.562</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.918</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  team_x  season_x name_x      gameId playerTeam_x opposingTeam_x  Shootout Game_x  OT Game_x  Win_x  Loss_x home_or_away_x gameDate_x  position_x situation_x  xGoalsPercentage_x  corsiPercentage_x  fenwickPercentage_x  iceTime_x  xOnGoalFor_x  xGoalsFor_x  xReboundsFor_x  xFreezeFor_x  xPlayStoppedFor_x  \\\n",
       "0    NYR      2018    NYR  2018020006          NYR            NSH                0          0      0       1           HOME 2018-10-04  Team Level         all              0.6160             0.4874               0.5341     3600.0        34.472        2.984           2.224         7.267              1.042   \n",
       "1    NYR      2018    NYR  2018020057          NYR            EDM                0          0      0       1           HOME 2018-10-13  Team Level         all              0.4856             0.4811               0.4805     3600.0        25.878        2.211           1.592         6.131              0.881   \n",
       "2    NYR      2018    NYR  2018020115          NYR            CGY                0          0      0       1           HOME 2018-10-21  Team Level         all              0.6969             0.6016               0.6196     3600.0        40.474        4.494           2.873         8.911              1.356   \n",
       "3    NYR      2018    NYR  2018020122          NYR            FLA                0          0      1       0           HOME 2018-10-23  Team Level         all              0.4654             0.4286               0.4026     3600.0        22.224        2.478           1.631         5.106              0.704   \n",
       "4    NYR      2018    NYR  2018020208          NYR            BUF                0          0      1       0           HOME 2018-11-04  Team Level         all              0.5345             0.3739               0.3820     3600.0        23.294        2.513           1.427         5.496              0.729   \n",
       "\n",
       "   xPlayContinuedInZoneFor_x  xPlayContinuedOutsideZoneFor_x  flurryAdjustedxGoalsFor_x  scoreVenueAdjustedxGoalsFor_x  flurryScoreVenueAdjustedxGoalsFor_x  shotsOnGoalFor_x  missedShotsFor_x  blockedShotAttemptsFor_x  shotAttemptsFor_x  goalsFor_x  reboundsFor_x  reboundGoalsFor_x  freezeFor_x  playStoppedFor_x  \\\n",
       "0                     18.851                          14.633                      2.948                          2.852                                2.818              36.0              11.0                      11.0               58.0         2.0            2.0                1.0          5.0               1.0   \n",
       "1                     14.904                          11.281                      2.099                          2.095                                1.992              24.0              13.0                      14.0               51.0         1.0            3.0                0.0          7.0               1.0   \n",
       "2                     21.909                          17.457                      4.192                          4.164                                3.886              45.0              12.0                      20.0               77.0         1.0            8.0                0.0         10.0               2.0   \n",
       "3                     12.374                           8.706                      2.443                          2.474                                2.439              22.0               9.0                      17.0               48.0         5.0            3.0                0.0          6.0               0.0   \n",
       "4                     13.058                          10.777                      2.500                          2.506                                2.493              22.0              12.0                       9.0               43.0         3.0            0.0                0.0          7.0               0.0   \n",
       "\n",
       "   playContinuedInZoneFor_x  playContinuedOutsideZoneFor_x  savedShotsOnGoalFor_x  savedUnblockedShotAttemptsFor_x  penaltiesFor_x  penalityMinutesFor_x  faceOffsWonFor_x  hitsFor_x  takeawaysFor_x  giveawaysFor_x  lowDangerShotsFor_x  mediumDangerShotsFor_x  highDangerShotsFor_x  lowDangerxGoalsFor_x  \\\n",
       "0                      22.0                           15.0                   34.0                             45.0             2.0                   4.0              29.0       24.0            10.0            10.0                 33.0                    11.0                   3.0                 0.785   \n",
       "1                      12.0                           13.0                   23.0                             36.0             4.0                   8.0              29.0       23.0             7.0            11.0                 31.0                     4.0                   2.0                 0.850   \n",
       "2                      17.0                           19.0                   44.0                             56.0             3.0                   6.0              20.0       31.0             8.0            15.0                 40.0                    10.0                   7.0                 1.496   \n",
       "3                       8.0                            9.0                   17.0                             26.0             4.0                  11.0              31.0       28.0             9.0            15.0                 23.0                     7.0                   1.0                 0.774   \n",
       "4                      12.0                           12.0                   19.0                             31.0             4.0                   8.0              28.0       24.0            12.0            20.0                 27.0                     4.0                   3.0                 0.652   \n",
       "\n",
       "   mediumDangerxGoalsFor_x  highDangerxGoalsFor_x  lowDangerGoalsFor_x  mediumDangerGoalsFor_x  highDangerGoalsFor_x  scoreAdjustedShotsAttemptsFor_x  unblockedShotAttemptsFor_x  scoreAdjustedUnblockedShotAttemptsFor_x  dZoneGiveawaysFor_x  xGoalsFromxReboundsOfShotsFor_x  xGoalsFromActualReboundsOfShotsFor_x  \\\n",
       "0                    1.412                  0.787                  0.0                     0.0                   2.0                           55.535                        47.0                                   45.081                  2.0                            0.486                                 0.521   \n",
       "1                    0.514                  0.848                  1.0                     0.0                   0.0                           49.361                        37.0                                   35.820                  6.0                            0.340                                 1.047   \n",
       "2                    1.155                  1.843                  1.0                     0.0                   0.0                           70.976                        57.0                                   52.475                 15.0                            0.608                                 1.690   \n",
       "3                    0.796                  0.908                  4.0                     0.0                   1.0                           48.732                        31.0                                   31.055                  9.0                            0.359                                 0.217   \n",
       "4                    0.547                  1.315                  2.0                     0.0                   1.0                           44.562                        34.0                                   34.918                 18.0                            0.292                                 0.000   \n",
       "\n",
       "   reboundxGoalsFor_x  totalShotCreditFor_x  scoreAdjustedTotalShotCreditFor_x  scoreFlurryAdjustedTotalShotCreditFor_x  xOnGoalAgainst_x  xGoalsAgainst_x  xReboundsAgainst_x  xFreezeAgainst_x  xPlayStoppedAgainst_x  xPlayContinuedInZoneAgainst_x  xPlayContinuedOutsideZoneAgainst_x  flurryAdjustedxGoalsAgainst_x  \\\n",
       "0               0.521                 2.949                              2.819                                    2.790            29.403            1.860               1.845             7.090                  0.898                         16.864                              12.443                          1.849   \n",
       "1               1.047                 1.504                              1.446                                    1.435            28.237            2.342               1.791             6.929                  0.959                         16.066                              11.912                          2.254   \n",
       "2               1.690                 3.411                              3.164                                    3.051            24.688            1.955               1.510             5.731                  0.786                         13.542                              11.476                          1.925   \n",
       "3               0.217                 2.621                              2.614                                    2.585            33.062            2.847               2.299             7.885                  1.071                         18.013                              13.885                          2.609   \n",
       "4               0.000                 2.805                              2.797                                    2.781            38.112            2.189               3.016             8.649                  1.378                         24.378                              15.391                          2.139   \n",
       "\n",
       "   scoreVenueAdjustedxGoalsAgainst_x  flurryScoreVenueAdjustedxGoalsAgainst_x  shotsOnGoalAgainst_x  missedShotsAgainst_x  blockedShotAttemptsAgainst_x  shotAttemptsAgainst_x  goalsAgainst_x  reboundsAgainst_x  reboundGoalsAgainst_x  freezeAgainst_x  playStoppedAgainst_x  playContinuedInZoneAgainst_x  \\\n",
       "0                              1.953                                    1.941                  33.0                   8.0                          20.0                   61.0             3.0                0.0                    0.0              8.0                   2.0                          12.0   \n",
       "1                              2.441                                    2.348                  27.0                  13.0                          15.0                   55.0             2.0                3.0                    1.0              8.0                   2.0                           9.0   \n",
       "2                              2.164                                    2.129                  26.0                   9.0                          16.0                   51.0             4.0                0.0                    0.0              2.0                   0.0                          14.0   \n",
       "3                              2.916                                    2.667                  38.0                   8.0                          18.0                   64.0             2.0                2.0                    0.0              6.0                   0.0                          17.0   \n",
       "4                              2.207                                    2.157                  40.0                  15.0                          17.0                   72.0             1.0                1.0                    0.0              6.0                   1.0                          31.0   \n",
       "\n",
       "   playContinuedOutsideZoneAgainst_x  savedShotsOnGoalAgainst_x  savedUnblockedShotAttemptsAgainst_x  penaltiesAgainst_x  penalityMinutesAgainst_x  faceOffsWonAgainst_x  hitsAgainst_x  takeawaysAgainst_x  giveawaysAgainst_x  lowDangerShotsAgainst_x  mediumDangerShotsAgainst_x  highDangerShotsAgainst_x  \\\n",
       "0                               16.0                       30.0                                 38.0                 3.0                       6.0                  32.0           21.0                16.0                 9.0                     33.0                         7.0                       1.0   \n",
       "1                               16.0                       25.0                                 38.0                 2.0                       4.0                  26.0           31.0                 6.0                10.0                     33.0                         4.0                       3.0   \n",
       "2                               15.0                       22.0                                 31.0                 2.0                       4.0                  31.0           23.0                 8.0                 6.0                     27.0                         6.0                       2.0   \n",
       "3                               19.0                       36.0                                 44.0                 7.0                      17.0                  27.0           28.0                10.0                11.0                     37.0                         6.0                       3.0   \n",
       "4                               15.0                       39.0                                 54.0                 1.0                       2.0                  28.0           18.0                 6.0                11.0                     47.0                         5.0                       3.0   \n",
       "\n",
       "   lowDangerxGoalsAgainst_x  mediumDangerxGoalsAgainst_x  highDangerxGoalsAgainst_x  lowDangerGoalsAgainst_x  mediumDangerGoalsAgainst_x  highDangerGoalsAgainst_x  scoreAdjustedShotsAttemptsAgainst_x  unblockedShotAttemptsAgainst_x  scoreAdjustedUnblockedShotAttemptsAgainst_x  dZoneGiveawaysAgainst_x  \\\n",
       "0                     0.893                        0.736                      0.231                      2.0                         0.0                       1.0                               64.070                            41.0                                       42.797                      4.0   \n",
       "1                     0.610                        0.583                      1.148                      0.0                         0.0                       2.0                               57.029                            40.0                                       41.294                      3.0   \n",
       "2                     0.556                        0.768                      0.631                      1.0                         1.0                       2.0                               56.055                            35.0                                       38.101                      4.0   \n",
       "3                     0.940                        0.839                      1.068                      1.0                         0.0                       1.0                               63.625                            46.0                                       46.135                      5.0   \n",
       "4                     0.880                        0.558                      0.751                      0.0                         0.0                       1.0                               71.124                            55.0                                       54.481                      6.0   \n",
       "\n",
       "   xGoalsFromxReboundsOfShotsAgainst_x  xGoalsFromActualReboundsOfShotsAgainst_x  reboundxGoalsAgainst_x  totalShotCreditAgainst_x  scoreAdjustedTotalShotCreditAgainst_x  scoreFlurryAdjustedTotalShotCreditAgainst_x  playoffGame_x  year_x  month_x  day_x  home_or_away#_x  team#_x  opposingTeam#_x team_y  season_y  \\\n",
       "0                                0.384                                     0.000                   0.000                     2.244                                  2.357                                        2.342              0    2018       10      4                1       19               17    NSH      2018   \n",
       "1                                0.392                                     0.942                   0.942                     1.792                                  1.849                                        1.842              0    2018       10     13                1       19               11    EDM      2018   \n",
       "2                                0.326                                     0.000                   0.000                     2.281                                  2.517                                        2.479              0    2018       10     21                1       19                6    CGY      2018   \n",
       "3                                0.503                                     0.517                   0.517                     2.833                                  2.885                                        2.795              0    2018       10     23                1       19               12    FLA      2018   \n",
       "4                                0.684                                     0.243                   0.243                     2.630                                  2.655                                        2.599              0    2018       11      4                1       19                3    BUF      2018   \n",
       "\n",
       "  name_y playerTeam_y opposingTeam_y  Shootout Game_y  OT Game_y  Win_y  Loss_y home_or_away_y gameDate_y  position_y situation_y  xGoalsPercentage_y  corsiPercentage_y  fenwickPercentage_y  iceTime_y  xOnGoalFor_y  xGoalsFor_y  xReboundsFor_y  xFreezeFor_y  xPlayStoppedFor_y  xPlayContinuedInZoneFor_y  \\\n",
       "0    NSH          NSH            NYR                0          0      1       0           AWAY 2018-10-04  Team Level         all              0.3840             0.5126               0.4659     3600.0        29.403        1.860           1.845         7.090              0.898                     16.864   \n",
       "1    EDM          EDM            NYR                0          0      1       0           AWAY 2018-10-13  Team Level         all              0.5144             0.5189               0.5195     3600.0        28.237        2.342           1.791         6.929              0.959                     16.066   \n",
       "2    CGY          CGY            NYR                0          0      1       0           AWAY 2018-10-21  Team Level         all              0.3031             0.3984               0.3804     3600.0        24.688        1.955           1.510         5.731              0.786                     13.542   \n",
       "3    FLA          FLA            NYR                0          0      0       1           AWAY 2018-10-23  Team Level         all              0.5346             0.5714               0.5974     3600.0        33.062        2.847           2.299         7.885              1.071                     18.013   \n",
       "4    BUF          BUF            NYR                0          0      0       1           AWAY 2018-11-04  Team Level         all              0.4655             0.6261               0.6180     3600.0        38.112        2.189           3.016         8.649              1.378                     24.378   \n",
       "\n",
       "   xPlayContinuedOutsideZoneFor_y  flurryAdjustedxGoalsFor_y  scoreVenueAdjustedxGoalsFor_y  flurryScoreVenueAdjustedxGoalsFor_y  shotsOnGoalFor_y  missedShotsFor_y  blockedShotAttemptsFor_y  shotAttemptsFor_y  goalsFor_y  reboundsFor_y  reboundGoalsFor_y  freezeFor_y  playStoppedFor_y  playContinuedInZoneFor_y  \\\n",
       "0                          12.443                      1.849                          1.953                                1.941              33.0               8.0                      20.0               61.0         3.0            0.0                0.0          8.0               2.0                      12.0   \n",
       "1                          11.912                      2.254                          2.441                                2.348              27.0              13.0                      15.0               55.0         2.0            3.0                1.0          8.0               2.0                       9.0   \n",
       "2                          11.476                      1.925                          2.164                                2.129              26.0               9.0                      16.0               51.0         4.0            0.0                0.0          2.0               0.0                      14.0   \n",
       "3                          13.885                      2.609                          2.916                                2.667              38.0               8.0                      18.0               64.0         2.0            2.0                0.0          6.0               0.0                      17.0   \n",
       "4                          15.391                      2.139                          2.207                                2.157              40.0              15.0                      17.0               72.0         1.0            1.0                0.0          6.0               1.0                      31.0   \n",
       "\n",
       "   playContinuedOutsideZoneFor_y  savedShotsOnGoalFor_y  savedUnblockedShotAttemptsFor_y  penaltiesFor_y  penalityMinutesFor_y  faceOffsWonFor_y  hitsFor_y  takeawaysFor_y  giveawaysFor_y  lowDangerShotsFor_y  mediumDangerShotsFor_y  highDangerShotsFor_y  lowDangerxGoalsFor_y  mediumDangerxGoalsFor_y  \\\n",
       "0                           16.0                   30.0                             38.0             3.0                   6.0              32.0       21.0            16.0             9.0                 33.0                     7.0                   1.0                 0.893                    0.736   \n",
       "1                           16.0                   25.0                             38.0             2.0                   4.0              26.0       31.0             6.0            10.0                 33.0                     4.0                   3.0                 0.610                    0.583   \n",
       "2                           15.0                   22.0                             31.0             2.0                   4.0              31.0       23.0             8.0             6.0                 27.0                     6.0                   2.0                 0.556                    0.768   \n",
       "3                           19.0                   36.0                             44.0             7.0                  17.0              27.0       28.0            10.0            11.0                 37.0                     6.0                   3.0                 0.940                    0.839   \n",
       "4                           15.0                   39.0                             54.0             1.0                   2.0              28.0       18.0             6.0            11.0                 47.0                     5.0                   3.0                 0.880                    0.558   \n",
       "\n",
       "   highDangerxGoalsFor_y  lowDangerGoalsFor_y  mediumDangerGoalsFor_y  highDangerGoalsFor_y  scoreAdjustedShotsAttemptsFor_y  unblockedShotAttemptsFor_y  scoreAdjustedUnblockedShotAttemptsFor_y  dZoneGiveawaysFor_y  xGoalsFromxReboundsOfShotsFor_y  xGoalsFromActualReboundsOfShotsFor_y  reboundxGoalsFor_y  \\\n",
       "0                  0.231                  2.0                     0.0                   1.0                           64.070                        41.0                                   42.797                  4.0                            0.384                                 0.000               0.000   \n",
       "1                  1.148                  0.0                     0.0                   2.0                           57.029                        40.0                                   41.294                  3.0                            0.392                                 0.942               0.942   \n",
       "2                  0.631                  1.0                     1.0                   2.0                           56.055                        35.0                                   38.101                  4.0                            0.326                                 0.000               0.000   \n",
       "3                  1.068                  1.0                     0.0                   1.0                           63.625                        46.0                                   46.135                  5.0                            0.503                                 0.517               0.517   \n",
       "4                  0.751                  0.0                     0.0                   1.0                           71.124                        55.0                                   54.481                  6.0                            0.684                                 0.243               0.243   \n",
       "\n",
       "   totalShotCreditFor_y  scoreAdjustedTotalShotCreditFor_y  scoreFlurryAdjustedTotalShotCreditFor_y  xOnGoalAgainst_y  xGoalsAgainst_y  xReboundsAgainst_y  xFreezeAgainst_y  xPlayStoppedAgainst_y  xPlayContinuedInZoneAgainst_y  xPlayContinuedOutsideZoneAgainst_y  flurryAdjustedxGoalsAgainst_y  \\\n",
       "0                 2.244                              2.357                                    2.342            34.472            2.984               2.224             7.267                  1.042                         18.851                              14.633                          2.948   \n",
       "1                 1.792                              1.849                                    1.842            25.878            2.211               1.592             6.131                  0.881                         14.904                              11.281                          2.099   \n",
       "2                 2.281                              2.517                                    2.479            40.474            4.494               2.873             8.911                  1.356                         21.909                              17.457                          4.192   \n",
       "3                 2.833                              2.885                                    2.795            22.224            2.478               1.631             5.106                  0.704                         12.374                               8.706                          2.443   \n",
       "4                 2.630                              2.655                                    2.599            23.294            2.513               1.427             5.496                  0.729                         13.058                              10.777                          2.500   \n",
       "\n",
       "   scoreVenueAdjustedxGoalsAgainst_y  flurryScoreVenueAdjustedxGoalsAgainst_y  shotsOnGoalAgainst_y  missedShotsAgainst_y  blockedShotAttemptsAgainst_y  shotAttemptsAgainst_y  goalsAgainst_y  reboundsAgainst_y  reboundGoalsAgainst_y  freezeAgainst_y  playStoppedAgainst_y  playContinuedInZoneAgainst_y  \\\n",
       "0                              2.852                                    2.818                  36.0                  11.0                          11.0                   58.0             2.0                2.0                    1.0              5.0                   1.0                          22.0   \n",
       "1                              2.095                                    1.992                  24.0                  13.0                          14.0                   51.0             1.0                3.0                    0.0              7.0                   1.0                          12.0   \n",
       "2                              4.164                                    3.886                  45.0                  12.0                          20.0                   77.0             1.0                8.0                    0.0             10.0                   2.0                          17.0   \n",
       "3                              2.474                                    2.439                  22.0                   9.0                          17.0                   48.0             5.0                3.0                    0.0              6.0                   0.0                           8.0   \n",
       "4                              2.506                                    2.493                  22.0                  12.0                           9.0                   43.0             3.0                0.0                    0.0              7.0                   0.0                          12.0   \n",
       "\n",
       "   playContinuedOutsideZoneAgainst_y  savedShotsOnGoalAgainst_y  savedUnblockedShotAttemptsAgainst_y  penaltiesAgainst_y  penalityMinutesAgainst_y  faceOffsWonAgainst_y  hitsAgainst_y  takeawaysAgainst_y  giveawaysAgainst_y  lowDangerShotsAgainst_y  mediumDangerShotsAgainst_y  highDangerShotsAgainst_y  \\\n",
       "0                               15.0                       34.0                                 45.0                 2.0                       4.0                  29.0           24.0                10.0                10.0                     33.0                        11.0                       3.0   \n",
       "1                               13.0                       23.0                                 36.0                 4.0                       8.0                  29.0           23.0                 7.0                11.0                     31.0                         4.0                       2.0   \n",
       "2                               19.0                       44.0                                 56.0                 3.0                       6.0                  20.0           31.0                 8.0                15.0                     40.0                        10.0                       7.0   \n",
       "3                                9.0                       17.0                                 26.0                 4.0                      11.0                  31.0           28.0                 9.0                15.0                     23.0                         7.0                       1.0   \n",
       "4                               12.0                       19.0                                 31.0                 4.0                       8.0                  28.0           24.0                12.0                20.0                     27.0                         4.0                       3.0   \n",
       "\n",
       "   lowDangerxGoalsAgainst_y  mediumDangerxGoalsAgainst_y  highDangerxGoalsAgainst_y  lowDangerGoalsAgainst_y  mediumDangerGoalsAgainst_y  highDangerGoalsAgainst_y  scoreAdjustedShotsAttemptsAgainst_y  unblockedShotAttemptsAgainst_y  scoreAdjustedUnblockedShotAttemptsAgainst_y  dZoneGiveawaysAgainst_y  \\\n",
       "0                     0.785                        1.412                      0.787                      0.0                         0.0                       2.0                               55.535                            47.0                                       45.081                      2.0   \n",
       "1                     0.850                        0.514                      0.848                      1.0                         0.0                       0.0                               49.361                            37.0                                       35.820                      6.0   \n",
       "2                     1.496                        1.155                      1.843                      1.0                         0.0                       0.0                               70.976                            57.0                                       52.475                     15.0   \n",
       "3                     0.774                        0.796                      0.908                      4.0                         0.0                       1.0                               48.732                            31.0                                       31.055                      9.0   \n",
       "4                     0.652                        0.547                      1.315                      2.0                         0.0                       1.0                               44.562                            34.0                                       34.918                     18.0   \n",
       "\n",
       "   xGoalsFromxReboundsOfShotsAgainst_y  xGoalsFromActualReboundsOfShotsAgainst_y  reboundxGoalsAgainst_y  totalShotCreditAgainst_y  scoreAdjustedTotalShotCreditAgainst_y  scoreFlurryAdjustedTotalShotCreditAgainst_y  playoffGame_y  year_y  month_y  day_y  home_or_away#_y  team#_y  opposingTeam#_y  \n",
       "0                                0.486                                     0.521                   0.521                     2.949                                  2.819                                        2.790              0    2018       10      4                0       17               19  \n",
       "1                                0.340                                     1.047                   1.047                     1.504                                  1.446                                        1.435              0    2018       10     13                0       11               19  \n",
       "2                                0.608                                     1.690                   1.690                     3.411                                  3.164                                        3.051              0    2018       10     21                0        6               19  \n",
       "3                                0.359                                     0.217                   0.217                     2.621                                  2.614                                        2.585              0    2018       10     23                0       12               19  \n",
       "4                                0.292                                     0.000                   0.000                     2.805                                  2.797                                        2.781              0    2018       11      4                0        3               19  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical data\n",
    "categorical_cols = ['team_x', 'opposingTeam_x'] \n",
    "\n",
    "#import pandas as pd\n",
    "master = pd.get_dummies(master, columns = categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playerTeam_x</th>\n",
       "      <th>Shootout Game_x</th>\n",
       "      <th>OT Game_x</th>\n",
       "      <th>Win_x</th>\n",
       "      <th>Loss_x</th>\n",
       "      <th>home_or_away_x</th>\n",
       "      <th>gameDate_x</th>\n",
       "      <th>position_x</th>\n",
       "      <th>situation_x</th>\n",
       "      <th>xGoalsPercentage_x</th>\n",
       "      <th>corsiPercentage_x</th>\n",
       "      <th>fenwickPercentage_x</th>\n",
       "      <th>iceTime_x</th>\n",
       "      <th>xOnGoalFor_x</th>\n",
       "      <th>xGoalsFor_x</th>\n",
       "      <th>xReboundsFor_x</th>\n",
       "      <th>xFreezeFor_x</th>\n",
       "      <th>xPlayStoppedFor_x</th>\n",
       "      <th>xPlayContinuedInZoneFor_x</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor_x</th>\n",
       "      <th>flurryAdjustedxGoalsFor_x</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor_x</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor_x</th>\n",
       "      <th>shotsOnGoalFor_x</th>\n",
       "      <th>missedShotsFor_x</th>\n",
       "      <th>blockedShotAttemptsFor_x</th>\n",
       "      <th>shotAttemptsFor_x</th>\n",
       "      <th>goalsFor_x</th>\n",
       "      <th>reboundsFor_x</th>\n",
       "      <th>reboundGoalsFor_x</th>\n",
       "      <th>freezeFor_x</th>\n",
       "      <th>playStoppedFor_x</th>\n",
       "      <th>playContinuedInZoneFor_x</th>\n",
       "      <th>playContinuedOutsideZoneFor_x</th>\n",
       "      <th>savedShotsOnGoalFor_x</th>\n",
       "      <th>savedUnblockedShotAttemptsFor_x</th>\n",
       "      <th>penaltiesFor_x</th>\n",
       "      <th>penalityMinutesFor_x</th>\n",
       "      <th>faceOffsWonFor_x</th>\n",
       "      <th>hitsFor_x</th>\n",
       "      <th>takeawaysFor_x</th>\n",
       "      <th>giveawaysFor_x</th>\n",
       "      <th>lowDangerShotsFor_x</th>\n",
       "      <th>mediumDangerShotsFor_x</th>\n",
       "      <th>highDangerShotsFor_x</th>\n",
       "      <th>lowDangerxGoalsFor_x</th>\n",
       "      <th>mediumDangerxGoalsFor_x</th>\n",
       "      <th>highDangerxGoalsFor_x</th>\n",
       "      <th>lowDangerGoalsFor_x</th>\n",
       "      <th>mediumDangerGoalsFor_x</th>\n",
       "      <th>highDangerGoalsFor_x</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor_x</th>\n",
       "      <th>unblockedShotAttemptsFor_x</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor_x</th>\n",
       "      <th>dZoneGiveawaysFor_x</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor_x</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor_x</th>\n",
       "      <th>reboundxGoalsFor_x</th>\n",
       "      <th>totalShotCreditFor_x</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor_x</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor_x</th>\n",
       "      <th>xOnGoalAgainst_x</th>\n",
       "      <th>xGoalsAgainst_x</th>\n",
       "      <th>xReboundsAgainst_x</th>\n",
       "      <th>xFreezeAgainst_x</th>\n",
       "      <th>xPlayStoppedAgainst_x</th>\n",
       "      <th>xPlayContinuedInZoneAgainst_x</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst_x</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst_x</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst_x</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst_x</th>\n",
       "      <th>shotsOnGoalAgainst_x</th>\n",
       "      <th>missedShotsAgainst_x</th>\n",
       "      <th>blockedShotAttemptsAgainst_x</th>\n",
       "      <th>shotAttemptsAgainst_x</th>\n",
       "      <th>goalsAgainst_x</th>\n",
       "      <th>reboundsAgainst_x</th>\n",
       "      <th>reboundGoalsAgainst_x</th>\n",
       "      <th>freezeAgainst_x</th>\n",
       "      <th>playStoppedAgainst_x</th>\n",
       "      <th>playContinuedInZoneAgainst_x</th>\n",
       "      <th>playContinuedOutsideZoneAgainst_x</th>\n",
       "      <th>savedShotsOnGoalAgainst_x</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst_x</th>\n",
       "      <th>penaltiesAgainst_x</th>\n",
       "      <th>penalityMinutesAgainst_x</th>\n",
       "      <th>faceOffsWonAgainst_x</th>\n",
       "      <th>hitsAgainst_x</th>\n",
       "      <th>takeawaysAgainst_x</th>\n",
       "      <th>giveawaysAgainst_x</th>\n",
       "      <th>lowDangerShotsAgainst_x</th>\n",
       "      <th>mediumDangerShotsAgainst_x</th>\n",
       "      <th>highDangerShotsAgainst_x</th>\n",
       "      <th>lowDangerxGoalsAgainst_x</th>\n",
       "      <th>mediumDangerxGoalsAgainst_x</th>\n",
       "      <th>highDangerxGoalsAgainst_x</th>\n",
       "      <th>lowDangerGoalsAgainst_x</th>\n",
       "      <th>mediumDangerGoalsAgainst_x</th>\n",
       "      <th>highDangerGoalsAgainst_x</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst_x</th>\n",
       "      <th>unblockedShotAttemptsAgainst_x</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst_x</th>\n",
       "      <th>dZoneGiveawaysAgainst_x</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst_x</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst_x</th>\n",
       "      <th>reboundxGoalsAgainst_x</th>\n",
       "      <th>totalShotCreditAgainst_x</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst_x</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst_x</th>\n",
       "      <th>playoffGame_x</th>\n",
       "      <th>year_x</th>\n",
       "      <th>month_x</th>\n",
       "      <th>day_x</th>\n",
       "      <th>home_or_away#_x</th>\n",
       "      <th>team#_x</th>\n",
       "      <th>opposingTeam#_x</th>\n",
       "      <th>team_y</th>\n",
       "      <th>season_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>playerTeam_y</th>\n",
       "      <th>opposingTeam_y</th>\n",
       "      <th>Shootout Game_y</th>\n",
       "      <th>OT Game_y</th>\n",
       "      <th>Win_y</th>\n",
       "      <th>Loss_y</th>\n",
       "      <th>home_or_away_y</th>\n",
       "      <th>gameDate_y</th>\n",
       "      <th>position_y</th>\n",
       "      <th>situation_y</th>\n",
       "      <th>xGoalsPercentage_y</th>\n",
       "      <th>corsiPercentage_y</th>\n",
       "      <th>fenwickPercentage_y</th>\n",
       "      <th>iceTime_y</th>\n",
       "      <th>xOnGoalFor_y</th>\n",
       "      <th>xGoalsFor_y</th>\n",
       "      <th>xReboundsFor_y</th>\n",
       "      <th>xFreezeFor_y</th>\n",
       "      <th>xPlayStoppedFor_y</th>\n",
       "      <th>xPlayContinuedInZoneFor_y</th>\n",
       "      <th>xPlayContinuedOutsideZoneFor_y</th>\n",
       "      <th>flurryAdjustedxGoalsFor_y</th>\n",
       "      <th>scoreVenueAdjustedxGoalsFor_y</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsFor_y</th>\n",
       "      <th>shotsOnGoalFor_y</th>\n",
       "      <th>missedShotsFor_y</th>\n",
       "      <th>blockedShotAttemptsFor_y</th>\n",
       "      <th>shotAttemptsFor_y</th>\n",
       "      <th>...</th>\n",
       "      <th>freezeFor_y</th>\n",
       "      <th>playStoppedFor_y</th>\n",
       "      <th>playContinuedInZoneFor_y</th>\n",
       "      <th>playContinuedOutsideZoneFor_y</th>\n",
       "      <th>savedShotsOnGoalFor_y</th>\n",
       "      <th>savedUnblockedShotAttemptsFor_y</th>\n",
       "      <th>penaltiesFor_y</th>\n",
       "      <th>penalityMinutesFor_y</th>\n",
       "      <th>faceOffsWonFor_y</th>\n",
       "      <th>hitsFor_y</th>\n",
       "      <th>takeawaysFor_y</th>\n",
       "      <th>giveawaysFor_y</th>\n",
       "      <th>lowDangerShotsFor_y</th>\n",
       "      <th>mediumDangerShotsFor_y</th>\n",
       "      <th>highDangerShotsFor_y</th>\n",
       "      <th>lowDangerxGoalsFor_y</th>\n",
       "      <th>mediumDangerxGoalsFor_y</th>\n",
       "      <th>highDangerxGoalsFor_y</th>\n",
       "      <th>lowDangerGoalsFor_y</th>\n",
       "      <th>mediumDangerGoalsFor_y</th>\n",
       "      <th>highDangerGoalsFor_y</th>\n",
       "      <th>scoreAdjustedShotsAttemptsFor_y</th>\n",
       "      <th>unblockedShotAttemptsFor_y</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsFor_y</th>\n",
       "      <th>dZoneGiveawaysFor_y</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsFor_y</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsFor_y</th>\n",
       "      <th>reboundxGoalsFor_y</th>\n",
       "      <th>totalShotCreditFor_y</th>\n",
       "      <th>scoreAdjustedTotalShotCreditFor_y</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditFor_y</th>\n",
       "      <th>xOnGoalAgainst_y</th>\n",
       "      <th>xGoalsAgainst_y</th>\n",
       "      <th>xReboundsAgainst_y</th>\n",
       "      <th>xFreezeAgainst_y</th>\n",
       "      <th>xPlayStoppedAgainst_y</th>\n",
       "      <th>xPlayContinuedInZoneAgainst_y</th>\n",
       "      <th>xPlayContinuedOutsideZoneAgainst_y</th>\n",
       "      <th>flurryAdjustedxGoalsAgainst_y</th>\n",
       "      <th>scoreVenueAdjustedxGoalsAgainst_y</th>\n",
       "      <th>flurryScoreVenueAdjustedxGoalsAgainst_y</th>\n",
       "      <th>shotsOnGoalAgainst_y</th>\n",
       "      <th>missedShotsAgainst_y</th>\n",
       "      <th>blockedShotAttemptsAgainst_y</th>\n",
       "      <th>shotAttemptsAgainst_y</th>\n",
       "      <th>goalsAgainst_y</th>\n",
       "      <th>reboundsAgainst_y</th>\n",
       "      <th>reboundGoalsAgainst_y</th>\n",
       "      <th>freezeAgainst_y</th>\n",
       "      <th>playStoppedAgainst_y</th>\n",
       "      <th>playContinuedInZoneAgainst_y</th>\n",
       "      <th>playContinuedOutsideZoneAgainst_y</th>\n",
       "      <th>savedShotsOnGoalAgainst_y</th>\n",
       "      <th>savedUnblockedShotAttemptsAgainst_y</th>\n",
       "      <th>penaltiesAgainst_y</th>\n",
       "      <th>penalityMinutesAgainst_y</th>\n",
       "      <th>faceOffsWonAgainst_y</th>\n",
       "      <th>hitsAgainst_y</th>\n",
       "      <th>takeawaysAgainst_y</th>\n",
       "      <th>giveawaysAgainst_y</th>\n",
       "      <th>lowDangerShotsAgainst_y</th>\n",
       "      <th>mediumDangerShotsAgainst_y</th>\n",
       "      <th>highDangerShotsAgainst_y</th>\n",
       "      <th>lowDangerxGoalsAgainst_y</th>\n",
       "      <th>mediumDangerxGoalsAgainst_y</th>\n",
       "      <th>highDangerxGoalsAgainst_y</th>\n",
       "      <th>lowDangerGoalsAgainst_y</th>\n",
       "      <th>mediumDangerGoalsAgainst_y</th>\n",
       "      <th>highDangerGoalsAgainst_y</th>\n",
       "      <th>scoreAdjustedShotsAttemptsAgainst_y</th>\n",
       "      <th>unblockedShotAttemptsAgainst_y</th>\n",
       "      <th>scoreAdjustedUnblockedShotAttemptsAgainst_y</th>\n",
       "      <th>dZoneGiveawaysAgainst_y</th>\n",
       "      <th>xGoalsFromxReboundsOfShotsAgainst_y</th>\n",
       "      <th>xGoalsFromActualReboundsOfShotsAgainst_y</th>\n",
       "      <th>reboundxGoalsAgainst_y</th>\n",
       "      <th>totalShotCreditAgainst_y</th>\n",
       "      <th>scoreAdjustedTotalShotCreditAgainst_y</th>\n",
       "      <th>scoreFlurryAdjustedTotalShotCreditAgainst_y</th>\n",
       "      <th>playoffGame_y</th>\n",
       "      <th>year_y</th>\n",
       "      <th>month_y</th>\n",
       "      <th>day_y</th>\n",
       "      <th>home_or_away#_y</th>\n",
       "      <th>team#_y</th>\n",
       "      <th>opposingTeam#_y</th>\n",
       "      <th>team_x_ANA</th>\n",
       "      <th>team_x_ARI</th>\n",
       "      <th>team_x_BOS</th>\n",
       "      <th>team_x_BUF</th>\n",
       "      <th>team_x_CAR</th>\n",
       "      <th>team_x_CBJ</th>\n",
       "      <th>team_x_CGY</th>\n",
       "      <th>team_x_CHI</th>\n",
       "      <th>team_x_COL</th>\n",
       "      <th>team_x_DAL</th>\n",
       "      <th>team_x_DET</th>\n",
       "      <th>team_x_EDM</th>\n",
       "      <th>team_x_FLA</th>\n",
       "      <th>team_x_LAK</th>\n",
       "      <th>team_x_MIN</th>\n",
       "      <th>team_x_MTL</th>\n",
       "      <th>team_x_NJD</th>\n",
       "      <th>team_x_NSH</th>\n",
       "      <th>team_x_NYI</th>\n",
       "      <th>team_x_NYR</th>\n",
       "      <th>team_x_OTT</th>\n",
       "      <th>team_x_PHI</th>\n",
       "      <th>team_x_PIT</th>\n",
       "      <th>team_x_SEA</th>\n",
       "      <th>team_x_SJS</th>\n",
       "      <th>team_x_STL</th>\n",
       "      <th>team_x_TBL</th>\n",
       "      <th>team_x_TOR</th>\n",
       "      <th>team_x_VAN</th>\n",
       "      <th>team_x_VGK</th>\n",
       "      <th>team_x_WPG</th>\n",
       "      <th>team_x_WSH</th>\n",
       "      <th>opposingTeam_x_ANA</th>\n",
       "      <th>opposingTeam_x_ARI</th>\n",
       "      <th>opposingTeam_x_BOS</th>\n",
       "      <th>opposingTeam_x_BUF</th>\n",
       "      <th>opposingTeam_x_CAR</th>\n",
       "      <th>opposingTeam_x_CBJ</th>\n",
       "      <th>opposingTeam_x_CGY</th>\n",
       "      <th>opposingTeam_x_CHI</th>\n",
       "      <th>opposingTeam_x_COL</th>\n",
       "      <th>opposingTeam_x_DAL</th>\n",
       "      <th>opposingTeam_x_DET</th>\n",
       "      <th>opposingTeam_x_EDM</th>\n",
       "      <th>opposingTeam_x_FLA</th>\n",
       "      <th>opposingTeam_x_LAK</th>\n",
       "      <th>opposingTeam_x_MIN</th>\n",
       "      <th>opposingTeam_x_MTL</th>\n",
       "      <th>opposingTeam_x_NJD</th>\n",
       "      <th>opposingTeam_x_NSH</th>\n",
       "      <th>opposingTeam_x_NYI</th>\n",
       "      <th>opposingTeam_x_NYR</th>\n",
       "      <th>opposingTeam_x_OTT</th>\n",
       "      <th>opposingTeam_x_PHI</th>\n",
       "      <th>opposingTeam_x_PIT</th>\n",
       "      <th>opposingTeam_x_SEA</th>\n",
       "      <th>opposingTeam_x_SJS</th>\n",
       "      <th>opposingTeam_x_STL</th>\n",
       "      <th>opposingTeam_x_TBL</th>\n",
       "      <th>opposingTeam_x_TOR</th>\n",
       "      <th>opposingTeam_x_VAN</th>\n",
       "      <th>opposingTeam_x_VGK</th>\n",
       "      <th>opposingTeam_x_WPG</th>\n",
       "      <th>opposingTeam_x_WSH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020006</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>NSH</td>\n",
       "      <td>2018</td>\n",
       "      <td>NSH</td>\n",
       "      <td>NSH</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>29.403</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.845</td>\n",
       "      <td>7.090</td>\n",
       "      <td>0.898</td>\n",
       "      <td>16.864</td>\n",
       "      <td>12.443</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.941</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.070</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.342</td>\n",
       "      <td>34.472</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.224</td>\n",
       "      <td>7.267</td>\n",
       "      <td>1.042</td>\n",
       "      <td>18.851</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.818</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.535</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.819</td>\n",
       "      <td>2.790</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020057</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>EDM</td>\n",
       "      <td>2018</td>\n",
       "      <td>EDM</td>\n",
       "      <td>EDM</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>28.237</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.791</td>\n",
       "      <td>6.929</td>\n",
       "      <td>0.959</td>\n",
       "      <td>16.066</td>\n",
       "      <td>11.912</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.348</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.029</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.842</td>\n",
       "      <td>25.878</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.592</td>\n",
       "      <td>6.131</td>\n",
       "      <td>0.881</td>\n",
       "      <td>14.904</td>\n",
       "      <td>11.281</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.095</td>\n",
       "      <td>1.992</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.361</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.435</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020115</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>CGY</td>\n",
       "      <td>2018</td>\n",
       "      <td>CGY</td>\n",
       "      <td>CGY</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>24.688</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.510</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.786</td>\n",
       "      <td>13.542</td>\n",
       "      <td>11.476</td>\n",
       "      <td>1.925</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.129</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.055</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.479</td>\n",
       "      <td>40.474</td>\n",
       "      <td>4.494</td>\n",
       "      <td>2.873</td>\n",
       "      <td>8.911</td>\n",
       "      <td>1.356</td>\n",
       "      <td>21.909</td>\n",
       "      <td>17.457</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.164</td>\n",
       "      <td>3.886</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.976</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.475</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>3.411</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020122</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>22.224</td>\n",
       "      <td>2.478</td>\n",
       "      <td>1.631</td>\n",
       "      <td>5.106</td>\n",
       "      <td>0.704</td>\n",
       "      <td>12.374</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.443</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.732</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.055</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.217</td>\n",
       "      <td>2.621</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.585</td>\n",
       "      <td>33.062</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>7.885</td>\n",
       "      <td>1.071</td>\n",
       "      <td>18.013</td>\n",
       "      <td>13.885</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.625</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.795</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>FLA</td>\n",
       "      <td>2018</td>\n",
       "      <td>FLA</td>\n",
       "      <td>FLA</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5974</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>33.062</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>7.885</td>\n",
       "      <td>1.071</td>\n",
       "      <td>18.013</td>\n",
       "      <td>13.885</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.625</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.795</td>\n",
       "      <td>22.224</td>\n",
       "      <td>2.478</td>\n",
       "      <td>1.631</td>\n",
       "      <td>5.106</td>\n",
       "      <td>0.704</td>\n",
       "      <td>12.374</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.443</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.732</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.055</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.217</td>\n",
       "      <td>2.621</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.585</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2018020208</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>23.294</td>\n",
       "      <td>2.513</td>\n",
       "      <td>1.427</td>\n",
       "      <td>5.496</td>\n",
       "      <td>0.729</td>\n",
       "      <td>13.058</td>\n",
       "      <td>10.777</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.506</td>\n",
       "      <td>2.493</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.562</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.918</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.781</td>\n",
       "      <td>38.112</td>\n",
       "      <td>2.189</td>\n",
       "      <td>3.016</td>\n",
       "      <td>8.649</td>\n",
       "      <td>1.378</td>\n",
       "      <td>24.378</td>\n",
       "      <td>15.391</td>\n",
       "      <td>2.139</td>\n",
       "      <td>2.207</td>\n",
       "      <td>2.157</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.124</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.599</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>BUF</td>\n",
       "      <td>2018</td>\n",
       "      <td>BUF</td>\n",
       "      <td>BUF</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Team Level</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>38.112</td>\n",
       "      <td>2.189</td>\n",
       "      <td>3.016</td>\n",
       "      <td>8.649</td>\n",
       "      <td>1.378</td>\n",
       "      <td>24.378</td>\n",
       "      <td>15.391</td>\n",
       "      <td>2.139</td>\n",
       "      <td>2.207</td>\n",
       "      <td>2.157</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.124</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.599</td>\n",
       "      <td>23.294</td>\n",
       "      <td>2.513</td>\n",
       "      <td>1.427</td>\n",
       "      <td>5.496</td>\n",
       "      <td>0.729</td>\n",
       "      <td>13.058</td>\n",
       "      <td>10.777</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.506</td>\n",
       "      <td>2.493</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.562</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.918</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season_x name_x      gameId playerTeam_x  Shootout Game_x  OT Game_x  Win_x  Loss_x home_or_away_x gameDate_x  position_x situation_x  xGoalsPercentage_x  corsiPercentage_x  fenwickPercentage_x  iceTime_x  xOnGoalFor_x  xGoalsFor_x  xReboundsFor_x  xFreezeFor_x  xPlayStoppedFor_x  xPlayContinuedInZoneFor_x  \\\n",
       "0      2018    NYR  2018020006          NYR                0          0      0       1           HOME 2018-10-04  Team Level         all              0.6160             0.4874               0.5341     3600.0        34.472        2.984           2.224         7.267              1.042                     18.851   \n",
       "1      2018    NYR  2018020057          NYR                0          0      0       1           HOME 2018-10-13  Team Level         all              0.4856             0.4811               0.4805     3600.0        25.878        2.211           1.592         6.131              0.881                     14.904   \n",
       "2      2018    NYR  2018020115          NYR                0          0      0       1           HOME 2018-10-21  Team Level         all              0.6969             0.6016               0.6196     3600.0        40.474        4.494           2.873         8.911              1.356                     21.909   \n",
       "3      2018    NYR  2018020122          NYR                0          0      1       0           HOME 2018-10-23  Team Level         all              0.4654             0.4286               0.4026     3600.0        22.224        2.478           1.631         5.106              0.704                     12.374   \n",
       "4      2018    NYR  2018020208          NYR                0          0      1       0           HOME 2018-11-04  Team Level         all              0.5345             0.3739               0.3820     3600.0        23.294        2.513           1.427         5.496              0.729                     13.058   \n",
       "\n",
       "   xPlayContinuedOutsideZoneFor_x  flurryAdjustedxGoalsFor_x  scoreVenueAdjustedxGoalsFor_x  flurryScoreVenueAdjustedxGoalsFor_x  shotsOnGoalFor_x  missedShotsFor_x  blockedShotAttemptsFor_x  shotAttemptsFor_x  goalsFor_x  reboundsFor_x  reboundGoalsFor_x  freezeFor_x  playStoppedFor_x  playContinuedInZoneFor_x  \\\n",
       "0                          14.633                      2.948                          2.852                                2.818              36.0              11.0                      11.0               58.0         2.0            2.0                1.0          5.0               1.0                      22.0   \n",
       "1                          11.281                      2.099                          2.095                                1.992              24.0              13.0                      14.0               51.0         1.0            3.0                0.0          7.0               1.0                      12.0   \n",
       "2                          17.457                      4.192                          4.164                                3.886              45.0              12.0                      20.0               77.0         1.0            8.0                0.0         10.0               2.0                      17.0   \n",
       "3                           8.706                      2.443                          2.474                                2.439              22.0               9.0                      17.0               48.0         5.0            3.0                0.0          6.0               0.0                       8.0   \n",
       "4                          10.777                      2.500                          2.506                                2.493              22.0              12.0                       9.0               43.0         3.0            0.0                0.0          7.0               0.0                      12.0   \n",
       "\n",
       "   playContinuedOutsideZoneFor_x  savedShotsOnGoalFor_x  savedUnblockedShotAttemptsFor_x  penaltiesFor_x  penalityMinutesFor_x  faceOffsWonFor_x  hitsFor_x  takeawaysFor_x  giveawaysFor_x  lowDangerShotsFor_x  mediumDangerShotsFor_x  highDangerShotsFor_x  lowDangerxGoalsFor_x  mediumDangerxGoalsFor_x  \\\n",
       "0                           15.0                   34.0                             45.0             2.0                   4.0              29.0       24.0            10.0            10.0                 33.0                    11.0                   3.0                 0.785                    1.412   \n",
       "1                           13.0                   23.0                             36.0             4.0                   8.0              29.0       23.0             7.0            11.0                 31.0                     4.0                   2.0                 0.850                    0.514   \n",
       "2                           19.0                   44.0                             56.0             3.0                   6.0              20.0       31.0             8.0            15.0                 40.0                    10.0                   7.0                 1.496                    1.155   \n",
       "3                            9.0                   17.0                             26.0             4.0                  11.0              31.0       28.0             9.0            15.0                 23.0                     7.0                   1.0                 0.774                    0.796   \n",
       "4                           12.0                   19.0                             31.0             4.0                   8.0              28.0       24.0            12.0            20.0                 27.0                     4.0                   3.0                 0.652                    0.547   \n",
       "\n",
       "   highDangerxGoalsFor_x  lowDangerGoalsFor_x  mediumDangerGoalsFor_x  highDangerGoalsFor_x  scoreAdjustedShotsAttemptsFor_x  unblockedShotAttemptsFor_x  scoreAdjustedUnblockedShotAttemptsFor_x  dZoneGiveawaysFor_x  xGoalsFromxReboundsOfShotsFor_x  xGoalsFromActualReboundsOfShotsFor_x  reboundxGoalsFor_x  \\\n",
       "0                  0.787                  0.0                     0.0                   2.0                           55.535                        47.0                                   45.081                  2.0                            0.486                                 0.521               0.521   \n",
       "1                  0.848                  1.0                     0.0                   0.0                           49.361                        37.0                                   35.820                  6.0                            0.340                                 1.047               1.047   \n",
       "2                  1.843                  1.0                     0.0                   0.0                           70.976                        57.0                                   52.475                 15.0                            0.608                                 1.690               1.690   \n",
       "3                  0.908                  4.0                     0.0                   1.0                           48.732                        31.0                                   31.055                  9.0                            0.359                                 0.217               0.217   \n",
       "4                  1.315                  2.0                     0.0                   1.0                           44.562                        34.0                                   34.918                 18.0                            0.292                                 0.000               0.000   \n",
       "\n",
       "   totalShotCreditFor_x  scoreAdjustedTotalShotCreditFor_x  scoreFlurryAdjustedTotalShotCreditFor_x  xOnGoalAgainst_x  xGoalsAgainst_x  xReboundsAgainst_x  xFreezeAgainst_x  xPlayStoppedAgainst_x  xPlayContinuedInZoneAgainst_x  xPlayContinuedOutsideZoneAgainst_x  flurryAdjustedxGoalsAgainst_x  \\\n",
       "0                 2.949                              2.819                                    2.790            29.403            1.860               1.845             7.090                  0.898                         16.864                              12.443                          1.849   \n",
       "1                 1.504                              1.446                                    1.435            28.237            2.342               1.791             6.929                  0.959                         16.066                              11.912                          2.254   \n",
       "2                 3.411                              3.164                                    3.051            24.688            1.955               1.510             5.731                  0.786                         13.542                              11.476                          1.925   \n",
       "3                 2.621                              2.614                                    2.585            33.062            2.847               2.299             7.885                  1.071                         18.013                              13.885                          2.609   \n",
       "4                 2.805                              2.797                                    2.781            38.112            2.189               3.016             8.649                  1.378                         24.378                              15.391                          2.139   \n",
       "\n",
       "   scoreVenueAdjustedxGoalsAgainst_x  flurryScoreVenueAdjustedxGoalsAgainst_x  shotsOnGoalAgainst_x  missedShotsAgainst_x  blockedShotAttemptsAgainst_x  shotAttemptsAgainst_x  goalsAgainst_x  reboundsAgainst_x  reboundGoalsAgainst_x  freezeAgainst_x  playStoppedAgainst_x  playContinuedInZoneAgainst_x  \\\n",
       "0                              1.953                                    1.941                  33.0                   8.0                          20.0                   61.0             3.0                0.0                    0.0              8.0                   2.0                          12.0   \n",
       "1                              2.441                                    2.348                  27.0                  13.0                          15.0                   55.0             2.0                3.0                    1.0              8.0                   2.0                           9.0   \n",
       "2                              2.164                                    2.129                  26.0                   9.0                          16.0                   51.0             4.0                0.0                    0.0              2.0                   0.0                          14.0   \n",
       "3                              2.916                                    2.667                  38.0                   8.0                          18.0                   64.0             2.0                2.0                    0.0              6.0                   0.0                          17.0   \n",
       "4                              2.207                                    2.157                  40.0                  15.0                          17.0                   72.0             1.0                1.0                    0.0              6.0                   1.0                          31.0   \n",
       "\n",
       "   playContinuedOutsideZoneAgainst_x  savedShotsOnGoalAgainst_x  savedUnblockedShotAttemptsAgainst_x  penaltiesAgainst_x  penalityMinutesAgainst_x  faceOffsWonAgainst_x  hitsAgainst_x  takeawaysAgainst_x  giveawaysAgainst_x  lowDangerShotsAgainst_x  mediumDangerShotsAgainst_x  highDangerShotsAgainst_x  \\\n",
       "0                               16.0                       30.0                                 38.0                 3.0                       6.0                  32.0           21.0                16.0                 9.0                     33.0                         7.0                       1.0   \n",
       "1                               16.0                       25.0                                 38.0                 2.0                       4.0                  26.0           31.0                 6.0                10.0                     33.0                         4.0                       3.0   \n",
       "2                               15.0                       22.0                                 31.0                 2.0                       4.0                  31.0           23.0                 8.0                 6.0                     27.0                         6.0                       2.0   \n",
       "3                               19.0                       36.0                                 44.0                 7.0                      17.0                  27.0           28.0                10.0                11.0                     37.0                         6.0                       3.0   \n",
       "4                               15.0                       39.0                                 54.0                 1.0                       2.0                  28.0           18.0                 6.0                11.0                     47.0                         5.0                       3.0   \n",
       "\n",
       "   lowDangerxGoalsAgainst_x  mediumDangerxGoalsAgainst_x  highDangerxGoalsAgainst_x  lowDangerGoalsAgainst_x  mediumDangerGoalsAgainst_x  highDangerGoalsAgainst_x  scoreAdjustedShotsAttemptsAgainst_x  unblockedShotAttemptsAgainst_x  scoreAdjustedUnblockedShotAttemptsAgainst_x  dZoneGiveawaysAgainst_x  \\\n",
       "0                     0.893                        0.736                      0.231                      2.0                         0.0                       1.0                               64.070                            41.0                                       42.797                      4.0   \n",
       "1                     0.610                        0.583                      1.148                      0.0                         0.0                       2.0                               57.029                            40.0                                       41.294                      3.0   \n",
       "2                     0.556                        0.768                      0.631                      1.0                         1.0                       2.0                               56.055                            35.0                                       38.101                      4.0   \n",
       "3                     0.940                        0.839                      1.068                      1.0                         0.0                       1.0                               63.625                            46.0                                       46.135                      5.0   \n",
       "4                     0.880                        0.558                      0.751                      0.0                         0.0                       1.0                               71.124                            55.0                                       54.481                      6.0   \n",
       "\n",
       "   xGoalsFromxReboundsOfShotsAgainst_x  xGoalsFromActualReboundsOfShotsAgainst_x  reboundxGoalsAgainst_x  totalShotCreditAgainst_x  scoreAdjustedTotalShotCreditAgainst_x  scoreFlurryAdjustedTotalShotCreditAgainst_x  playoffGame_x  year_x  month_x  day_x  home_or_away#_x  team#_x  opposingTeam#_x team_y  season_y  \\\n",
       "0                                0.384                                     0.000                   0.000                     2.244                                  2.357                                        2.342              0    2018       10      4                1       19               17    NSH      2018   \n",
       "1                                0.392                                     0.942                   0.942                     1.792                                  1.849                                        1.842              0    2018       10     13                1       19               11    EDM      2018   \n",
       "2                                0.326                                     0.000                   0.000                     2.281                                  2.517                                        2.479              0    2018       10     21                1       19                6    CGY      2018   \n",
       "3                                0.503                                     0.517                   0.517                     2.833                                  2.885                                        2.795              0    2018       10     23                1       19               12    FLA      2018   \n",
       "4                                0.684                                     0.243                   0.243                     2.630                                  2.655                                        2.599              0    2018       11      4                1       19                3    BUF      2018   \n",
       "\n",
       "  name_y playerTeam_y opposingTeam_y  Shootout Game_y  OT Game_y  Win_y  Loss_y home_or_away_y gameDate_y  position_y situation_y  xGoalsPercentage_y  corsiPercentage_y  fenwickPercentage_y  iceTime_y  xOnGoalFor_y  xGoalsFor_y  xReboundsFor_y  xFreezeFor_y  xPlayStoppedFor_y  xPlayContinuedInZoneFor_y  \\\n",
       "0    NSH          NSH            NYR                0          0      1       0           AWAY 2018-10-04  Team Level         all              0.3840             0.5126               0.4659     3600.0        29.403        1.860           1.845         7.090              0.898                     16.864   \n",
       "1    EDM          EDM            NYR                0          0      1       0           AWAY 2018-10-13  Team Level         all              0.5144             0.5189               0.5195     3600.0        28.237        2.342           1.791         6.929              0.959                     16.066   \n",
       "2    CGY          CGY            NYR                0          0      1       0           AWAY 2018-10-21  Team Level         all              0.3031             0.3984               0.3804     3600.0        24.688        1.955           1.510         5.731              0.786                     13.542   \n",
       "3    FLA          FLA            NYR                0          0      0       1           AWAY 2018-10-23  Team Level         all              0.5346             0.5714               0.5974     3600.0        33.062        2.847           2.299         7.885              1.071                     18.013   \n",
       "4    BUF          BUF            NYR                0          0      0       1           AWAY 2018-11-04  Team Level         all              0.4655             0.6261               0.6180     3600.0        38.112        2.189           3.016         8.649              1.378                     24.378   \n",
       "\n",
       "   xPlayContinuedOutsideZoneFor_y  flurryAdjustedxGoalsFor_y  scoreVenueAdjustedxGoalsFor_y  flurryScoreVenueAdjustedxGoalsFor_y  shotsOnGoalFor_y  missedShotsFor_y  blockedShotAttemptsFor_y  shotAttemptsFor_y  ...  freezeFor_y  playStoppedFor_y  playContinuedInZoneFor_y  playContinuedOutsideZoneFor_y  \\\n",
       "0                          12.443                      1.849                          1.953                                1.941              33.0               8.0                      20.0               61.0  ...          8.0               2.0                      12.0                           16.0   \n",
       "1                          11.912                      2.254                          2.441                                2.348              27.0              13.0                      15.0               55.0  ...          8.0               2.0                       9.0                           16.0   \n",
       "2                          11.476                      1.925                          2.164                                2.129              26.0               9.0                      16.0               51.0  ...          2.0               0.0                      14.0                           15.0   \n",
       "3                          13.885                      2.609                          2.916                                2.667              38.0               8.0                      18.0               64.0  ...          6.0               0.0                      17.0                           19.0   \n",
       "4                          15.391                      2.139                          2.207                                2.157              40.0              15.0                      17.0               72.0  ...          6.0               1.0                      31.0                           15.0   \n",
       "\n",
       "   savedShotsOnGoalFor_y  savedUnblockedShotAttemptsFor_y  penaltiesFor_y  penalityMinutesFor_y  faceOffsWonFor_y  hitsFor_y  takeawaysFor_y  giveawaysFor_y  lowDangerShotsFor_y  mediumDangerShotsFor_y  highDangerShotsFor_y  lowDangerxGoalsFor_y  mediumDangerxGoalsFor_y  highDangerxGoalsFor_y  lowDangerGoalsFor_y  \\\n",
       "0                   30.0                             38.0             3.0                   6.0              32.0       21.0            16.0             9.0                 33.0                     7.0                   1.0                 0.893                    0.736                  0.231                  2.0   \n",
       "1                   25.0                             38.0             2.0                   4.0              26.0       31.0             6.0            10.0                 33.0                     4.0                   3.0                 0.610                    0.583                  1.148                  0.0   \n",
       "2                   22.0                             31.0             2.0                   4.0              31.0       23.0             8.0             6.0                 27.0                     6.0                   2.0                 0.556                    0.768                  0.631                  1.0   \n",
       "3                   36.0                             44.0             7.0                  17.0              27.0       28.0            10.0            11.0                 37.0                     6.0                   3.0                 0.940                    0.839                  1.068                  1.0   \n",
       "4                   39.0                             54.0             1.0                   2.0              28.0       18.0             6.0            11.0                 47.0                     5.0                   3.0                 0.880                    0.558                  0.751                  0.0   \n",
       "\n",
       "   mediumDangerGoalsFor_y  highDangerGoalsFor_y  scoreAdjustedShotsAttemptsFor_y  unblockedShotAttemptsFor_y  scoreAdjustedUnblockedShotAttemptsFor_y  dZoneGiveawaysFor_y  xGoalsFromxReboundsOfShotsFor_y  xGoalsFromActualReboundsOfShotsFor_y  reboundxGoalsFor_y  totalShotCreditFor_y  \\\n",
       "0                     0.0                   1.0                           64.070                        41.0                                   42.797                  4.0                            0.384                                 0.000               0.000                 2.244   \n",
       "1                     0.0                   2.0                           57.029                        40.0                                   41.294                  3.0                            0.392                                 0.942               0.942                 1.792   \n",
       "2                     1.0                   2.0                           56.055                        35.0                                   38.101                  4.0                            0.326                                 0.000               0.000                 2.281   \n",
       "3                     0.0                   1.0                           63.625                        46.0                                   46.135                  5.0                            0.503                                 0.517               0.517                 2.833   \n",
       "4                     0.0                   1.0                           71.124                        55.0                                   54.481                  6.0                            0.684                                 0.243               0.243                 2.630   \n",
       "\n",
       "   scoreAdjustedTotalShotCreditFor_y  scoreFlurryAdjustedTotalShotCreditFor_y  xOnGoalAgainst_y  xGoalsAgainst_y  xReboundsAgainst_y  xFreezeAgainst_y  xPlayStoppedAgainst_y  xPlayContinuedInZoneAgainst_y  xPlayContinuedOutsideZoneAgainst_y  flurryAdjustedxGoalsAgainst_y  scoreVenueAdjustedxGoalsAgainst_y  \\\n",
       "0                              2.357                                    2.342            34.472            2.984               2.224             7.267                  1.042                         18.851                              14.633                          2.948                              2.852   \n",
       "1                              1.849                                    1.842            25.878            2.211               1.592             6.131                  0.881                         14.904                              11.281                          2.099                              2.095   \n",
       "2                              2.517                                    2.479            40.474            4.494               2.873             8.911                  1.356                         21.909                              17.457                          4.192                              4.164   \n",
       "3                              2.885                                    2.795            22.224            2.478               1.631             5.106                  0.704                         12.374                               8.706                          2.443                              2.474   \n",
       "4                              2.655                                    2.599            23.294            2.513               1.427             5.496                  0.729                         13.058                              10.777                          2.500                              2.506   \n",
       "\n",
       "   flurryScoreVenueAdjustedxGoalsAgainst_y  shotsOnGoalAgainst_y  missedShotsAgainst_y  blockedShotAttemptsAgainst_y  shotAttemptsAgainst_y  goalsAgainst_y  reboundsAgainst_y  reboundGoalsAgainst_y  freezeAgainst_y  playStoppedAgainst_y  playContinuedInZoneAgainst_y  playContinuedOutsideZoneAgainst_y  \\\n",
       "0                                    2.818                  36.0                  11.0                          11.0                   58.0             2.0                2.0                    1.0              5.0                   1.0                          22.0                               15.0   \n",
       "1                                    1.992                  24.0                  13.0                          14.0                   51.0             1.0                3.0                    0.0              7.0                   1.0                          12.0                               13.0   \n",
       "2                                    3.886                  45.0                  12.0                          20.0                   77.0             1.0                8.0                    0.0             10.0                   2.0                          17.0                               19.0   \n",
       "3                                    2.439                  22.0                   9.0                          17.0                   48.0             5.0                3.0                    0.0              6.0                   0.0                           8.0                                9.0   \n",
       "4                                    2.493                  22.0                  12.0                           9.0                   43.0             3.0                0.0                    0.0              7.0                   0.0                          12.0                               12.0   \n",
       "\n",
       "   savedShotsOnGoalAgainst_y  savedUnblockedShotAttemptsAgainst_y  penaltiesAgainst_y  penalityMinutesAgainst_y  faceOffsWonAgainst_y  hitsAgainst_y  takeawaysAgainst_y  giveawaysAgainst_y  lowDangerShotsAgainst_y  mediumDangerShotsAgainst_y  highDangerShotsAgainst_y  lowDangerxGoalsAgainst_y  \\\n",
       "0                       34.0                                 45.0                 2.0                       4.0                  29.0           24.0                10.0                10.0                     33.0                        11.0                       3.0                     0.785   \n",
       "1                       23.0                                 36.0                 4.0                       8.0                  29.0           23.0                 7.0                11.0                     31.0                         4.0                       2.0                     0.850   \n",
       "2                       44.0                                 56.0                 3.0                       6.0                  20.0           31.0                 8.0                15.0                     40.0                        10.0                       7.0                     1.496   \n",
       "3                       17.0                                 26.0                 4.0                      11.0                  31.0           28.0                 9.0                15.0                     23.0                         7.0                       1.0                     0.774   \n",
       "4                       19.0                                 31.0                 4.0                       8.0                  28.0           24.0                12.0                20.0                     27.0                         4.0                       3.0                     0.652   \n",
       "\n",
       "   mediumDangerxGoalsAgainst_y  highDangerxGoalsAgainst_y  lowDangerGoalsAgainst_y  mediumDangerGoalsAgainst_y  highDangerGoalsAgainst_y  scoreAdjustedShotsAttemptsAgainst_y  unblockedShotAttemptsAgainst_y  scoreAdjustedUnblockedShotAttemptsAgainst_y  dZoneGiveawaysAgainst_y  xGoalsFromxReboundsOfShotsAgainst_y  \\\n",
       "0                        1.412                      0.787                      0.0                         0.0                       2.0                               55.535                            47.0                                       45.081                      2.0                                0.486   \n",
       "1                        0.514                      0.848                      1.0                         0.0                       0.0                               49.361                            37.0                                       35.820                      6.0                                0.340   \n",
       "2                        1.155                      1.843                      1.0                         0.0                       0.0                               70.976                            57.0                                       52.475                     15.0                                0.608   \n",
       "3                        0.796                      0.908                      4.0                         0.0                       1.0                               48.732                            31.0                                       31.055                      9.0                                0.359   \n",
       "4                        0.547                      1.315                      2.0                         0.0                       1.0                               44.562                            34.0                                       34.918                     18.0                                0.292   \n",
       "\n",
       "   xGoalsFromActualReboundsOfShotsAgainst_y  reboundxGoalsAgainst_y  totalShotCreditAgainst_y  scoreAdjustedTotalShotCreditAgainst_y  scoreFlurryAdjustedTotalShotCreditAgainst_y  playoffGame_y  year_y  month_y  day_y  home_or_away#_y  team#_y  opposingTeam#_y  team_x_ANA  team_x_ARI  team_x_BOS  team_x_BUF  \\\n",
       "0                                     0.521                   0.521                     2.949                                  2.819                                        2.790              0    2018       10      4                0       17               19           0           0           0           0   \n",
       "1                                     1.047                   1.047                     1.504                                  1.446                                        1.435              0    2018       10     13                0       11               19           0           0           0           0   \n",
       "2                                     1.690                   1.690                     3.411                                  3.164                                        3.051              0    2018       10     21                0        6               19           0           0           0           0   \n",
       "3                                     0.217                   0.217                     2.621                                  2.614                                        2.585              0    2018       10     23                0       12               19           0           0           0           0   \n",
       "4                                     0.000                   0.000                     2.805                                  2.797                                        2.781              0    2018       11      4                0        3               19           0           0           0           0   \n",
       "\n",
       "   team_x_CAR  team_x_CBJ  team_x_CGY  team_x_CHI  team_x_COL  team_x_DAL  team_x_DET  team_x_EDM  team_x_FLA  team_x_LAK  team_x_MIN  team_x_MTL  team_x_NJD  team_x_NSH  team_x_NYI  team_x_NYR  team_x_OTT  team_x_PHI  team_x_PIT  team_x_SEA  team_x_SJS  team_x_STL  team_x_TBL  team_x_TOR  team_x_VAN  team_x_VGK  \\\n",
       "0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0           0           0           0           0   \n",
       "\n",
       "   team_x_WPG  team_x_WSH  opposingTeam_x_ANA  opposingTeam_x_ARI  opposingTeam_x_BOS  opposingTeam_x_BUF  opposingTeam_x_CAR  opposingTeam_x_CBJ  opposingTeam_x_CGY  opposingTeam_x_CHI  opposingTeam_x_COL  opposingTeam_x_DAL  opposingTeam_x_DET  opposingTeam_x_EDM  opposingTeam_x_FLA  opposingTeam_x_LAK  \\\n",
       "0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0   \n",
       "2           0           0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0   \n",
       "3           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0   \n",
       "4           0           0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_MIN  opposingTeam_x_MTL  opposingTeam_x_NJD  opposingTeam_x_NSH  opposingTeam_x_NYI  opposingTeam_x_NYR  opposingTeam_x_OTT  opposingTeam_x_PHI  opposingTeam_x_PIT  opposingTeam_x_SEA  opposingTeam_x_SJS  opposingTeam_x_STL  opposingTeam_x_TBL  opposingTeam_x_TOR  opposingTeam_x_VAN  \\\n",
       "0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "2                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "3                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "4                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_VGK  opposingTeam_x_WPG  opposingTeam_x_WSH  \n",
       "0                   0                   0                   0  \n",
       "1                   0                   0                   0  \n",
       "2                   0                   0                   0  \n",
       "3                   0                   0                   0  \n",
       "4                   0                   0                   0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliced DF for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = master[['team_x_ANA',\n",
    " 'team_x_ARI',\n",
    " 'team_x_BOS',\n",
    " 'team_x_BUF',\n",
    " 'team_x_CAR',\n",
    " 'team_x_CBJ',\n",
    " 'team_x_CGY',\n",
    " 'team_x_CHI',\n",
    " 'team_x_COL',\n",
    " 'team_x_DAL',\n",
    " 'team_x_DET',\n",
    " 'team_x_EDM',\n",
    " 'team_x_FLA',\n",
    " 'team_x_LAK',\n",
    " 'team_x_MIN',\n",
    " 'team_x_MTL',\n",
    " 'team_x_NJD',\n",
    " 'team_x_NSH',\n",
    " 'team_x_NYI',\n",
    " 'team_x_NYR',\n",
    " 'team_x_OTT',\n",
    " 'team_x_PHI',\n",
    " 'team_x_PIT',\n",
    " 'team_x_SEA',\n",
    " 'team_x_SJS',\n",
    " 'team_x_STL',\n",
    " 'team_x_TBL',\n",
    " 'team_x_TOR',\n",
    " 'team_x_VAN',\n",
    " 'team_x_VGK',\n",
    " 'team_x_WPG',\n",
    " 'team_x_WSH',\n",
    " 'opposingTeam_x_ANA',\n",
    " 'opposingTeam_x_ARI',\n",
    " 'opposingTeam_x_BOS',\n",
    " 'opposingTeam_x_BUF',\n",
    " 'opposingTeam_x_CAR',\n",
    " 'opposingTeam_x_CBJ',\n",
    " 'opposingTeam_x_CGY',\n",
    " 'opposingTeam_x_CHI',\n",
    " 'opposingTeam_x_COL',\n",
    " 'opposingTeam_x_DAL',\n",
    " 'opposingTeam_x_DET',\n",
    " 'opposingTeam_x_EDM',\n",
    " 'opposingTeam_x_FLA',\n",
    " 'opposingTeam_x_LAK',\n",
    " 'opposingTeam_x_MIN',\n",
    " 'opposingTeam_x_MTL',\n",
    " 'opposingTeam_x_NJD',\n",
    " 'opposingTeam_x_NSH',\n",
    " 'opposingTeam_x_NYI',\n",
    " 'opposingTeam_x_NYR',\n",
    " 'opposingTeam_x_OTT',\n",
    " 'opposingTeam_x_PHI',\n",
    " 'opposingTeam_x_PIT',\n",
    " 'opposingTeam_x_SEA',\n",
    " 'opposingTeam_x_SJS',\n",
    " 'opposingTeam_x_STL',\n",
    " 'opposingTeam_x_TBL',\n",
    " 'opposingTeam_x_TOR',\n",
    " 'opposingTeam_x_VAN',\n",
    " 'opposingTeam_x_VGK',\n",
    " 'opposingTeam_x_WPG',\n",
    " 'opposingTeam_x_WSH',\n",
    " 'Win_x', 'corsiPercentage_x', 'corsiPercentage_y', 'fenwickPercentage_x', 'fenwickPercentage_y'\n",
    " ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_x_ANA</th>\n",
       "      <th>team_x_ARI</th>\n",
       "      <th>team_x_BOS</th>\n",
       "      <th>team_x_BUF</th>\n",
       "      <th>team_x_CAR</th>\n",
       "      <th>team_x_CBJ</th>\n",
       "      <th>team_x_CGY</th>\n",
       "      <th>team_x_CHI</th>\n",
       "      <th>team_x_COL</th>\n",
       "      <th>team_x_DAL</th>\n",
       "      <th>team_x_DET</th>\n",
       "      <th>team_x_EDM</th>\n",
       "      <th>team_x_FLA</th>\n",
       "      <th>team_x_LAK</th>\n",
       "      <th>team_x_MIN</th>\n",
       "      <th>team_x_MTL</th>\n",
       "      <th>team_x_NJD</th>\n",
       "      <th>team_x_NSH</th>\n",
       "      <th>team_x_NYI</th>\n",
       "      <th>team_x_NYR</th>\n",
       "      <th>team_x_OTT</th>\n",
       "      <th>team_x_PHI</th>\n",
       "      <th>team_x_PIT</th>\n",
       "      <th>team_x_SEA</th>\n",
       "      <th>team_x_SJS</th>\n",
       "      <th>team_x_STL</th>\n",
       "      <th>team_x_TBL</th>\n",
       "      <th>team_x_TOR</th>\n",
       "      <th>team_x_VAN</th>\n",
       "      <th>team_x_VGK</th>\n",
       "      <th>team_x_WPG</th>\n",
       "      <th>team_x_WSH</th>\n",
       "      <th>opposingTeam_x_ANA</th>\n",
       "      <th>opposingTeam_x_ARI</th>\n",
       "      <th>opposingTeam_x_BOS</th>\n",
       "      <th>opposingTeam_x_BUF</th>\n",
       "      <th>opposingTeam_x_CAR</th>\n",
       "      <th>opposingTeam_x_CBJ</th>\n",
       "      <th>opposingTeam_x_CGY</th>\n",
       "      <th>opposingTeam_x_CHI</th>\n",
       "      <th>opposingTeam_x_COL</th>\n",
       "      <th>opposingTeam_x_DAL</th>\n",
       "      <th>opposingTeam_x_DET</th>\n",
       "      <th>opposingTeam_x_EDM</th>\n",
       "      <th>opposingTeam_x_FLA</th>\n",
       "      <th>opposingTeam_x_LAK</th>\n",
       "      <th>opposingTeam_x_MIN</th>\n",
       "      <th>opposingTeam_x_MTL</th>\n",
       "      <th>opposingTeam_x_NJD</th>\n",
       "      <th>opposingTeam_x_NSH</th>\n",
       "      <th>opposingTeam_x_NYI</th>\n",
       "      <th>opposingTeam_x_NYR</th>\n",
       "      <th>opposingTeam_x_OTT</th>\n",
       "      <th>opposingTeam_x_PHI</th>\n",
       "      <th>opposingTeam_x_PIT</th>\n",
       "      <th>opposingTeam_x_SEA</th>\n",
       "      <th>opposingTeam_x_SJS</th>\n",
       "      <th>opposingTeam_x_STL</th>\n",
       "      <th>opposingTeam_x_TBL</th>\n",
       "      <th>opposingTeam_x_TOR</th>\n",
       "      <th>opposingTeam_x_VAN</th>\n",
       "      <th>opposingTeam_x_VGK</th>\n",
       "      <th>opposingTeam_x_WPG</th>\n",
       "      <th>opposingTeam_x_WSH</th>\n",
       "      <th>Win_x</th>\n",
       "      <th>corsiPercentage_x</th>\n",
       "      <th>corsiPercentage_y</th>\n",
       "      <th>fenwickPercentage_x</th>\n",
       "      <th>fenwickPercentage_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.4659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.5195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>0.3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.5974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>0.6180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_x_ANA  team_x_ARI  team_x_BOS  team_x_BUF  team_x_CAR  team_x_CBJ  team_x_CGY  team_x_CHI  team_x_COL  team_x_DAL  team_x_DET  team_x_EDM  team_x_FLA  team_x_LAK  team_x_MIN  team_x_MTL  team_x_NJD  team_x_NSH  team_x_NYI  team_x_NYR  team_x_OTT  team_x_PHI  team_x_PIT  team_x_SEA  team_x_SJS  team_x_STL  \\\n",
       "0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "\n",
       "   team_x_TBL  team_x_TOR  team_x_VAN  team_x_VGK  team_x_WPG  team_x_WSH  opposingTeam_x_ANA  opposingTeam_x_ARI  opposingTeam_x_BOS  opposingTeam_x_BUF  opposingTeam_x_CAR  opposingTeam_x_CBJ  opposingTeam_x_CGY  opposingTeam_x_CHI  opposingTeam_x_COL  opposingTeam_x_DAL  opposingTeam_x_DET  opposingTeam_x_EDM  \\\n",
       "0           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1   \n",
       "2           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0   \n",
       "3           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "4           0           0           0           0           0           0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_FLA  opposingTeam_x_LAK  opposingTeam_x_MIN  opposingTeam_x_MTL  opposingTeam_x_NJD  opposingTeam_x_NSH  opposingTeam_x_NYI  opposingTeam_x_NYR  opposingTeam_x_OTT  opposingTeam_x_PHI  opposingTeam_x_PIT  opposingTeam_x_SEA  opposingTeam_x_SJS  opposingTeam_x_STL  opposingTeam_x_TBL  \\\n",
       "0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "2                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "3                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "4                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_TOR  opposingTeam_x_VAN  opposingTeam_x_VGK  opposingTeam_x_WPG  opposingTeam_x_WSH  Win_x  corsiPercentage_x  corsiPercentage_y  fenwickPercentage_x  fenwickPercentage_y  \n",
       "0                   0                   0                   0                   0                   0      0             0.4874             0.5126               0.5341               0.4659  \n",
       "1                   0                   0                   0                   0                   0      0             0.4811             0.5189               0.4805               0.5195  \n",
       "2                   0                   0                   0                   0                   0      0             0.6016             0.3984               0.6196               0.3804  \n",
       "3                   0                   0                   0                   0                   0      1             0.4286             0.5714               0.4026               0.5974  \n",
       "4                   0                   0                   0                   0                   0      1             0.3739             0.6261               0.3820               0.6180  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NN/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "\n",
    "final.iloc[:, 65:] = scalar.fit_transform(final.iloc[:, 65:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_x_ANA</th>\n",
       "      <th>team_x_ARI</th>\n",
       "      <th>team_x_BOS</th>\n",
       "      <th>team_x_BUF</th>\n",
       "      <th>team_x_CAR</th>\n",
       "      <th>team_x_CBJ</th>\n",
       "      <th>team_x_CGY</th>\n",
       "      <th>team_x_CHI</th>\n",
       "      <th>team_x_COL</th>\n",
       "      <th>team_x_DAL</th>\n",
       "      <th>team_x_DET</th>\n",
       "      <th>team_x_EDM</th>\n",
       "      <th>team_x_FLA</th>\n",
       "      <th>team_x_LAK</th>\n",
       "      <th>team_x_MIN</th>\n",
       "      <th>team_x_MTL</th>\n",
       "      <th>team_x_NJD</th>\n",
       "      <th>team_x_NSH</th>\n",
       "      <th>team_x_NYI</th>\n",
       "      <th>team_x_NYR</th>\n",
       "      <th>team_x_OTT</th>\n",
       "      <th>team_x_PHI</th>\n",
       "      <th>team_x_PIT</th>\n",
       "      <th>team_x_SEA</th>\n",
       "      <th>team_x_SJS</th>\n",
       "      <th>team_x_STL</th>\n",
       "      <th>team_x_TBL</th>\n",
       "      <th>team_x_TOR</th>\n",
       "      <th>team_x_VAN</th>\n",
       "      <th>team_x_VGK</th>\n",
       "      <th>team_x_WPG</th>\n",
       "      <th>team_x_WSH</th>\n",
       "      <th>opposingTeam_x_ANA</th>\n",
       "      <th>opposingTeam_x_ARI</th>\n",
       "      <th>opposingTeam_x_BOS</th>\n",
       "      <th>opposingTeam_x_BUF</th>\n",
       "      <th>opposingTeam_x_CAR</th>\n",
       "      <th>opposingTeam_x_CBJ</th>\n",
       "      <th>opposingTeam_x_CGY</th>\n",
       "      <th>opposingTeam_x_CHI</th>\n",
       "      <th>opposingTeam_x_COL</th>\n",
       "      <th>opposingTeam_x_DAL</th>\n",
       "      <th>opposingTeam_x_DET</th>\n",
       "      <th>opposingTeam_x_EDM</th>\n",
       "      <th>opposingTeam_x_FLA</th>\n",
       "      <th>opposingTeam_x_LAK</th>\n",
       "      <th>opposingTeam_x_MIN</th>\n",
       "      <th>opposingTeam_x_MTL</th>\n",
       "      <th>opposingTeam_x_NJD</th>\n",
       "      <th>opposingTeam_x_NSH</th>\n",
       "      <th>opposingTeam_x_NYI</th>\n",
       "      <th>opposingTeam_x_NYR</th>\n",
       "      <th>opposingTeam_x_OTT</th>\n",
       "      <th>opposingTeam_x_PHI</th>\n",
       "      <th>opposingTeam_x_PIT</th>\n",
       "      <th>opposingTeam_x_SEA</th>\n",
       "      <th>opposingTeam_x_SJS</th>\n",
       "      <th>opposingTeam_x_STL</th>\n",
       "      <th>opposingTeam_x_TBL</th>\n",
       "      <th>opposingTeam_x_TOR</th>\n",
       "      <th>opposingTeam_x_VAN</th>\n",
       "      <th>opposingTeam_x_VGK</th>\n",
       "      <th>opposingTeam_x_WPG</th>\n",
       "      <th>opposingTeam_x_WSH</th>\n",
       "      <th>Win_x</th>\n",
       "      <th>corsiPercentage_x</th>\n",
       "      <th>corsiPercentage_y</th>\n",
       "      <th>fenwickPercentage_x</th>\n",
       "      <th>fenwickPercentage_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.314255</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.262182</td>\n",
       "      <td>-0.262187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.394897</td>\n",
       "      <td>0.394893</td>\n",
       "      <td>-0.408183</td>\n",
       "      <td>0.408176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.147546</td>\n",
       "      <td>-1.147552</td>\n",
       "      <td>1.331514</td>\n",
       "      <td>-1.331518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.066916</td>\n",
       "      <td>1.066912</td>\n",
       "      <td>-1.382463</td>\n",
       "      <td>1.382455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.767096</td>\n",
       "      <td>1.767092</td>\n",
       "      <td>-1.640103</td>\n",
       "      <td>1.640095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_x_ANA  team_x_ARI  team_x_BOS  team_x_BUF  team_x_CAR  team_x_CBJ  team_x_CGY  team_x_CHI  team_x_COL  team_x_DAL  team_x_DET  team_x_EDM  team_x_FLA  team_x_LAK  team_x_MIN  team_x_MTL  team_x_NJD  team_x_NSH  team_x_NYI  team_x_NYR  team_x_OTT  team_x_PHI  team_x_PIT  team_x_SEA  team_x_SJS  team_x_STL  \\\n",
       "0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           0           1           0           0           0           0           0           0   \n",
       "\n",
       "   team_x_TBL  team_x_TOR  team_x_VAN  team_x_VGK  team_x_WPG  team_x_WSH  opposingTeam_x_ANA  opposingTeam_x_ARI  opposingTeam_x_BOS  opposingTeam_x_BUF  opposingTeam_x_CAR  opposingTeam_x_CBJ  opposingTeam_x_CGY  opposingTeam_x_CHI  opposingTeam_x_COL  opposingTeam_x_DAL  opposingTeam_x_DET  opposingTeam_x_EDM  \\\n",
       "0           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1   \n",
       "2           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0   \n",
       "3           0           0           0           0           0           0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "4           0           0           0           0           0           0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_FLA  opposingTeam_x_LAK  opposingTeam_x_MIN  opposingTeam_x_MTL  opposingTeam_x_NJD  opposingTeam_x_NSH  opposingTeam_x_NYI  opposingTeam_x_NYR  opposingTeam_x_OTT  opposingTeam_x_PHI  opposingTeam_x_PIT  opposingTeam_x_SEA  opposingTeam_x_SJS  opposingTeam_x_STL  opposingTeam_x_TBL  \\\n",
       "0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "2                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "3                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "4                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0   \n",
       "\n",
       "   opposingTeam_x_TOR  opposingTeam_x_VAN  opposingTeam_x_VGK  opposingTeam_x_WPG  opposingTeam_x_WSH  Win_x  corsiPercentage_x  corsiPercentage_y  fenwickPercentage_x  fenwickPercentage_y  \n",
       "0                   0                   0                   0                   0                   0      0          -0.314255           0.314250             0.262182            -0.262187  \n",
       "1                   0                   0                   0                   0                   0      0          -0.394897           0.394893            -0.408183             0.408176  \n",
       "2                   0                   0                   0                   0                   0      0           1.147546          -1.147552             1.331514            -1.331518  \n",
       "3                   0                   0                   0                   0                   0      1          -1.066916           1.066912            -1.382463             1.382455  \n",
       "4                   0                   0                   0                   0                   0      1          -1.767096           1.767092            -1.640103             1.640095  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3619, 69)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for models\n",
    "features = final.drop(labels = \"Win_x\", axis = 1)\n",
    "labels = final[\"Win_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Logistic Regression model has been trained.\n",
      "** Training Score: 0.690846286701209\n",
      "** Testing Score: 0.6795580110497238\n",
      "** Training LogLoss: 0.5803957742694043\n",
      "** Testing LogLoss: 0.5894982976285701\n"
     ]
    }
   ],
   "source": [
    "# Train a LinearRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "lm = LogisticRegression(random_state = 19, max_iter=2000, solver = 'liblinear')\n",
    "#lm.fit(X_train.values,y_train)\n",
    "lm.fit(X_train, y_train)\n",
    "print(\"** Logistic Regression model has been trained.\")\n",
    "    \n",
    "# Get the train and test accuracy scores\n",
    "print(f\"** Training Score: {lm.score(X_train, y_train)}\")\n",
    "print(f\"** Testing Score: {lm.score(X_test, y_test)}\")\n",
    "\n",
    "# Get the train and test logloss results\n",
    "print(f\"** Training LogLoss: {log_loss(y_train, lm.predict_proba(X_train))}\")\n",
    "print(f\"** Testing LogLoss: {log_loss(y_test, lm.predict_proba(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 2, num_estimators: 10, Accuracy: 0.558 (+/- 0.025)\n",
      "max_features: 2, num_estimators: 30, Accuracy: 0.576 (+/- 0.018)\n",
      "max_features: 2, num_estimators: 50, Accuracy: 0.574 (+/- 0.026)\n",
      "max_features: 2, num_estimators: 70, Accuracy: 0.579 (+/- 0.023)\n",
      "max_features: 2, num_estimators: 90, Accuracy: 0.573 (+/- 0.025)\n",
      "max_features: 2, num_estimators: 110, Accuracy: 0.574 (+/- 0.029)\n",
      "max_features: 2, num_estimators: 130, Accuracy: 0.576 (+/- 0.031)\n",
      "max_features: 2, num_estimators: 150, Accuracy: 0.574 (+/- 0.028)\n",
      "max_features: 2, num_estimators: 170, Accuracy: 0.572 (+/- 0.033)\n",
      "max_features: 2, num_estimators: 190, Accuracy: 0.575 (+/- 0.023)\n",
      "max_features: 4, num_estimators: 10, Accuracy: 0.569 (+/- 0.048)\n",
      "max_features: 4, num_estimators: 30, Accuracy: 0.582 (+/- 0.050)\n",
      "max_features: 4, num_estimators: 50, Accuracy: 0.582 (+/- 0.041)\n",
      "max_features: 4, num_estimators: 70, Accuracy: 0.586 (+/- 0.040)\n",
      "max_features: 4, num_estimators: 90, Accuracy: 0.586 (+/- 0.031)\n",
      "max_features: 4, num_estimators: 110, Accuracy: 0.581 (+/- 0.034)\n",
      "max_features: 4, num_estimators: 130, Accuracy: 0.583 (+/- 0.046)\n",
      "max_features: 4, num_estimators: 150, Accuracy: 0.581 (+/- 0.042)\n",
      "max_features: 4, num_estimators: 170, Accuracy: 0.585 (+/- 0.042)\n",
      "max_features: 4, num_estimators: 190, Accuracy: 0.586 (+/- 0.038)\n",
      "max_features: 6, num_estimators: 10, Accuracy: 0.566 (+/- 0.035)\n",
      "max_features: 6, num_estimators: 30, Accuracy: 0.578 (+/- 0.020)\n",
      "max_features: 6, num_estimators: 50, Accuracy: 0.590 (+/- 0.044)\n",
      "max_features: 6, num_estimators: 70, Accuracy: 0.585 (+/- 0.044)\n",
      "max_features: 6, num_estimators: 90, Accuracy: 0.588 (+/- 0.044)\n",
      "max_features: 6, num_estimators: 110, Accuracy: 0.584 (+/- 0.046)\n",
      "max_features: 6, num_estimators: 130, Accuracy: 0.585 (+/- 0.050)\n",
      "max_features: 6, num_estimators: 150, Accuracy: 0.591 (+/- 0.045)\n",
      "max_features: 6, num_estimators: 170, Accuracy: 0.591 (+/- 0.044)\n",
      "max_features: 6, num_estimators: 190, Accuracy: 0.588 (+/- 0.051)\n",
      "max_features: 8, num_estimators: 10, Accuracy: 0.574 (+/- 0.034)\n",
      "max_features: 8, num_estimators: 30, Accuracy: 0.590 (+/- 0.028)\n",
      "max_features: 8, num_estimators: 50, Accuracy: 0.590 (+/- 0.036)\n",
      "max_features: 8, num_estimators: 70, Accuracy: 0.593 (+/- 0.043)\n",
      "max_features: 8, num_estimators: 90, Accuracy: 0.590 (+/- 0.048)\n",
      "max_features: 8, num_estimators: 110, Accuracy: 0.593 (+/- 0.051)\n",
      "max_features: 8, num_estimators: 130, Accuracy: 0.589 (+/- 0.050)\n",
      "max_features: 8, num_estimators: 150, Accuracy: 0.588 (+/- 0.049)\n",
      "max_features: 8, num_estimators: 170, Accuracy: 0.590 (+/- 0.053)\n",
      "max_features: 8, num_estimators: 190, Accuracy: 0.588 (+/- 0.054)\n",
      "max_features: 10, num_estimators: 10, Accuracy: 0.572 (+/- 0.057)\n",
      "max_features: 10, num_estimators: 30, Accuracy: 0.584 (+/- 0.036)\n",
      "max_features: 10, num_estimators: 50, Accuracy: 0.588 (+/- 0.049)\n",
      "max_features: 10, num_estimators: 70, Accuracy: 0.592 (+/- 0.048)\n",
      "max_features: 10, num_estimators: 90, Accuracy: 0.590 (+/- 0.047)\n",
      "max_features: 10, num_estimators: 110, Accuracy: 0.599 (+/- 0.055)\n",
      "max_features: 10, num_estimators: 130, Accuracy: 0.597 (+/- 0.048)\n",
      "max_features: 10, num_estimators: 150, Accuracy: 0.597 (+/- 0.051)\n",
      "max_features: 10, num_estimators: 170, Accuracy: 0.597 (+/- 0.055)\n",
      "max_features: 10, num_estimators: 190, Accuracy: 0.598 (+/- 0.053)\n",
      "max_features: 12, num_estimators: 10, Accuracy: 0.572 (+/- 0.047)\n",
      "max_features: 12, num_estimators: 30, Accuracy: 0.590 (+/- 0.040)\n",
      "max_features: 12, num_estimators: 50, Accuracy: 0.591 (+/- 0.051)\n",
      "max_features: 12, num_estimators: 70, Accuracy: 0.590 (+/- 0.046)\n",
      "max_features: 12, num_estimators: 90, Accuracy: 0.592 (+/- 0.038)\n",
      "max_features: 12, num_estimators: 110, Accuracy: 0.595 (+/- 0.041)\n",
      "max_features: 12, num_estimators: 130, Accuracy: 0.596 (+/- 0.038)\n",
      "max_features: 12, num_estimators: 150, Accuracy: 0.595 (+/- 0.040)\n",
      "max_features: 12, num_estimators: 170, Accuracy: 0.593 (+/- 0.040)\n",
      "max_features: 12, num_estimators: 190, Accuracy: 0.591 (+/- 0.049)\n",
      "max_features: 14, num_estimators: 10, Accuracy: 0.585 (+/- 0.051)\n",
      "max_features: 14, num_estimators: 30, Accuracy: 0.590 (+/- 0.048)\n",
      "max_features: 14, num_estimators: 50, Accuracy: 0.592 (+/- 0.045)\n",
      "max_features: 14, num_estimators: 70, Accuracy: 0.597 (+/- 0.044)\n",
      "max_features: 14, num_estimators: 90, Accuracy: 0.591 (+/- 0.043)\n",
      "max_features: 14, num_estimators: 110, Accuracy: 0.590 (+/- 0.041)\n",
      "max_features: 14, num_estimators: 130, Accuracy: 0.590 (+/- 0.050)\n",
      "max_features: 14, num_estimators: 150, Accuracy: 0.594 (+/- 0.050)\n",
      "max_features: 14, num_estimators: 170, Accuracy: 0.593 (+/- 0.045)\n",
      "max_features: 14, num_estimators: 190, Accuracy: 0.593 (+/- 0.046)\n",
      "max_features: 16, num_estimators: 10, Accuracy: 0.584 (+/- 0.040)\n",
      "max_features: 16, num_estimators: 30, Accuracy: 0.593 (+/- 0.035)\n",
      "max_features: 16, num_estimators: 50, Accuracy: 0.594 (+/- 0.054)\n",
      "max_features: 16, num_estimators: 70, Accuracy: 0.596 (+/- 0.050)\n",
      "max_features: 16, num_estimators: 90, Accuracy: 0.596 (+/- 0.047)\n",
      "max_features: 16, num_estimators: 110, Accuracy: 0.599 (+/- 0.041)\n",
      "max_features: 16, num_estimators: 130, Accuracy: 0.594 (+/- 0.038)\n",
      "max_features: 16, num_estimators: 150, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 16, num_estimators: 170, Accuracy: 0.597 (+/- 0.034)\n",
      "max_features: 16, num_estimators: 190, Accuracy: 0.596 (+/- 0.033)\n",
      "max_features: 18, num_estimators: 10, Accuracy: 0.582 (+/- 0.023)\n",
      "max_features: 18, num_estimators: 30, Accuracy: 0.595 (+/- 0.042)\n",
      "max_features: 18, num_estimators: 50, Accuracy: 0.597 (+/- 0.047)\n",
      "max_features: 18, num_estimators: 70, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 18, num_estimators: 90, Accuracy: 0.596 (+/- 0.044)\n",
      "max_features: 18, num_estimators: 110, Accuracy: 0.599 (+/- 0.043)\n",
      "max_features: 18, num_estimators: 130, Accuracy: 0.599 (+/- 0.045)\n",
      "max_features: 18, num_estimators: 150, Accuracy: 0.596 (+/- 0.037)\n",
      "max_features: 18, num_estimators: 170, Accuracy: 0.599 (+/- 0.046)\n",
      "max_features: 18, num_estimators: 190, Accuracy: 0.599 (+/- 0.047)\n",
      "max_features: 20, num_estimators: 10, Accuracy: 0.579 (+/- 0.037)\n",
      "max_features: 20, num_estimators: 30, Accuracy: 0.593 (+/- 0.037)\n",
      "max_features: 20, num_estimators: 50, Accuracy: 0.598 (+/- 0.039)\n",
      "max_features: 20, num_estimators: 70, Accuracy: 0.599 (+/- 0.037)\n",
      "max_features: 20, num_estimators: 90, Accuracy: 0.594 (+/- 0.044)\n",
      "max_features: 20, num_estimators: 110, Accuracy: 0.598 (+/- 0.043)\n",
      "max_features: 20, num_estimators: 130, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 20, num_estimators: 150, Accuracy: 0.600 (+/- 0.034)\n",
      "max_features: 20, num_estimators: 170, Accuracy: 0.598 (+/- 0.034)\n",
      "max_features: 20, num_estimators: 190, Accuracy: 0.598 (+/- 0.035)\n",
      "max_features: 22, num_estimators: 10, Accuracy: 0.577 (+/- 0.044)\n",
      "max_features: 22, num_estimators: 30, Accuracy: 0.588 (+/- 0.045)\n",
      "max_features: 22, num_estimators: 50, Accuracy: 0.588 (+/- 0.045)\n",
      "max_features: 22, num_estimators: 70, Accuracy: 0.591 (+/- 0.051)\n",
      "max_features: 22, num_estimators: 90, Accuracy: 0.589 (+/- 0.057)\n",
      "max_features: 22, num_estimators: 110, Accuracy: 0.588 (+/- 0.058)\n",
      "max_features: 22, num_estimators: 130, Accuracy: 0.593 (+/- 0.050)\n",
      "max_features: 22, num_estimators: 150, Accuracy: 0.591 (+/- 0.048)\n",
      "max_features: 22, num_estimators: 170, Accuracy: 0.592 (+/- 0.045)\n",
      "max_features: 22, num_estimators: 190, Accuracy: 0.592 (+/- 0.041)\n",
      "max_features: 24, num_estimators: 10, Accuracy: 0.580 (+/- 0.022)\n",
      "max_features: 24, num_estimators: 30, Accuracy: 0.593 (+/- 0.052)\n",
      "max_features: 24, num_estimators: 50, Accuracy: 0.599 (+/- 0.050)\n",
      "max_features: 24, num_estimators: 70, Accuracy: 0.592 (+/- 0.045)\n",
      "max_features: 24, num_estimators: 90, Accuracy: 0.592 (+/- 0.051)\n",
      "max_features: 24, num_estimators: 110, Accuracy: 0.596 (+/- 0.049)\n",
      "max_features: 24, num_estimators: 130, Accuracy: 0.598 (+/- 0.042)\n",
      "max_features: 24, num_estimators: 150, Accuracy: 0.598 (+/- 0.043)\n",
      "max_features: 24, num_estimators: 170, Accuracy: 0.599 (+/- 0.043)\n",
      "max_features: 24, num_estimators: 190, Accuracy: 0.598 (+/- 0.041)\n",
      "max_features: 26, num_estimators: 10, Accuracy: 0.577 (+/- 0.054)\n",
      "max_features: 26, num_estimators: 30, Accuracy: 0.586 (+/- 0.038)\n",
      "max_features: 26, num_estimators: 50, Accuracy: 0.598 (+/- 0.049)\n",
      "max_features: 26, num_estimators: 70, Accuracy: 0.596 (+/- 0.043)\n",
      "max_features: 26, num_estimators: 90, Accuracy: 0.598 (+/- 0.038)\n",
      "max_features: 26, num_estimators: 110, Accuracy: 0.605 (+/- 0.036)\n",
      "max_features: 26, num_estimators: 130, Accuracy: 0.600 (+/- 0.036)\n",
      "max_features: 26, num_estimators: 150, Accuracy: 0.603 (+/- 0.036)\n",
      "max_features: 26, num_estimators: 170, Accuracy: 0.604 (+/- 0.041)\n",
      "max_features: 26, num_estimators: 190, Accuracy: 0.600 (+/- 0.043)\n",
      "max_features: 28, num_estimators: 10, Accuracy: 0.584 (+/- 0.048)\n",
      "max_features: 28, num_estimators: 30, Accuracy: 0.589 (+/- 0.041)\n",
      "max_features: 28, num_estimators: 50, Accuracy: 0.592 (+/- 0.050)\n",
      "max_features: 28, num_estimators: 70, Accuracy: 0.597 (+/- 0.034)\n",
      "max_features: 28, num_estimators: 90, Accuracy: 0.596 (+/- 0.046)\n",
      "max_features: 28, num_estimators: 110, Accuracy: 0.598 (+/- 0.043)\n",
      "max_features: 28, num_estimators: 130, Accuracy: 0.594 (+/- 0.032)\n",
      "max_features: 28, num_estimators: 150, Accuracy: 0.596 (+/- 0.032)\n",
      "max_features: 28, num_estimators: 170, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 28, num_estimators: 190, Accuracy: 0.594 (+/- 0.037)\n",
      "max_features: 30, num_estimators: 10, Accuracy: 0.570 (+/- 0.047)\n",
      "max_features: 30, num_estimators: 30, Accuracy: 0.589 (+/- 0.038)\n",
      "max_features: 30, num_estimators: 50, Accuracy: 0.589 (+/- 0.026)\n",
      "max_features: 30, num_estimators: 70, Accuracy: 0.597 (+/- 0.035)\n",
      "max_features: 30, num_estimators: 90, Accuracy: 0.590 (+/- 0.023)\n",
      "max_features: 30, num_estimators: 110, Accuracy: 0.590 (+/- 0.031)\n",
      "max_features: 30, num_estimators: 130, Accuracy: 0.590 (+/- 0.036)\n",
      "max_features: 30, num_estimators: 150, Accuracy: 0.589 (+/- 0.028)\n",
      "max_features: 30, num_estimators: 170, Accuracy: 0.588 (+/- 0.032)\n",
      "max_features: 30, num_estimators: 190, Accuracy: 0.592 (+/- 0.036)\n",
      "max_features: 32, num_estimators: 10, Accuracy: 0.582 (+/- 0.032)\n",
      "max_features: 32, num_estimators: 30, Accuracy: 0.597 (+/- 0.036)\n",
      "max_features: 32, num_estimators: 50, Accuracy: 0.598 (+/- 0.045)\n",
      "max_features: 32, num_estimators: 70, Accuracy: 0.599 (+/- 0.044)\n",
      "max_features: 32, num_estimators: 90, Accuracy: 0.600 (+/- 0.044)\n",
      "max_features: 32, num_estimators: 110, Accuracy: 0.601 (+/- 0.043)\n",
      "max_features: 32, num_estimators: 130, Accuracy: 0.601 (+/- 0.038)\n",
      "max_features: 32, num_estimators: 150, Accuracy: 0.602 (+/- 0.037)\n",
      "max_features: 32, num_estimators: 170, Accuracy: 0.602 (+/- 0.039)\n",
      "max_features: 32, num_estimators: 190, Accuracy: 0.602 (+/- 0.039)\n",
      "max_features: 34, num_estimators: 10, Accuracy: 0.578 (+/- 0.040)\n",
      "max_features: 34, num_estimators: 30, Accuracy: 0.592 (+/- 0.035)\n",
      "max_features: 34, num_estimators: 50, Accuracy: 0.593 (+/- 0.042)\n",
      "max_features: 34, num_estimators: 70, Accuracy: 0.594 (+/- 0.044)\n",
      "max_features: 34, num_estimators: 90, Accuracy: 0.590 (+/- 0.044)\n",
      "max_features: 34, num_estimators: 110, Accuracy: 0.592 (+/- 0.042)\n",
      "max_features: 34, num_estimators: 130, Accuracy: 0.593 (+/- 0.035)\n",
      "max_features: 34, num_estimators: 150, Accuracy: 0.594 (+/- 0.045)\n",
      "max_features: 34, num_estimators: 170, Accuracy: 0.594 (+/- 0.040)\n",
      "max_features: 34, num_estimators: 190, Accuracy: 0.595 (+/- 0.044)\n",
      "max_features: 36, num_estimators: 10, Accuracy: 0.589 (+/- 0.016)\n",
      "max_features: 36, num_estimators: 30, Accuracy: 0.596 (+/- 0.023)\n",
      "max_features: 36, num_estimators: 50, Accuracy: 0.598 (+/- 0.041)\n",
      "max_features: 36, num_estimators: 70, Accuracy: 0.594 (+/- 0.037)\n",
      "max_features: 36, num_estimators: 90, Accuracy: 0.595 (+/- 0.034)\n",
      "max_features: 36, num_estimators: 110, Accuracy: 0.594 (+/- 0.025)\n",
      "max_features: 36, num_estimators: 130, Accuracy: 0.595 (+/- 0.032)\n",
      "max_features: 36, num_estimators: 150, Accuracy: 0.593 (+/- 0.027)\n",
      "max_features: 36, num_estimators: 170, Accuracy: 0.594 (+/- 0.027)\n",
      "max_features: 36, num_estimators: 190, Accuracy: 0.592 (+/- 0.026)\n",
      "max_features: 38, num_estimators: 10, Accuracy: 0.575 (+/- 0.034)\n",
      "max_features: 38, num_estimators: 30, Accuracy: 0.589 (+/- 0.036)\n",
      "max_features: 38, num_estimators: 50, Accuracy: 0.588 (+/- 0.034)\n",
      "max_features: 38, num_estimators: 70, Accuracy: 0.588 (+/- 0.033)\n",
      "max_features: 38, num_estimators: 90, Accuracy: 0.591 (+/- 0.040)\n",
      "max_features: 38, num_estimators: 110, Accuracy: 0.594 (+/- 0.036)\n",
      "max_features: 38, num_estimators: 130, Accuracy: 0.595 (+/- 0.036)\n",
      "max_features: 38, num_estimators: 150, Accuracy: 0.594 (+/- 0.037)\n",
      "max_features: 38, num_estimators: 170, Accuracy: 0.593 (+/- 0.041)\n",
      "max_features: 38, num_estimators: 190, Accuracy: 0.593 (+/- 0.035)\n",
      "max_features: 40, num_estimators: 10, Accuracy: 0.583 (+/- 0.031)\n",
      "max_features: 40, num_estimators: 30, Accuracy: 0.589 (+/- 0.040)\n",
      "max_features: 40, num_estimators: 50, Accuracy: 0.588 (+/- 0.045)\n",
      "max_features: 40, num_estimators: 70, Accuracy: 0.587 (+/- 0.047)\n",
      "max_features: 40, num_estimators: 90, Accuracy: 0.589 (+/- 0.033)\n",
      "max_features: 40, num_estimators: 110, Accuracy: 0.589 (+/- 0.030)\n",
      "max_features: 40, num_estimators: 130, Accuracy: 0.592 (+/- 0.037)\n",
      "max_features: 40, num_estimators: 150, Accuracy: 0.592 (+/- 0.029)\n",
      "max_features: 40, num_estimators: 170, Accuracy: 0.593 (+/- 0.029)\n",
      "max_features: 40, num_estimators: 190, Accuracy: 0.594 (+/- 0.031)\n",
      "max_features: 42, num_estimators: 10, Accuracy: 0.598 (+/- 0.053)\n",
      "max_features: 42, num_estimators: 30, Accuracy: 0.595 (+/- 0.040)\n",
      "max_features: 42, num_estimators: 50, Accuracy: 0.591 (+/- 0.053)\n",
      "max_features: 42, num_estimators: 70, Accuracy: 0.587 (+/- 0.049)\n",
      "max_features: 42, num_estimators: 90, Accuracy: 0.587 (+/- 0.048)\n",
      "max_features: 42, num_estimators: 110, Accuracy: 0.589 (+/- 0.041)\n",
      "max_features: 42, num_estimators: 130, Accuracy: 0.592 (+/- 0.040)\n",
      "max_features: 42, num_estimators: 150, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 42, num_estimators: 170, Accuracy: 0.593 (+/- 0.039)\n",
      "max_features: 42, num_estimators: 190, Accuracy: 0.594 (+/- 0.037)\n",
      "max_features: 44, num_estimators: 10, Accuracy: 0.577 (+/- 0.046)\n",
      "max_features: 44, num_estimators: 30, Accuracy: 0.591 (+/- 0.029)\n",
      "max_features: 44, num_estimators: 50, Accuracy: 0.589 (+/- 0.034)\n",
      "max_features: 44, num_estimators: 70, Accuracy: 0.593 (+/- 0.031)\n",
      "max_features: 44, num_estimators: 90, Accuracy: 0.592 (+/- 0.027)\n",
      "max_features: 44, num_estimators: 110, Accuracy: 0.595 (+/- 0.027)\n",
      "max_features: 44, num_estimators: 130, Accuracy: 0.595 (+/- 0.034)\n",
      "max_features: 44, num_estimators: 150, Accuracy: 0.599 (+/- 0.030)\n",
      "max_features: 44, num_estimators: 170, Accuracy: 0.601 (+/- 0.033)\n",
      "max_features: 44, num_estimators: 190, Accuracy: 0.600 (+/- 0.034)\n",
      "max_features: 46, num_estimators: 10, Accuracy: 0.580 (+/- 0.028)\n",
      "max_features: 46, num_estimators: 30, Accuracy: 0.585 (+/- 0.023)\n",
      "max_features: 46, num_estimators: 50, Accuracy: 0.590 (+/- 0.026)\n",
      "max_features: 46, num_estimators: 70, Accuracy: 0.592 (+/- 0.024)\n",
      "max_features: 46, num_estimators: 90, Accuracy: 0.595 (+/- 0.020)\n",
      "max_features: 46, num_estimators: 110, Accuracy: 0.591 (+/- 0.027)\n",
      "max_features: 46, num_estimators: 130, Accuracy: 0.595 (+/- 0.030)\n",
      "max_features: 46, num_estimators: 150, Accuracy: 0.597 (+/- 0.038)\n",
      "max_features: 46, num_estimators: 170, Accuracy: 0.593 (+/- 0.032)\n",
      "max_features: 46, num_estimators: 190, Accuracy: 0.596 (+/- 0.029)\n",
      "max_features: 48, num_estimators: 10, Accuracy: 0.586 (+/- 0.037)\n",
      "max_features: 48, num_estimators: 30, Accuracy: 0.596 (+/- 0.046)\n",
      "max_features: 48, num_estimators: 50, Accuracy: 0.594 (+/- 0.040)\n",
      "max_features: 48, num_estimators: 70, Accuracy: 0.593 (+/- 0.044)\n",
      "max_features: 48, num_estimators: 90, Accuracy: 0.596 (+/- 0.038)\n",
      "max_features: 48, num_estimators: 110, Accuracy: 0.594 (+/- 0.037)\n",
      "max_features: 48, num_estimators: 130, Accuracy: 0.596 (+/- 0.036)\n",
      "max_features: 48, num_estimators: 150, Accuracy: 0.597 (+/- 0.038)\n",
      "max_features: 48, num_estimators: 170, Accuracy: 0.591 (+/- 0.037)\n",
      "max_features: 48, num_estimators: 190, Accuracy: 0.592 (+/- 0.040)\n",
      "max_features: 50, num_estimators: 10, Accuracy: 0.577 (+/- 0.049)\n",
      "max_features: 50, num_estimators: 30, Accuracy: 0.596 (+/- 0.041)\n",
      "max_features: 50, num_estimators: 50, Accuracy: 0.590 (+/- 0.034)\n",
      "max_features: 50, num_estimators: 70, Accuracy: 0.598 (+/- 0.033)\n",
      "max_features: 50, num_estimators: 90, Accuracy: 0.590 (+/- 0.034)\n",
      "max_features: 50, num_estimators: 110, Accuracy: 0.592 (+/- 0.034)\n",
      "max_features: 50, num_estimators: 130, Accuracy: 0.596 (+/- 0.036)\n",
      "max_features: 50, num_estimators: 150, Accuracy: 0.593 (+/- 0.044)\n",
      "max_features: 50, num_estimators: 170, Accuracy: 0.590 (+/- 0.049)\n",
      "max_features: 50, num_estimators: 190, Accuracy: 0.595 (+/- 0.044)\n",
      "max_features: 52, num_estimators: 10, Accuracy: 0.583 (+/- 0.037)\n",
      "max_features: 52, num_estimators: 30, Accuracy: 0.591 (+/- 0.036)\n",
      "max_features: 52, num_estimators: 50, Accuracy: 0.598 (+/- 0.044)\n",
      "max_features: 52, num_estimators: 70, Accuracy: 0.593 (+/- 0.034)\n",
      "max_features: 52, num_estimators: 90, Accuracy: 0.591 (+/- 0.043)\n",
      "max_features: 52, num_estimators: 110, Accuracy: 0.589 (+/- 0.045)\n",
      "max_features: 52, num_estimators: 130, Accuracy: 0.593 (+/- 0.046)\n",
      "max_features: 52, num_estimators: 150, Accuracy: 0.595 (+/- 0.038)\n",
      "max_features: 52, num_estimators: 170, Accuracy: 0.598 (+/- 0.040)\n",
      "max_features: 52, num_estimators: 190, Accuracy: 0.596 (+/- 0.044)\n",
      "max_features: 54, num_estimators: 10, Accuracy: 0.584 (+/- 0.045)\n",
      "max_features: 54, num_estimators: 30, Accuracy: 0.591 (+/- 0.052)\n",
      "max_features: 54, num_estimators: 50, Accuracy: 0.595 (+/- 0.048)\n",
      "max_features: 54, num_estimators: 70, Accuracy: 0.593 (+/- 0.052)\n",
      "max_features: 54, num_estimators: 90, Accuracy: 0.592 (+/- 0.048)\n",
      "max_features: 54, num_estimators: 110, Accuracy: 0.597 (+/- 0.052)\n",
      "max_features: 54, num_estimators: 130, Accuracy: 0.594 (+/- 0.049)\n",
      "max_features: 54, num_estimators: 150, Accuracy: 0.590 (+/- 0.039)\n",
      "max_features: 54, num_estimators: 170, Accuracy: 0.590 (+/- 0.046)\n",
      "max_features: 54, num_estimators: 190, Accuracy: 0.589 (+/- 0.041)\n",
      "max_features: 56, num_estimators: 10, Accuracy: 0.585 (+/- 0.051)\n",
      "max_features: 56, num_estimators: 30, Accuracy: 0.591 (+/- 0.040)\n",
      "max_features: 56, num_estimators: 50, Accuracy: 0.596 (+/- 0.034)\n",
      "max_features: 56, num_estimators: 70, Accuracy: 0.600 (+/- 0.046)\n",
      "max_features: 56, num_estimators: 90, Accuracy: 0.594 (+/- 0.039)\n",
      "max_features: 56, num_estimators: 110, Accuracy: 0.593 (+/- 0.029)\n",
      "max_features: 56, num_estimators: 130, Accuracy: 0.592 (+/- 0.042)\n",
      "max_features: 56, num_estimators: 150, Accuracy: 0.593 (+/- 0.045)\n",
      "max_features: 56, num_estimators: 170, Accuracy: 0.590 (+/- 0.044)\n",
      "max_features: 56, num_estimators: 190, Accuracy: 0.592 (+/- 0.045)\n",
      "max_features: 58, num_estimators: 10, Accuracy: 0.593 (+/- 0.041)\n",
      "max_features: 58, num_estimators: 30, Accuracy: 0.590 (+/- 0.038)\n",
      "max_features: 58, num_estimators: 50, Accuracy: 0.596 (+/- 0.032)\n",
      "max_features: 58, num_estimators: 70, Accuracy: 0.592 (+/- 0.042)\n",
      "max_features: 58, num_estimators: 90, Accuracy: 0.592 (+/- 0.039)\n",
      "max_features: 58, num_estimators: 110, Accuracy: 0.591 (+/- 0.039)\n",
      "max_features: 58, num_estimators: 130, Accuracy: 0.590 (+/- 0.040)\n",
      "max_features: 58, num_estimators: 150, Accuracy: 0.591 (+/- 0.034)\n",
      "max_features: 58, num_estimators: 170, Accuracy: 0.590 (+/- 0.033)\n",
      "max_features: 58, num_estimators: 190, Accuracy: 0.592 (+/- 0.041)\n",
      "max_features: 60, num_estimators: 10, Accuracy: 0.579 (+/- 0.046)\n",
      "max_features: 60, num_estimators: 30, Accuracy: 0.585 (+/- 0.034)\n",
      "max_features: 60, num_estimators: 50, Accuracy: 0.592 (+/- 0.044)\n",
      "max_features: 60, num_estimators: 70, Accuracy: 0.592 (+/- 0.035)\n",
      "max_features: 60, num_estimators: 90, Accuracy: 0.593 (+/- 0.035)\n",
      "max_features: 60, num_estimators: 110, Accuracy: 0.593 (+/- 0.037)\n",
      "max_features: 60, num_estimators: 130, Accuracy: 0.593 (+/- 0.041)\n",
      "max_features: 60, num_estimators: 150, Accuracy: 0.594 (+/- 0.039)\n",
      "max_features: 60, num_estimators: 170, Accuracy: 0.595 (+/- 0.040)\n",
      "max_features: 60, num_estimators: 190, Accuracy: 0.593 (+/- 0.033)\n",
      "max_features: 62, num_estimators: 10, Accuracy: 0.590 (+/- 0.037)\n",
      "max_features: 62, num_estimators: 30, Accuracy: 0.597 (+/- 0.042)\n",
      "max_features: 62, num_estimators: 50, Accuracy: 0.595 (+/- 0.048)\n",
      "max_features: 62, num_estimators: 70, Accuracy: 0.599 (+/- 0.042)\n",
      "max_features: 62, num_estimators: 90, Accuracy: 0.596 (+/- 0.035)\n",
      "max_features: 62, num_estimators: 110, Accuracy: 0.594 (+/- 0.042)\n",
      "max_features: 62, num_estimators: 130, Accuracy: 0.592 (+/- 0.038)\n",
      "max_features: 62, num_estimators: 150, Accuracy: 0.596 (+/- 0.037)\n",
      "max_features: 62, num_estimators: 170, Accuracy: 0.595 (+/- 0.041)\n",
      "max_features: 62, num_estimators: 190, Accuracy: 0.592 (+/- 0.038)\n",
      "max_features: 64, num_estimators: 10, Accuracy: 0.580 (+/- 0.037)\n",
      "max_features: 64, num_estimators: 30, Accuracy: 0.589 (+/- 0.034)\n",
      "max_features: 64, num_estimators: 50, Accuracy: 0.594 (+/- 0.045)\n",
      "max_features: 64, num_estimators: 70, Accuracy: 0.599 (+/- 0.046)\n",
      "max_features: 64, num_estimators: 90, Accuracy: 0.595 (+/- 0.045)\n",
      "max_features: 64, num_estimators: 110, Accuracy: 0.595 (+/- 0.043)\n",
      "max_features: 64, num_estimators: 130, Accuracy: 0.592 (+/- 0.047)\n",
      "max_features: 64, num_estimators: 150, Accuracy: 0.596 (+/- 0.047)\n",
      "max_features: 64, num_estimators: 170, Accuracy: 0.592 (+/- 0.041)\n",
      "max_features: 64, num_estimators: 190, Accuracy: 0.594 (+/- 0.038)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initializing a DataFrame to save each model results\n",
    "rf_results = pd.DataFrame()\n",
    "\n",
    "# Loop to use different parameters in the model\n",
    "for f in np.arange(2,68,2):\n",
    "    for e in np.arange(10,200,20):\n",
    "        # Create Random Forest model\n",
    "        clf = RandomForestClassifier(max_features = f,\n",
    "                                    random_state = 0,\n",
    "                                    n_estimators = e)\n",
    "        \n",
    "        # Fit and train the model using the training data\n",
    "        clf.fit(X_train, y_train.values.ravel())\n",
    "        \n",
    "        # Scoring the models results\n",
    "        #cScore = clf2.score(df_test_att, df_test_label)\n",
    "        \n",
    "        # Score the model based on 'cv' folds\n",
    "        clfScores = cross_val_score(clf, X_train, y_train.values.ravel(), cv = 5)\n",
    "        \n",
    "        # Print average scores and +/- two standard deviations away (covering 95% of scores)\n",
    "        print(\"max_features: %i, num_estimators: %i, Accuracy: %0.3f (+/- %0.3f)\" % (f, e, clfScores.mean(), clfScores.std() * 2))\n",
    "        \n",
    "        # New row for results dataframe containing model hyperparameters and results\n",
    "        new_row = {'max_features': f,\n",
    "                   'num_estimators': e,\n",
    "                   'accuracy': clfScores.mean()}\n",
    "        rf_results = rf_results.append(new_row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# Data for a three-dimensional scattered points\n",
    "x = rf_results['max_features'].tolist()\n",
    "y = rf_results['num_estimators'].tolist()     # test removing .tolist() on all three lines\n",
    "z = rf_results['accuracy'].tolist()\n",
    "\n",
    "# Creating figure\n",
    "fig = plt.figure(figsize= (12,8))\n",
    "ax = plt.axes(projection = \"3d\")\n",
    "\n",
    "# Creating plot\n",
    "ax.scatter3D(x, y, z, cmap = 'Greens')\n",
    "plt.title(\"Random Forest - Hyperparameter Testing\")\n",
    "ax.set_xlabel('max_features')\n",
    "ax.set_ylabel('num_estimators')\n",
    "ax.set_zlabel('accuracy')\n",
    "\n",
    "#Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>max_features</th>\n",
       "      <th>num_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.604850</td>\n",
       "      <td>26.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.603815</td>\n",
       "      <td>26.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.602773</td>\n",
       "      <td>26.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>32.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>32.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.572377</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.570303</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.568583</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.565811</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  max_features  num_estimators\n",
       "125  0.604850          26.0           110.0\n",
       "128  0.603815          26.0           170.0\n",
       "127  0.602773          26.0           150.0\n",
       "157  0.602088          32.0           150.0\n",
       "158  0.601748          32.0           170.0\n",
       "..        ...           ...             ...\n",
       "40   0.572377          10.0            10.0\n",
       "140  0.570303          30.0            10.0\n",
       "10   0.568583           4.0            10.0\n",
       "20   0.565811           6.0            10.0\n",
       "0    0.557851           2.0            10.0\n",
       "\n",
       "[320 rows x 3 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results DataFrame\n",
    "rf_results.sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset: (2895, 68)\n",
      "Dimensions:68\n"
     ]
    }
   ],
   "source": [
    "# Finding the shape for input_dim\n",
    "print(f\"The shape of the dataset: {X_train.shape}\")\n",
    "dims = X_train.shape[1]\n",
    "print(f'Dimensions:{dims}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a multilayer neural network using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(68, input_dim = dims, activation = 'softmax'))\n",
    "#model.add(SimpleRNN(68, activation = 'relu'))\n",
    "#model.add(Dropout(.20))\n",
    "model.add(Dense(34, activation = 'softmax'))\n",
    "#model.add(Dense(1, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 68)                4692      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 34)                2346      \n",
      "=================================================================\n",
      "Total params: 7,038\n",
      "Trainable params: 7,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(0.001)\n",
    "# optimizer = tf.keras.optimizers.Adadelta(1.) # BEST!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model to provide the training parameters\n",
    "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/300\n",
      "2460/2460 [==============================] - 0s 197us/sample - loss: 3.3857 - accuracy: 0.4138 - val_loss: 3.2346 - val_accuracy: 0.4667\n",
      "Epoch 2/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.0877 - accuracy: 0.5126 - val_loss: 2.9355 - val_accuracy: 0.5540\n",
      "Epoch 3/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 2.7890 - accuracy: 0.5382 - val_loss: 2.6358 - val_accuracy: 0.5678\n",
      "Epoch 4/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 2.4909 - accuracy: 0.5520 - val_loss: 2.3375 - val_accuracy: 0.5563\n",
      "Epoch 5/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.1969 - accuracy: 0.5585 - val_loss: 2.0470 - val_accuracy: 0.5517\n",
      "Epoch 6/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.9160 - accuracy: 0.5610 - val_loss: 1.7762 - val_accuracy: 0.5517\n",
      "Epoch 7/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 1.6624 - accuracy: 0.5650 - val_loss: 1.5423 - val_accuracy: 0.5494\n",
      "Epoch 8/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.4517 - accuracy: 0.5614 - val_loss: 1.3574 - val_accuracy: 0.5425\n",
      "Epoch 9/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 1.2883 - accuracy: 0.5581 - val_loss: 1.2170 - val_accuracy: 0.5333\n",
      "Epoch 10/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.1642 - accuracy: 0.5565 - val_loss: 1.1101 - val_accuracy: 0.5425\n",
      "Epoch 11/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.0691 - accuracy: 0.5504 - val_loss: 1.0275 - val_accuracy: 0.5425\n",
      "Epoch 12/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.9959 - accuracy: 0.5472 - val_loss: 0.9642 - val_accuracy: 0.5425\n",
      "Epoch 13/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.9404 - accuracy: 0.5472 - val_loss: 0.9163 - val_accuracy: 0.5425\n",
      "Epoch 14/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8982 - accuracy: 0.5472 - val_loss: 0.8800 - val_accuracy: 0.5425\n",
      "Epoch 15/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.8659 - accuracy: 0.5472 - val_loss: 0.8518 - val_accuracy: 0.5425\n",
      "Epoch 16/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.8408 - accuracy: 0.5472 - val_loss: 0.8295 - val_accuracy: 0.5425\n",
      "Epoch 17/300\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.8209 - accuracy: 0.5472 - val_loss: 0.8117 - val_accuracy: 0.5425\n",
      "Epoch 18/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.8048 - accuracy: 0.5472 - val_loss: 0.7972 - val_accuracy: 0.5425\n",
      "Epoch 19/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7916 - accuracy: 0.5472 - val_loss: 0.7852 - val_accuracy: 0.5425\n",
      "Epoch 20/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7806 - accuracy: 0.5472 - val_loss: 0.7751 - val_accuracy: 0.5425\n",
      "Epoch 21/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7713 - accuracy: 0.5472 - val_loss: 0.7666 - val_accuracy: 0.5425\n",
      "Epoch 22/300\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7634 - accuracy: 0.5472 - val_loss: 0.7592 - val_accuracy: 0.5425\n",
      "Epoch 23/300\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7566 - accuracy: 0.5472 - val_loss: 0.7529 - val_accuracy: 0.5425\n",
      "Epoch 24/300\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7507 - accuracy: 0.5472 - val_loss: 0.7473 - val_accuracy: 0.5425\n",
      "Epoch 25/300\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7455 - accuracy: 0.5472 - val_loss: 0.7424 - val_accuracy: 0.5425\n",
      "Epoch 26/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7409 - accuracy: 0.5435 - val_loss: 0.7381 - val_accuracy: 0.5425\n",
      "Epoch 27/300\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7367 - accuracy: 0.5472 - val_loss: 0.7342 - val_accuracy: 0.5425\n",
      "Epoch 28/300\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7331 - accuracy: 0.5472 - val_loss: 0.7308 - val_accuracy: 0.5425\n",
      "Epoch 29/300\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7298 - accuracy: 0.5419 - val_loss: 0.7276 - val_accuracy: 0.5425\n",
      "Epoch 30/300\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7268 - accuracy: 0.5374 - val_loss: 0.7248 - val_accuracy: 0.5310\n",
      "Epoch 31/300\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7240 - accuracy: 0.5411 - val_loss: 0.7222 - val_accuracy: 0.5379\n",
      "Epoch 32/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7215 - accuracy: 0.5443 - val_loss: 0.7198 - val_accuracy: 0.5425\n",
      "Epoch 33/300\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7192 - accuracy: 0.5423 - val_loss: 0.7176 - val_accuracy: 0.5402\n",
      "Epoch 34/300\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7171 - accuracy: 0.5415 - val_loss: 0.7156 - val_accuracy: 0.5356\n",
      "Epoch 35/300\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7151 - accuracy: 0.5488 - val_loss: 0.7138 - val_accuracy: 0.5379\n",
      "Epoch 36/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7133 - accuracy: 0.5545 - val_loss: 0.7120 - val_accuracy: 0.5356\n",
      "Epoch 37/300\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7116 - accuracy: 0.5516 - val_loss: 0.7104 - val_accuracy: 0.5379\n",
      "Epoch 38/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7100 - accuracy: 0.5545 - val_loss: 0.7090 - val_accuracy: 0.5471\n",
      "Epoch 39/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7085 - accuracy: 0.5504 - val_loss: 0.7075 - val_accuracy: 0.5379\n",
      "Epoch 40/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7071 - accuracy: 0.5496 - val_loss: 0.7062 - val_accuracy: 0.5448\n",
      "Epoch 41/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7058 - accuracy: 0.5553 - val_loss: 0.7049 - val_accuracy: 0.5448\n",
      "Epoch 42/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7044 - accuracy: 0.5537 - val_loss: 0.7038 - val_accuracy: 0.5448\n",
      "Epoch 43/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7033 - accuracy: 0.5537 - val_loss: 0.7026 - val_accuracy: 0.5494\n",
      "Epoch 44/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.7021 - accuracy: 0.5553 - val_loss: 0.7016 - val_accuracy: 0.5471\n",
      "Epoch 45/300\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.7009 - accuracy: 0.5561 - val_loss: 0.7005 - val_accuracy: 0.5494\n",
      "Epoch 46/300\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.6999 - accuracy: 0.5545 - val_loss: 0.6995 - val_accuracy: 0.5517\n",
      "Epoch 47/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6989 - accuracy: 0.5545 - val_loss: 0.6986 - val_accuracy: 0.5494\n",
      "Epoch 48/300\n",
      "2460/2460 [==============================] - 0s 140us/sample - loss: 0.6978 - accuracy: 0.5569 - val_loss: 0.6977 - val_accuracy: 0.5448\n",
      "Epoch 49/300\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.6969 - accuracy: 0.5561 - val_loss: 0.6968 - val_accuracy: 0.5402\n",
      "Epoch 50/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6959 - accuracy: 0.5581 - val_loss: 0.6959 - val_accuracy: 0.5425\n",
      "Epoch 51/300\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6950 - accuracy: 0.5606 - val_loss: 0.6950 - val_accuracy: 0.5517\n",
      "Epoch 52/300\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.6940 - accuracy: 0.5622 - val_loss: 0.6941 - val_accuracy: 0.5471\n",
      "Epoch 53/300\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.6931 - accuracy: 0.5626 - val_loss: 0.6933 - val_accuracy: 0.5517\n",
      "Epoch 54/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.6922 - accuracy: 0.5610 - val_loss: 0.6924 - val_accuracy: 0.5494\n",
      "Epoch 55/300\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6913 - accuracy: 0.5659 - val_loss: 0.6916 - val_accuracy: 0.5471\n",
      "Epoch 56/300\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6903 - accuracy: 0.5650 - val_loss: 0.6908 - val_accuracy: 0.5448\n",
      "Epoch 57/300\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.6893 - accuracy: 0.5675 - val_loss: 0.6899 - val_accuracy: 0.5448\n",
      "Epoch 58/300\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.6884 - accuracy: 0.5667 - val_loss: 0.6891 - val_accuracy: 0.5494\n",
      "Epoch 59/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6874 - accuracy: 0.5687 - val_loss: 0.6882 - val_accuracy: 0.5517\n",
      "Epoch 60/300\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.6864 - accuracy: 0.5699 - val_loss: 0.6873 - val_accuracy: 0.5586\n",
      "Epoch 61/300\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6853 - accuracy: 0.5724 - val_loss: 0.6864 - val_accuracy: 0.5586\n",
      "Epoch 62/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6841 - accuracy: 0.5752 - val_loss: 0.6854 - val_accuracy: 0.5632\n",
      "Epoch 63/300\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6829 - accuracy: 0.5797 - val_loss: 0.6843 - val_accuracy: 0.5678\n",
      "Epoch 64/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6813 - accuracy: 0.5862 - val_loss: 0.6831 - val_accuracy: 0.5770\n",
      "Epoch 65/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6793 - accuracy: 0.5919 - val_loss: 0.6807 - val_accuracy: 0.5862\n",
      "Epoch 66/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.6745 - accuracy: 0.5947 - val_loss: 0.6750 - val_accuracy: 0.6046\n",
      "Epoch 67/300\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.6678 - accuracy: 0.6122 - val_loss: 0.6724 - val_accuracy: 0.6046\n",
      "Epoch 68/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6628 - accuracy: 0.6163 - val_loss: 0.6694 - val_accuracy: 0.6115\n",
      "Epoch 69/300\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.6577 - accuracy: 0.6264 - val_loss: 0.6658 - val_accuracy: 0.6184\n",
      "Epoch 70/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6521 - accuracy: 0.6394 - val_loss: 0.6601 - val_accuracy: 0.6414\n",
      "Epoch 71/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.6458 - accuracy: 0.6528 - val_loss: 0.6542 - val_accuracy: 0.6621\n",
      "Epoch 72/300\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.6402 - accuracy: 0.6634 - val_loss: 0.6496 - val_accuracy: 0.6644\n",
      "Epoch 73/300\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6345 - accuracy: 0.6715 - val_loss: 0.6452 - val_accuracy: 0.6667\n",
      "Epoch 74/300\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.6295 - accuracy: 0.6740 - val_loss: 0.6422 - val_accuracy: 0.6644\n",
      "Epoch 75/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.6249 - accuracy: 0.6789 - val_loss: 0.6389 - val_accuracy: 0.6690\n",
      "Epoch 76/300\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.6207 - accuracy: 0.6776 - val_loss: 0.6360 - val_accuracy: 0.6621\n",
      "Epoch 77/300\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6168 - accuracy: 0.6821 - val_loss: 0.6340 - val_accuracy: 0.6667\n",
      "Epoch 78/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6133 - accuracy: 0.6874 - val_loss: 0.6323 - val_accuracy: 0.6690\n",
      "Epoch 79/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6101 - accuracy: 0.6882 - val_loss: 0.6304 - val_accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6073 - accuracy: 0.6878 - val_loss: 0.6286 - val_accuracy: 0.6690\n",
      "Epoch 81/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.6047 - accuracy: 0.6931 - val_loss: 0.6276 - val_accuracy: 0.6690\n",
      "Epoch 82/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6024 - accuracy: 0.6911 - val_loss: 0.6267 - val_accuracy: 0.6713\n",
      "Epoch 83/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6001 - accuracy: 0.6943 - val_loss: 0.6256 - val_accuracy: 0.6713\n",
      "Epoch 84/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5981 - accuracy: 0.6976 - val_loss: 0.6248 - val_accuracy: 0.6690\n",
      "Epoch 85/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5962 - accuracy: 0.6955 - val_loss: 0.6243 - val_accuracy: 0.6690\n",
      "Epoch 86/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5944 - accuracy: 0.6967 - val_loss: 0.6239 - val_accuracy: 0.6690\n",
      "Epoch 87/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5929 - accuracy: 0.6988 - val_loss: 0.6238 - val_accuracy: 0.6713\n",
      "Epoch 88/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5912 - accuracy: 0.7008 - val_loss: 0.6232 - val_accuracy: 0.6736\n",
      "Epoch 89/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5900 - accuracy: 0.7016 - val_loss: 0.6225 - val_accuracy: 0.6690\n",
      "Epoch 90/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5886 - accuracy: 0.7004 - val_loss: 0.6227 - val_accuracy: 0.6736\n",
      "Epoch 91/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5873 - accuracy: 0.7037 - val_loss: 0.6222 - val_accuracy: 0.6736\n",
      "Epoch 92/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5862 - accuracy: 0.7020 - val_loss: 0.6218 - val_accuracy: 0.6690\n",
      "Epoch 93/300\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5852 - accuracy: 0.7045 - val_loss: 0.6220 - val_accuracy: 0.6690\n",
      "Epoch 94/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5841 - accuracy: 0.7024 - val_loss: 0.6218 - val_accuracy: 0.6713\n",
      "Epoch 95/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5833 - accuracy: 0.7020 - val_loss: 0.6218 - val_accuracy: 0.6713\n",
      "Epoch 96/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5821 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6736\n",
      "Epoch 97/300\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5815 - accuracy: 0.7037 - val_loss: 0.6221 - val_accuracy: 0.6736\n",
      "Epoch 98/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5805 - accuracy: 0.7053 - val_loss: 0.6219 - val_accuracy: 0.6759\n",
      "Epoch 99/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5798 - accuracy: 0.7057 - val_loss: 0.6218 - val_accuracy: 0.6759\n",
      "Epoch 100/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5790 - accuracy: 0.7045 - val_loss: 0.6220 - val_accuracy: 0.6759\n",
      "Epoch 101/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5783 - accuracy: 0.7053 - val_loss: 0.6217 - val_accuracy: 0.6736\n",
      "Epoch 102/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5777 - accuracy: 0.7065 - val_loss: 0.6215 - val_accuracy: 0.6713\n",
      "Epoch 103/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5769 - accuracy: 0.7053 - val_loss: 0.6219 - val_accuracy: 0.6759\n",
      "Epoch 104/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5764 - accuracy: 0.7057 - val_loss: 0.6215 - val_accuracy: 0.6736\n",
      "Epoch 105/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5758 - accuracy: 0.7081 - val_loss: 0.6220 - val_accuracy: 0.6759\n",
      "Epoch 106/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5751 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6782\n",
      "Epoch 107/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5746 - accuracy: 0.7089 - val_loss: 0.6217 - val_accuracy: 0.6805\n",
      "Epoch 108/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5740 - accuracy: 0.7061 - val_loss: 0.6220 - val_accuracy: 0.6782\n",
      "Epoch 109/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5734 - accuracy: 0.7069 - val_loss: 0.6221 - val_accuracy: 0.6805\n",
      "Epoch 110/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5729 - accuracy: 0.7069 - val_loss: 0.6215 - val_accuracy: 0.6759\n",
      "Epoch 111/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5723 - accuracy: 0.7073 - val_loss: 0.6219 - val_accuracy: 0.6828\n",
      "Epoch 112/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5719 - accuracy: 0.7106 - val_loss: 0.6221 - val_accuracy: 0.6805\n",
      "Epoch 113/300\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5712 - accuracy: 0.7102 - val_loss: 0.6223 - val_accuracy: 0.6782\n",
      "Epoch 114/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5708 - accuracy: 0.7114 - val_loss: 0.6217 - val_accuracy: 0.6805\n",
      "Epoch 115/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5705 - accuracy: 0.7110 - val_loss: 0.6220 - val_accuracy: 0.6782\n",
      "Epoch 116/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5697 - accuracy: 0.7110 - val_loss: 0.6219 - val_accuracy: 0.6736\n",
      "Epoch 117/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5693 - accuracy: 0.7134 - val_loss: 0.6222 - val_accuracy: 0.6759\n",
      "Epoch 118/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5687 - accuracy: 0.7118 - val_loss: 0.6220 - val_accuracy: 0.6782\n",
      "Epoch 119/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5682 - accuracy: 0.7134 - val_loss: 0.6217 - val_accuracy: 0.6805\n",
      "Epoch 120/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5677 - accuracy: 0.7146 - val_loss: 0.6212 - val_accuracy: 0.6736\n",
      "Epoch 121/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5671 - accuracy: 0.7134 - val_loss: 0.6215 - val_accuracy: 0.6782\n",
      "Epoch 122/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5666 - accuracy: 0.7138 - val_loss: 0.6215 - val_accuracy: 0.6759\n",
      "Epoch 123/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5659 - accuracy: 0.7134 - val_loss: 0.6210 - val_accuracy: 0.6782\n",
      "Epoch 124/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5655 - accuracy: 0.7130 - val_loss: 0.6213 - val_accuracy: 0.6828\n",
      "Epoch 125/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5649 - accuracy: 0.7126 - val_loss: 0.6215 - val_accuracy: 0.6828\n",
      "Epoch 126/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5643 - accuracy: 0.7154 - val_loss: 0.6210 - val_accuracy: 0.6782\n",
      "Epoch 127/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5637 - accuracy: 0.7150 - val_loss: 0.6211 - val_accuracy: 0.6782\n",
      "Epoch 128/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5631 - accuracy: 0.7150 - val_loss: 0.6207 - val_accuracy: 0.6736\n",
      "Epoch 129/300\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5627 - accuracy: 0.7163 - val_loss: 0.6210 - val_accuracy: 0.6782\n",
      "Epoch 130/300\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5620 - accuracy: 0.7179 - val_loss: 0.6209 - val_accuracy: 0.6759\n",
      "Epoch 131/300\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5615 - accuracy: 0.7175 - val_loss: 0.6208 - val_accuracy: 0.6759\n",
      "Epoch 132/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5610 - accuracy: 0.7154 - val_loss: 0.6206 - val_accuracy: 0.6736\n",
      "Epoch 133/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5606 - accuracy: 0.7159 - val_loss: 0.6210 - val_accuracy: 0.6828\n",
      "Epoch 134/300\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5600 - accuracy: 0.7183 - val_loss: 0.6207 - val_accuracy: 0.6782\n",
      "Epoch 135/300\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5592 - accuracy: 0.7167 - val_loss: 0.6209 - val_accuracy: 0.6805\n",
      "Epoch 136/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5587 - accuracy: 0.7175 - val_loss: 0.6214 - val_accuracy: 0.6805\n",
      "Epoch 137/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5582 - accuracy: 0.7187 - val_loss: 0.6208 - val_accuracy: 0.6782\n",
      "Epoch 138/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5575 - accuracy: 0.7187 - val_loss: 0.6211 - val_accuracy: 0.6828\n",
      "Epoch 139/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5571 - accuracy: 0.7195 - val_loss: 0.6210 - val_accuracy: 0.6805\n",
      "Epoch 140/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5565 - accuracy: 0.7175 - val_loss: 0.6208 - val_accuracy: 0.6782\n",
      "Epoch 141/300\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5556 - accuracy: 0.7203 - val_loss: 0.6211 - val_accuracy: 0.6851\n",
      "Epoch 142/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5554 - accuracy: 0.7187 - val_loss: 0.6212 - val_accuracy: 0.6828\n",
      "Epoch 143/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5546 - accuracy: 0.7195 - val_loss: 0.6217 - val_accuracy: 0.6897\n",
      "Epoch 144/300\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5542 - accuracy: 0.7199 - val_loss: 0.6216 - val_accuracy: 0.6920\n",
      "Epoch 145/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5534 - accuracy: 0.7220 - val_loss: 0.6215 - val_accuracy: 0.6874\n",
      "Epoch 146/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5530 - accuracy: 0.7240 - val_loss: 0.6220 - val_accuracy: 0.6920\n",
      "Epoch 147/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5524 - accuracy: 0.7220 - val_loss: 0.6213 - val_accuracy: 0.6736\n",
      "Epoch 148/300\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5517 - accuracy: 0.7224 - val_loss: 0.6215 - val_accuracy: 0.6851\n",
      "Epoch 149/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5510 - accuracy: 0.7211 - val_loss: 0.6222 - val_accuracy: 0.6782\n",
      "Epoch 150/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5506 - accuracy: 0.7232 - val_loss: 0.6221 - val_accuracy: 0.6828\n",
      "Epoch 151/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5499 - accuracy: 0.7244 - val_loss: 0.6220 - val_accuracy: 0.6736\n",
      "Epoch 152/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5493 - accuracy: 0.7236 - val_loss: 0.6232 - val_accuracy: 0.6851\n",
      "Epoch 153/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5488 - accuracy: 0.7240 - val_loss: 0.6234 - val_accuracy: 0.6828\n",
      "Epoch 154/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5479 - accuracy: 0.7220 - val_loss: 0.6230 - val_accuracy: 0.6805\n",
      "Epoch 155/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5475 - accuracy: 0.7232 - val_loss: 0.6231 - val_accuracy: 0.6736\n",
      "Epoch 156/300\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5467 - accuracy: 0.7228 - val_loss: 0.6235 - val_accuracy: 0.6759\n",
      "Epoch 157/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5462 - accuracy: 0.7228 - val_loss: 0.6239 - val_accuracy: 0.6759\n",
      "Epoch 158/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5455 - accuracy: 0.7232 - val_loss: 0.6239 - val_accuracy: 0.6759\n",
      "Epoch 159/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5448 - accuracy: 0.7264 - val_loss: 0.6240 - val_accuracy: 0.6736\n",
      "Epoch 160/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5442 - accuracy: 0.7244 - val_loss: 0.6246 - val_accuracy: 0.6736\n",
      "Epoch 161/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5435 - accuracy: 0.7244 - val_loss: 0.6253 - val_accuracy: 0.6782\n",
      "Epoch 162/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5430 - accuracy: 0.7285 - val_loss: 0.6259 - val_accuracy: 0.6736\n",
      "Epoch 163/300\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5423 - accuracy: 0.7240 - val_loss: 0.6254 - val_accuracy: 0.6759\n",
      "Epoch 164/300\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5416 - accuracy: 0.7276 - val_loss: 0.6259 - val_accuracy: 0.6736\n",
      "Epoch 165/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5410 - accuracy: 0.7285 - val_loss: 0.6258 - val_accuracy: 0.6759\n",
      "Epoch 166/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5402 - accuracy: 0.7297 - val_loss: 0.6268 - val_accuracy: 0.6690\n",
      "Epoch 167/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5396 - accuracy: 0.7285 - val_loss: 0.6266 - val_accuracy: 0.6690\n",
      "Epoch 168/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5388 - accuracy: 0.7333 - val_loss: 0.6274 - val_accuracy: 0.6690\n",
      "Epoch 169/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5382 - accuracy: 0.7285 - val_loss: 0.6279 - val_accuracy: 0.6690\n",
      "Epoch 170/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5377 - accuracy: 0.7280 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
      "Epoch 171/300\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5367 - accuracy: 0.7313 - val_loss: 0.6281 - val_accuracy: 0.6690\n",
      "Epoch 172/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5360 - accuracy: 0.7329 - val_loss: 0.6289 - val_accuracy: 0.6667\n",
      "Epoch 173/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5354 - accuracy: 0.7309 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
      "Epoch 174/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5346 - accuracy: 0.7341 - val_loss: 0.6298 - val_accuracy: 0.6621\n",
      "Epoch 175/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5337 - accuracy: 0.7358 - val_loss: 0.6300 - val_accuracy: 0.6621\n",
      "Epoch 176/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5331 - accuracy: 0.7337 - val_loss: 0.6311 - val_accuracy: 0.6667\n",
      "Epoch 177/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5320 - accuracy: 0.7374 - val_loss: 0.6312 - val_accuracy: 0.6644\n",
      "Epoch 178/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5313 - accuracy: 0.7378 - val_loss: 0.6318 - val_accuracy: 0.6598\n",
      "Epoch 179/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5304 - accuracy: 0.7402 - val_loss: 0.6329 - val_accuracy: 0.6621\n",
      "Epoch 180/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5295 - accuracy: 0.7390 - val_loss: 0.6333 - val_accuracy: 0.6598\n",
      "Epoch 181/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5286 - accuracy: 0.7394 - val_loss: 0.6345 - val_accuracy: 0.6575\n",
      "Epoch 182/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5275 - accuracy: 0.7394 - val_loss: 0.6355 - val_accuracy: 0.6621\n",
      "Epoch 183/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5266 - accuracy: 0.7394 - val_loss: 0.6361 - val_accuracy: 0.6552\n",
      "Epoch 184/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5255 - accuracy: 0.7402 - val_loss: 0.6369 - val_accuracy: 0.6552\n",
      "Epoch 185/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5247 - accuracy: 0.7411 - val_loss: 0.6380 - val_accuracy: 0.6529\n",
      "Epoch 186/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5235 - accuracy: 0.7423 - val_loss: 0.6377 - val_accuracy: 0.6506\n",
      "Epoch 187/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5223 - accuracy: 0.7415 - val_loss: 0.6388 - val_accuracy: 0.6506\n",
      "Epoch 188/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5213 - accuracy: 0.7407 - val_loss: 0.6395 - val_accuracy: 0.6506\n",
      "Epoch 189/300\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5202 - accuracy: 0.7439 - val_loss: 0.6404 - val_accuracy: 0.6483\n",
      "Epoch 190/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5190 - accuracy: 0.7435 - val_loss: 0.6409 - val_accuracy: 0.6414\n",
      "Epoch 191/300\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5180 - accuracy: 0.7427 - val_loss: 0.6421 - val_accuracy: 0.6437\n",
      "Epoch 192/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5167 - accuracy: 0.7431 - val_loss: 0.6426 - val_accuracy: 0.6414\n",
      "Epoch 193/300\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5157 - accuracy: 0.7451 - val_loss: 0.6435 - val_accuracy: 0.6414\n",
      "Epoch 194/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5144 - accuracy: 0.7476 - val_loss: 0.6447 - val_accuracy: 0.6483\n",
      "Epoch 195/300\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5133 - accuracy: 0.7467 - val_loss: 0.6458 - val_accuracy: 0.6391\n",
      "Epoch 196/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5122 - accuracy: 0.7496 - val_loss: 0.6464 - val_accuracy: 0.6414\n",
      "Epoch 197/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5111 - accuracy: 0.7496 - val_loss: 0.6470 - val_accuracy: 0.6391\n",
      "Epoch 198/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5097 - accuracy: 0.7545 - val_loss: 0.6480 - val_accuracy: 0.6391\n",
      "Epoch 199/300\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5087 - accuracy: 0.7528 - val_loss: 0.6480 - val_accuracy: 0.6414\n",
      "Epoch 200/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5074 - accuracy: 0.7504 - val_loss: 0.6491 - val_accuracy: 0.6414\n",
      "Epoch 201/300\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.5062 - accuracy: 0.7561 - val_loss: 0.6504 - val_accuracy: 0.6391\n",
      "Epoch 202/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5049 - accuracy: 0.7557 - val_loss: 0.6509 - val_accuracy: 0.6391\n",
      "Epoch 203/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5037 - accuracy: 0.7545 - val_loss: 0.6522 - val_accuracy: 0.6322\n",
      "Epoch 204/300\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5027 - accuracy: 0.7545 - val_loss: 0.6534 - val_accuracy: 0.6345\n",
      "Epoch 205/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5014 - accuracy: 0.7573 - val_loss: 0.6539 - val_accuracy: 0.6414\n",
      "Epoch 206/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5001 - accuracy: 0.7602 - val_loss: 0.6556 - val_accuracy: 0.6345\n",
      "Epoch 207/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4988 - accuracy: 0.7602 - val_loss: 0.6564 - val_accuracy: 0.6391\n",
      "Epoch 208/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4975 - accuracy: 0.7626 - val_loss: 0.6577 - val_accuracy: 0.6345\n",
      "Epoch 209/300\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4963 - accuracy: 0.7606 - val_loss: 0.6584 - val_accuracy: 0.6345\n",
      "Epoch 210/300\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4952 - accuracy: 0.7642 - val_loss: 0.6592 - val_accuracy: 0.6368\n",
      "Epoch 211/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4937 - accuracy: 0.7634 - val_loss: 0.6609 - val_accuracy: 0.6368\n",
      "Epoch 212/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4925 - accuracy: 0.7622 - val_loss: 0.6630 - val_accuracy: 0.6368\n",
      "Epoch 213/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4913 - accuracy: 0.7634 - val_loss: 0.6632 - val_accuracy: 0.6345\n",
      "Epoch 214/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4904 - accuracy: 0.7650 - val_loss: 0.6636 - val_accuracy: 0.6414\n",
      "Epoch 215/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4888 - accuracy: 0.7671 - val_loss: 0.6655 - val_accuracy: 0.6414\n",
      "Epoch 216/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4875 - accuracy: 0.7675 - val_loss: 0.6667 - val_accuracy: 0.6460\n",
      "Epoch 217/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4863 - accuracy: 0.7703 - val_loss: 0.6671 - val_accuracy: 0.6460\n",
      "Epoch 218/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4849 - accuracy: 0.7703 - val_loss: 0.6702 - val_accuracy: 0.6414\n",
      "Epoch 219/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4837 - accuracy: 0.7715 - val_loss: 0.6710 - val_accuracy: 0.6483\n",
      "Epoch 220/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4825 - accuracy: 0.7728 - val_loss: 0.6718 - val_accuracy: 0.6460\n",
      "Epoch 221/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4812 - accuracy: 0.7720 - val_loss: 0.6733 - val_accuracy: 0.6414\n",
      "Epoch 222/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4800 - accuracy: 0.7732 - val_loss: 0.6741 - val_accuracy: 0.6414\n",
      "Epoch 223/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4786 - accuracy: 0.7768 - val_loss: 0.6759 - val_accuracy: 0.6368\n",
      "Epoch 224/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4772 - accuracy: 0.7760 - val_loss: 0.6767 - val_accuracy: 0.6460\n",
      "Epoch 225/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4759 - accuracy: 0.7768 - val_loss: 0.6784 - val_accuracy: 0.6414\n",
      "Epoch 226/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4746 - accuracy: 0.7793 - val_loss: 0.6788 - val_accuracy: 0.6529\n",
      "Epoch 227/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4734 - accuracy: 0.7789 - val_loss: 0.6804 - val_accuracy: 0.6414\n",
      "Epoch 228/300\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.4721 - accuracy: 0.7780 - val_loss: 0.6826 - val_accuracy: 0.6391\n",
      "Epoch 229/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4706 - accuracy: 0.7789 - val_loss: 0.6842 - val_accuracy: 0.6391\n",
      "Epoch 230/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4694 - accuracy: 0.7821 - val_loss: 0.6852 - val_accuracy: 0.6414\n",
      "Epoch 231/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4680 - accuracy: 0.7809 - val_loss: 0.6862 - val_accuracy: 0.6414\n",
      "Epoch 232/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4667 - accuracy: 0.7797 - val_loss: 0.6875 - val_accuracy: 0.6414\n",
      "Epoch 233/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4654 - accuracy: 0.7817 - val_loss: 0.6898 - val_accuracy: 0.6391\n",
      "Epoch 234/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4642 - accuracy: 0.7829 - val_loss: 0.6907 - val_accuracy: 0.6414\n",
      "Epoch 235/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4629 - accuracy: 0.7854 - val_loss: 0.6926 - val_accuracy: 0.6437\n",
      "Epoch 236/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4615 - accuracy: 0.7866 - val_loss: 0.6937 - val_accuracy: 0.6414\n",
      "Epoch 237/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4601 - accuracy: 0.7907 - val_loss: 0.6949 - val_accuracy: 0.6437\n",
      "Epoch 238/300\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4588 - accuracy: 0.7915 - val_loss: 0.6961 - val_accuracy: 0.6414\n",
      "Epoch 239/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4575 - accuracy: 0.7931 - val_loss: 0.6978 - val_accuracy: 0.6437\n",
      "Epoch 240/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4561 - accuracy: 0.7911 - val_loss: 0.6994 - val_accuracy: 0.6368\n",
      "Epoch 241/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4546 - accuracy: 0.7972 - val_loss: 0.7019 - val_accuracy: 0.6437\n",
      "Epoch 242/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4533 - accuracy: 0.7963 - val_loss: 0.7031 - val_accuracy: 0.6483\n",
      "Epoch 243/300\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4519 - accuracy: 0.7972 - val_loss: 0.7041 - val_accuracy: 0.6460\n",
      "Epoch 244/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4505 - accuracy: 0.8004 - val_loss: 0.7057 - val_accuracy: 0.6460\n",
      "Epoch 245/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4490 - accuracy: 0.7984 - val_loss: 0.7078 - val_accuracy: 0.6483\n",
      "Epoch 246/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4478 - accuracy: 0.8004 - val_loss: 0.7124 - val_accuracy: 0.6437\n",
      "Epoch 247/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4464 - accuracy: 0.8008 - val_loss: 0.7117 - val_accuracy: 0.6460\n",
      "Epoch 248/300\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4448 - accuracy: 0.8033 - val_loss: 0.7134 - val_accuracy: 0.6460\n",
      "Epoch 249/300\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.4436 - accuracy: 0.8049 - val_loss: 0.7149 - val_accuracy: 0.6483\n",
      "Epoch 250/300\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4421 - accuracy: 0.8065 - val_loss: 0.7164 - val_accuracy: 0.6391\n",
      "Epoch 251/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4409 - accuracy: 0.8073 - val_loss: 0.7195 - val_accuracy: 0.6437\n",
      "Epoch 252/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.4392 - accuracy: 0.8085 - val_loss: 0.7200 - val_accuracy: 0.6368\n",
      "Epoch 253/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4378 - accuracy: 0.8118 - val_loss: 0.7221 - val_accuracy: 0.6391\n",
      "Epoch 254/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4364 - accuracy: 0.8081 - val_loss: 0.7245 - val_accuracy: 0.6391\n",
      "Epoch 255/300\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4350 - accuracy: 0.8114 - val_loss: 0.7263 - val_accuracy: 0.6391\n",
      "Epoch 256/300\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4335 - accuracy: 0.8126 - val_loss: 0.7281 - val_accuracy: 0.6391\n",
      "Epoch 257/300\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4322 - accuracy: 0.8138 - val_loss: 0.7297 - val_accuracy: 0.6391\n",
      "Epoch 258/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4308 - accuracy: 0.8122 - val_loss: 0.7312 - val_accuracy: 0.6391\n",
      "Epoch 259/300\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4293 - accuracy: 0.8154 - val_loss: 0.7341 - val_accuracy: 0.6414\n",
      "Epoch 260/300\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4280 - accuracy: 0.8150 - val_loss: 0.7345 - val_accuracy: 0.6391\n",
      "Epoch 261/300\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4264 - accuracy: 0.8150 - val_loss: 0.7366 - val_accuracy: 0.6391\n",
      "Epoch 262/300\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4249 - accuracy: 0.8171 - val_loss: 0.7405 - val_accuracy: 0.6391\n",
      "Epoch 263/300\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.4234 - accuracy: 0.8163 - val_loss: 0.7413 - val_accuracy: 0.6368\n",
      "Epoch 264/300\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4219 - accuracy: 0.8171 - val_loss: 0.7433 - val_accuracy: 0.6368\n",
      "Epoch 265/300\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.4207 - accuracy: 0.8163 - val_loss: 0.7473 - val_accuracy: 0.6391\n",
      "Epoch 266/300\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.4193 - accuracy: 0.8171 - val_loss: 0.7493 - val_accuracy: 0.6414\n",
      "Epoch 267/300\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4178 - accuracy: 0.8167 - val_loss: 0.7505 - val_accuracy: 0.6391\n",
      "Epoch 268/300\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4163 - accuracy: 0.8203 - val_loss: 0.7533 - val_accuracy: 0.6368\n",
      "Epoch 269/300\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4149 - accuracy: 0.8232 - val_loss: 0.7545 - val_accuracy: 0.6368\n",
      "Epoch 270/300\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4135 - accuracy: 0.8167 - val_loss: 0.7565 - val_accuracy: 0.6391\n",
      "Epoch 271/300\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.4120 - accuracy: 0.8224 - val_loss: 0.7587 - val_accuracy: 0.6368\n",
      "Epoch 272/300\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.4104 - accuracy: 0.8215 - val_loss: 0.7606 - val_accuracy: 0.6368\n",
      "Epoch 273/300\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4092 - accuracy: 0.8203 - val_loss: 0.7634 - val_accuracy: 0.6368\n",
      "Epoch 274/300\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4076 - accuracy: 0.8220 - val_loss: 0.7660 - val_accuracy: 0.6322\n",
      "Epoch 275/300\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4063 - accuracy: 0.8248 - val_loss: 0.7677 - val_accuracy: 0.6345\n",
      "Epoch 276/300\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4050 - accuracy: 0.8252 - val_loss: 0.7689 - val_accuracy: 0.6322\n",
      "Epoch 277/300\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.4033 - accuracy: 0.8264 - val_loss: 0.7739 - val_accuracy: 0.6299\n",
      "Epoch 278/300\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.4021 - accuracy: 0.8256 - val_loss: 0.7764 - val_accuracy: 0.6299\n",
      "Epoch 279/300\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4004 - accuracy: 0.8305 - val_loss: 0.7779 - val_accuracy: 0.6299\n",
      "Epoch 280/300\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3990 - accuracy: 0.8293 - val_loss: 0.7794 - val_accuracy: 0.6299\n",
      "Epoch 281/300\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.3979 - accuracy: 0.8268 - val_loss: 0.7815 - val_accuracy: 0.6299\n",
      "Epoch 282/300\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3963 - accuracy: 0.8301 - val_loss: 0.7830 - val_accuracy: 0.6299\n",
      "Epoch 283/300\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.3951 - accuracy: 0.8313 - val_loss: 0.7875 - val_accuracy: 0.6345\n",
      "Epoch 284/300\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.3940 - accuracy: 0.8317 - val_loss: 0.7893 - val_accuracy: 0.6368\n",
      "Epoch 285/300\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.3920 - accuracy: 0.8305 - val_loss: 0.7908 - val_accuracy: 0.6276\n",
      "Epoch 286/300\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3906 - accuracy: 0.8337 - val_loss: 0.7950 - val_accuracy: 0.6345\n",
      "Epoch 287/300\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3892 - accuracy: 0.8309 - val_loss: 0.7974 - val_accuracy: 0.6368\n",
      "Epoch 288/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3879 - accuracy: 0.8337 - val_loss: 0.7990 - val_accuracy: 0.6391\n",
      "Epoch 289/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3865 - accuracy: 0.8346 - val_loss: 0.8034 - val_accuracy: 0.6345\n",
      "Epoch 290/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3854 - accuracy: 0.8358 - val_loss: 0.8040 - val_accuracy: 0.6368\n",
      "Epoch 291/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3839 - accuracy: 0.8354 - val_loss: 0.8062 - val_accuracy: 0.6368\n",
      "Epoch 292/300\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3823 - accuracy: 0.8386 - val_loss: 0.8083 - val_accuracy: 0.6391\n",
      "Epoch 293/300\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3809 - accuracy: 0.8370 - val_loss: 0.8106 - val_accuracy: 0.6391\n",
      "Epoch 294/300\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3798 - accuracy: 0.8374 - val_loss: 0.8142 - val_accuracy: 0.6345\n",
      "Epoch 295/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3781 - accuracy: 0.8386 - val_loss: 0.8157 - val_accuracy: 0.6437\n",
      "Epoch 296/300\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3766 - accuracy: 0.8382 - val_loss: 0.8205 - val_accuracy: 0.6391\n",
      "Epoch 297/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3753 - accuracy: 0.8382 - val_loss: 0.8216 - val_accuracy: 0.6414\n",
      "Epoch 298/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3742 - accuracy: 0.8419 - val_loss: 0.8245 - val_accuracy: 0.6368\n",
      "Epoch 299/300\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.3725 - accuracy: 0.8382 - val_loss: 0.8266 - val_accuracy: 0.6368\n",
      "Epoch 300/300\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3713 - accuracy: 0.8431 - val_loss: 0.8297 - val_accuracy: 0.6345\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epoch = 300\n",
    "history = model.fit(X_train, y_train, epochs = epoch, verbose = 1, validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2895/2895 [==============================] - 0s 41us/sample - loss: 0.4372 - accuracy: 0.8114\n",
      "The accuracy of the model is: 0.811398983001709\n",
      "The loss of the model is: 0.4372\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "model_eval = model.evaluate(X_train, y_train)\n",
    "print(f\"The accuracy of the model is: {model_eval[1]}\")\n",
    "print(f\"The loss of the model is: {round(model_eval[0], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6588397790055248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = history.history['val_loss']\n",
    "loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgval = sum(history.history['loss']) / len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6078234545300157"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'epochs': 300, 'steps': 77, 'samples': 2460, 'verbose': 0, 'do_validation': True, 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}\n"
     ]
    }
   ],
   "source": [
    "print(history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chief_worker_only', '_keras_api_names', '_keras_api_names_v1', 'epoch', 'history', 'model', 'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end', 'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin', 'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end', 'on_test_begin', 'on_test_end', 'on_train_batch_begin', 'on_train_batch_end', 'on_train_begin', 'on_train_end', 'params', 'set_model', 'set_params', 'validation_data']\n"
     ]
    }
   ],
   "source": [
    "print(dir(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(0, epoch)\n",
    "plt.plot(epochs, loss_train, 'g', label = 'Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label = 'Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['accuracy']\n",
    "loss_val = history.history['val_accuracy']\n",
    "epochs = range(0, epoch)\n",
    "plt.plot(epochs, loss_train, 'g', label = 'Training Accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label = 'Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer(optimize, learn):\n",
    "    \"\"\"Used to select an optimizer and learning rate. \"\"\"\n",
    "    optimizer_dict = {'Adam': tf.optimizers.Adam(learning_rate = learn),\n",
    "                      'SGD': tf.optimizers.SGD(learning_rate = learn),\n",
    "                      'Adadelta': tf.optimizers.Adadelta(learning_rate = learn),\n",
    "                      'RMSprop': tf.optimizers.RMSprop(learning_rate = learn),\n",
    "                      'Adagrad': tf.optimizers.Adagrad(learning_rate = learn),\n",
    "                      'Adamax': tf.optimizers.Adamax(learning_rate = learn),\n",
    "                      'Nadam': tf.optimizers.Nadam(learning_rate = learn),\n",
    "                      'Ftrl': tf.optimizers.Ftrl(learning_rate = learn),\n",
    "                      }\n",
    "    x = optimizer_dict[optimize]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 151us/sample - loss: 3.5694 - accuracy: 0.0146 - val_loss: 3.4758 - val_accuracy: 0.0322\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.3692 - accuracy: 0.1220 - val_loss: 3.2758 - val_accuracy: 0.2023\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 3.1689 - accuracy: 0.3467 - val_loss: 3.0716 - val_accuracy: 0.4897\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 2.9617 - accuracy: 0.5102 - val_loss: 2.8575 - val_accuracy: 0.5241\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.7441 - accuracy: 0.5285 - val_loss: 2.6343 - val_accuracy: 0.5264\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 2.5185 - accuracy: 0.5333 - val_loss: 2.4049 - val_accuracy: 0.5310\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 2.2915 - accuracy: 0.5333 - val_loss: 2.1792 - val_accuracy: 0.5264\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.0715 - accuracy: 0.5378 - val_loss: 1.9659 - val_accuracy: 0.5310\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.8659 - accuracy: 0.5419 - val_loss: 1.7692 - val_accuracy: 0.5356\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 1.6790 - accuracy: 0.5459 - val_loss: 1.5939 - val_accuracy: 0.5379\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 1.5131 - accuracy: 0.5512 - val_loss: 1.4394 - val_accuracy: 0.5379\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 1.3688 - accuracy: 0.5549 - val_loss: 1.3069 - val_accuracy: 0.5356\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 1.2457 - accuracy: 0.5565 - val_loss: 1.1947 - val_accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 1.1421 - accuracy: 0.5642 - val_loss: 1.1014 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.0567 - accuracy: 0.5699 - val_loss: 1.0248 - val_accuracy: 0.5425\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.9866 - accuracy: 0.5768 - val_loss: 0.9627 - val_accuracy: 0.5540\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.9298 - accuracy: 0.5866 - val_loss: 0.9120 - val_accuracy: 0.5747\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.8836 - accuracy: 0.5894 - val_loss: 0.8712 - val_accuracy: 0.5931\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8458 - accuracy: 0.5943 - val_loss: 0.8375 - val_accuracy: 0.6023\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8147 - accuracy: 0.5988 - val_loss: 0.8099 - val_accuracy: 0.5954\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7888 - accuracy: 0.6081 - val_loss: 0.7869 - val_accuracy: 0.5954\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7672 - accuracy: 0.6195 - val_loss: 0.7672 - val_accuracy: 0.6092\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7490 - accuracy: 0.6224 - val_loss: 0.7508 - val_accuracy: 0.6115\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.7331 - accuracy: 0.6321 - val_loss: 0.7366 - val_accuracy: 0.6230\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.7195 - accuracy: 0.6419 - val_loss: 0.7242 - val_accuracy: 0.6253\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.7075 - accuracy: 0.6419 - val_loss: 0.7133 - val_accuracy: 0.6368\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6969 - accuracy: 0.6472 - val_loss: 0.7038 - val_accuracy: 0.6368\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6873 - accuracy: 0.6504 - val_loss: 0.6953 - val_accuracy: 0.6437\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.6790 - accuracy: 0.6541 - val_loss: 0.6876 - val_accuracy: 0.6529\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6711 - accuracy: 0.6581 - val_loss: 0.6806 - val_accuracy: 0.6552\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6643 - accuracy: 0.6581 - val_loss: 0.6744 - val_accuracy: 0.6598\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6579 - accuracy: 0.6650 - val_loss: 0.6689 - val_accuracy: 0.6621\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.6520 - accuracy: 0.6691 - val_loss: 0.6635 - val_accuracy: 0.6575\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6464 - accuracy: 0.6695 - val_loss: 0.6586 - val_accuracy: 0.6690\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6415 - accuracy: 0.6756 - val_loss: 0.6544 - val_accuracy: 0.6759\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6367 - accuracy: 0.6740 - val_loss: 0.6502 - val_accuracy: 0.6759\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.6323 - accuracy: 0.6780 - val_loss: 0.6464 - val_accuracy: 0.6759\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6283 - accuracy: 0.6780 - val_loss: 0.6429 - val_accuracy: 0.6736\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6246 - accuracy: 0.6785 - val_loss: 0.6398 - val_accuracy: 0.6759\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6210 - accuracy: 0.6846 - val_loss: 0.6369 - val_accuracy: 0.6851\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.6176 - accuracy: 0.6846 - val_loss: 0.6342 - val_accuracy: 0.6851\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.6146 - accuracy: 0.6890 - val_loss: 0.6315 - val_accuracy: 0.6851\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6118 - accuracy: 0.6878 - val_loss: 0.6292 - val_accuracy: 0.6874\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.6089 - accuracy: 0.6858 - val_loss: 0.6270 - val_accuracy: 0.6851\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6063 - accuracy: 0.6907 - val_loss: 0.6251 - val_accuracy: 0.6782\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.6037 - accuracy: 0.6902 - val_loss: 0.6231 - val_accuracy: 0.6782\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.6014 - accuracy: 0.6919 - val_loss: 0.6213 - val_accuracy: 0.6828\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5994 - accuracy: 0.6935 - val_loss: 0.6198 - val_accuracy: 0.6690\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5972 - accuracy: 0.6939 - val_loss: 0.6184 - val_accuracy: 0.6805\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5955 - accuracy: 0.6947 - val_loss: 0.6169 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5935 - accuracy: 0.6967 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5918 - accuracy: 0.6972 - val_loss: 0.6144 - val_accuracy: 0.6690\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5902 - accuracy: 0.6984 - val_loss: 0.6133 - val_accuracy: 0.6644\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5887 - accuracy: 0.7016 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5875 - accuracy: 0.6984 - val_loss: 0.6114 - val_accuracy: 0.6736\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5859 - accuracy: 0.7004 - val_loss: 0.6108 - val_accuracy: 0.6713\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5847 - accuracy: 0.7012 - val_loss: 0.6098 - val_accuracy: 0.6713\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5834 - accuracy: 0.7053 - val_loss: 0.6090 - val_accuracy: 0.6759\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5823 - accuracy: 0.7024 - val_loss: 0.6086 - val_accuracy: 0.6690\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5812 - accuracy: 0.7041 - val_loss: 0.6079 - val_accuracy: 0.6736\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5801 - accuracy: 0.7033 - val_loss: 0.6076 - val_accuracy: 0.6713\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5791 - accuracy: 0.7008 - val_loss: 0.6071 - val_accuracy: 0.6736\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5782 - accuracy: 0.7053 - val_loss: 0.6065 - val_accuracy: 0.6759\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5775 - accuracy: 0.7053 - val_loss: 0.6065 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5764 - accuracy: 0.7065 - val_loss: 0.6059 - val_accuracy: 0.6736\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5755 - accuracy: 0.7053 - val_loss: 0.6053 - val_accuracy: 0.6759\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5748 - accuracy: 0.7081 - val_loss: 0.6050 - val_accuracy: 0.6759\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5741 - accuracy: 0.7057 - val_loss: 0.6049 - val_accuracy: 0.6690\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5735 - accuracy: 0.7069 - val_loss: 0.6045 - val_accuracy: 0.6713\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5726 - accuracy: 0.7077 - val_loss: 0.6045 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5721 - accuracy: 0.7077 - val_loss: 0.6041 - val_accuracy: 0.6736\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5713 - accuracy: 0.7077 - val_loss: 0.6039 - val_accuracy: 0.6713\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5708 - accuracy: 0.7081 - val_loss: 0.6038 - val_accuracy: 0.6690\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5702 - accuracy: 0.7110 - val_loss: 0.6036 - val_accuracy: 0.6713\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5698 - accuracy: 0.7085 - val_loss: 0.6035 - val_accuracy: 0.6713\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5691 - accuracy: 0.7065 - val_loss: 0.6034 - val_accuracy: 0.6736\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5686 - accuracy: 0.7098 - val_loss: 0.6033 - val_accuracy: 0.6713\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5681 - accuracy: 0.7093 - val_loss: 0.6030 - val_accuracy: 0.6736\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5679 - accuracy: 0.7102 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5671 - accuracy: 0.7110 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5666 - accuracy: 0.7098 - val_loss: 0.6029 - val_accuracy: 0.6713\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.5661 - accuracy: 0.7110 - val_loss: 0.6032 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 114us/sample - loss: 0.5656 - accuracy: 0.7093 - val_loss: 0.6029 - val_accuracy: 0.6713\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5651 - accuracy: 0.7106 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5647 - accuracy: 0.7122 - val_loss: 0.6026 - val_accuracy: 0.6690\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5645 - accuracy: 0.7130 - val_loss: 0.6027 - val_accuracy: 0.6690\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5639 - accuracy: 0.7110 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5637 - accuracy: 0.7110 - val_loss: 0.6028 - val_accuracy: 0.6713\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5630 - accuracy: 0.7110 - val_loss: 0.6029 - val_accuracy: 0.6713\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5627 - accuracy: 0.7122 - val_loss: 0.6027 - val_accuracy: 0.6621\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5624 - accuracy: 0.7126 - val_loss: 0.6026 - val_accuracy: 0.6644\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5620 - accuracy: 0.7089 - val_loss: 0.6028 - val_accuracy: 0.6713\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5616 - accuracy: 0.7134 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5613 - accuracy: 0.7126 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5611 - accuracy: 0.7098 - val_loss: 0.6027 - val_accuracy: 0.6690\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5604 - accuracy: 0.7130 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5602 - accuracy: 0.7122 - val_loss: 0.6027 - val_accuracy: 0.6713\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5599 - accuracy: 0.7114 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5595 - accuracy: 0.7159 - val_loss: 0.6028 - val_accuracy: 0.6690\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5592 - accuracy: 0.7098 - val_loss: 0.6030 - val_accuracy: 0.6690\n",
      "2895/2895 [==============================] - 0s 28us/sample - loss: 0.5649 - accuracy: 0.7092\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 162us/sample - loss: 2.5845 - accuracy: 0.4260 - val_loss: 1.5487 - val_accuracy: 0.5402\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 1.0568 - accuracy: 0.5963 - val_loss: 0.7804 - val_accuracy: 0.6069\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.7100 - accuracy: 0.6663 - val_loss: 0.6739 - val_accuracy: 0.6414\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6387 - accuracy: 0.6927 - val_loss: 0.6380 - val_accuracy: 0.6414\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6107 - accuracy: 0.6858 - val_loss: 0.6207 - val_accuracy: 0.6575\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5913 - accuracy: 0.7008 - val_loss: 0.6158 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5829 - accuracy: 0.7037 - val_loss: 0.6109 - val_accuracy: 0.6529\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5756 - accuracy: 0.7061 - val_loss: 0.6085 - val_accuracy: 0.6506\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5702 - accuracy: 0.6992 - val_loss: 0.6154 - val_accuracy: 0.6690\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5681 - accuracy: 0.7065 - val_loss: 0.6141 - val_accuracy: 0.6736\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5648 - accuracy: 0.7065 - val_loss: 0.6087 - val_accuracy: 0.6598\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5609 - accuracy: 0.7134 - val_loss: 0.6092 - val_accuracy: 0.6690\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5574 - accuracy: 0.7118 - val_loss: 0.6110 - val_accuracy: 0.6575\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5555 - accuracy: 0.7110 - val_loss: 0.6103 - val_accuracy: 0.6529\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5526 - accuracy: 0.7134 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5482 - accuracy: 0.7179 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5453 - accuracy: 0.7163 - val_loss: 0.6126 - val_accuracy: 0.6644\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5449 - accuracy: 0.7224 - val_loss: 0.6134 - val_accuracy: 0.6598\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5397 - accuracy: 0.7232 - val_loss: 0.6104 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5387 - accuracy: 0.7146 - val_loss: 0.6140 - val_accuracy: 0.6621\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5342 - accuracy: 0.7272 - val_loss: 0.6139 - val_accuracy: 0.6713\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5311 - accuracy: 0.7260 - val_loss: 0.6158 - val_accuracy: 0.6483\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5290 - accuracy: 0.7325 - val_loss: 0.6177 - val_accuracy: 0.6690\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5247 - accuracy: 0.7366 - val_loss: 0.6138 - val_accuracy: 0.6598\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5227 - accuracy: 0.7398 - val_loss: 0.6169 - val_accuracy: 0.6713\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5190 - accuracy: 0.7386 - val_loss: 0.6158 - val_accuracy: 0.6713\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5165 - accuracy: 0.7407 - val_loss: 0.6213 - val_accuracy: 0.6736\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5115 - accuracy: 0.7455 - val_loss: 0.6174 - val_accuracy: 0.6736\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5079 - accuracy: 0.7423 - val_loss: 0.6205 - val_accuracy: 0.6644\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5064 - accuracy: 0.7512 - val_loss: 0.6196 - val_accuracy: 0.6575\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5036 - accuracy: 0.7504 - val_loss: 0.6206 - val_accuracy: 0.6690\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4992 - accuracy: 0.7484 - val_loss: 0.6303 - val_accuracy: 0.6690\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4938 - accuracy: 0.7549 - val_loss: 0.6226 - val_accuracy: 0.6460\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4899 - accuracy: 0.7634 - val_loss: 0.6218 - val_accuracy: 0.6644\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4892 - accuracy: 0.7626 - val_loss: 0.6243 - val_accuracy: 0.6598\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4854 - accuracy: 0.7650 - val_loss: 0.6220 - val_accuracy: 0.6690\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4807 - accuracy: 0.7626 - val_loss: 0.6258 - val_accuracy: 0.6598\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4774 - accuracy: 0.7707 - val_loss: 0.6263 - val_accuracy: 0.6552\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4754 - accuracy: 0.7699 - val_loss: 0.6293 - val_accuracy: 0.6575\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4733 - accuracy: 0.7695 - val_loss: 0.6291 - val_accuracy: 0.6621\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4676 - accuracy: 0.7707 - val_loss: 0.6347 - val_accuracy: 0.6552\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4647 - accuracy: 0.7715 - val_loss: 0.6346 - val_accuracy: 0.6506\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4614 - accuracy: 0.7793 - val_loss: 0.6367 - val_accuracy: 0.6552\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4586 - accuracy: 0.7793 - val_loss: 0.6400 - val_accuracy: 0.6529\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4561 - accuracy: 0.7841 - val_loss: 0.6374 - val_accuracy: 0.6483\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4533 - accuracy: 0.7931 - val_loss: 0.6398 - val_accuracy: 0.6529\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4491 - accuracy: 0.7923 - val_loss: 0.6405 - val_accuracy: 0.6552\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4459 - accuracy: 0.7915 - val_loss: 0.6462 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4431 - accuracy: 0.7935 - val_loss: 0.6445 - val_accuracy: 0.6506\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4387 - accuracy: 0.7984 - val_loss: 0.6512 - val_accuracy: 0.6575\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4362 - accuracy: 0.7976 - val_loss: 0.6474 - val_accuracy: 0.6529\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4319 - accuracy: 0.8041 - val_loss: 0.6553 - val_accuracy: 0.6644\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4328 - accuracy: 0.8000 - val_loss: 0.6520 - val_accuracy: 0.6644\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4266 - accuracy: 0.8061 - val_loss: 0.6577 - val_accuracy: 0.6575\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4266 - accuracy: 0.8049 - val_loss: 0.6573 - val_accuracy: 0.6575\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4251 - accuracy: 0.8037 - val_loss: 0.6575 - val_accuracy: 0.6575\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4240 - accuracy: 0.8089 - val_loss: 0.6611 - val_accuracy: 0.6391\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4179 - accuracy: 0.8130 - val_loss: 0.6678 - val_accuracy: 0.6368\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4132 - accuracy: 0.8179 - val_loss: 0.6671 - val_accuracy: 0.6506\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4106 - accuracy: 0.8195 - val_loss: 0.6692 - val_accuracy: 0.6345\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4096 - accuracy: 0.8110 - val_loss: 0.6677 - val_accuracy: 0.6690\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4078 - accuracy: 0.8224 - val_loss: 0.6714 - val_accuracy: 0.6644\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4046 - accuracy: 0.8252 - val_loss: 0.6761 - val_accuracy: 0.6414\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4010 - accuracy: 0.8248 - val_loss: 0.6800 - val_accuracy: 0.6391\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.4000 - accuracy: 0.8203 - val_loss: 0.6799 - val_accuracy: 0.6506\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3975 - accuracy: 0.8244 - val_loss: 0.6763 - val_accuracy: 0.6437\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3956 - accuracy: 0.8232 - val_loss: 0.6800 - val_accuracy: 0.6437\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3932 - accuracy: 0.8297 - val_loss: 0.6888 - val_accuracy: 0.6460\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3921 - accuracy: 0.8329 - val_loss: 0.6984 - val_accuracy: 0.6322\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3869 - accuracy: 0.8337 - val_loss: 0.6861 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3857 - accuracy: 0.8297 - val_loss: 0.6934 - val_accuracy: 0.6460\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3829 - accuracy: 0.8354 - val_loss: 0.6878 - val_accuracy: 0.6598\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3797 - accuracy: 0.8285 - val_loss: 0.6946 - val_accuracy: 0.6345\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3774 - accuracy: 0.8390 - val_loss: 0.7107 - val_accuracy: 0.6368\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3794 - accuracy: 0.8431 - val_loss: 0.7005 - val_accuracy: 0.6460\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3744 - accuracy: 0.8398 - val_loss: 0.7093 - val_accuracy: 0.6575\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3737 - accuracy: 0.8366 - val_loss: 0.7085 - val_accuracy: 0.6483\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3732 - accuracy: 0.8407 - val_loss: 0.7104 - val_accuracy: 0.6483\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3695 - accuracy: 0.8431 - val_loss: 0.7119 - val_accuracy: 0.6483\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3669 - accuracy: 0.8435 - val_loss: 0.7122 - val_accuracy: 0.6690\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3638 - accuracy: 0.8415 - val_loss: 0.7112 - val_accuracy: 0.6552\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3618 - accuracy: 0.8492 - val_loss: 0.7241 - val_accuracy: 0.6368\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.3606 - accuracy: 0.8492 - val_loss: 0.7222 - val_accuracy: 0.6368\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3612 - accuracy: 0.8463 - val_loss: 0.7191 - val_accuracy: 0.6483\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3592 - accuracy: 0.8492 - val_loss: 0.7216 - val_accuracy: 0.6713\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3547 - accuracy: 0.8484 - val_loss: 0.7250 - val_accuracy: 0.6483\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3529 - accuracy: 0.8516 - val_loss: 0.7281 - val_accuracy: 0.6345\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.3512 - accuracy: 0.8496 - val_loss: 0.7341 - val_accuracy: 0.6322\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3512 - accuracy: 0.8504 - val_loss: 0.7318 - val_accuracy: 0.6345\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3505 - accuracy: 0.8492 - val_loss: 0.7514 - val_accuracy: 0.6207\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3467 - accuracy: 0.8549 - val_loss: 0.7414 - val_accuracy: 0.6529\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.3420 - accuracy: 0.8602 - val_loss: 0.7413 - val_accuracy: 0.6368\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3411 - accuracy: 0.8598 - val_loss: 0.7436 - val_accuracy: 0.6460\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.3394 - accuracy: 0.8561 - val_loss: 0.7480 - val_accuracy: 0.6460\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3362 - accuracy: 0.8630 - val_loss: 0.7501 - val_accuracy: 0.6368\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 134us/sample - loss: 0.3373 - accuracy: 0.8610 - val_loss: 0.7512 - val_accuracy: 0.6529\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3351 - accuracy: 0.8634 - val_loss: 0.7530 - val_accuracy: 0.6414\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.3329 - accuracy: 0.8573 - val_loss: 0.7546 - val_accuracy: 0.6575\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3319 - accuracy: 0.8610 - val_loss: 0.7587 - val_accuracy: 0.6506\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3302 - accuracy: 0.8593 - val_loss: 0.7648 - val_accuracy: 0.6483\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.3868 - accuracy: 0.8377\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 151us/sample - loss: 0.9120 - accuracy: 0.5935 - val_loss: 0.6236 - val_accuracy: 0.6529\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6078 - accuracy: 0.6707 - val_loss: 0.6177 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5885 - accuracy: 0.6866 - val_loss: 0.6352 - val_accuracy: 0.6713\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5810 - accuracy: 0.6931 - val_loss: 0.6217 - val_accuracy: 0.6828\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5758 - accuracy: 0.6963 - val_loss: 0.6256 - val_accuracy: 0.6713\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5576 - accuracy: 0.7114 - val_loss: 0.6546 - val_accuracy: 0.6506\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5558 - accuracy: 0.7110 - val_loss: 0.6433 - val_accuracy: 0.6368\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5313 - accuracy: 0.7248 - val_loss: 0.6612 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5159 - accuracy: 0.7370 - val_loss: 0.6691 - val_accuracy: 0.6690\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5158 - accuracy: 0.7378 - val_loss: 0.6770 - val_accuracy: 0.6460\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4927 - accuracy: 0.7520 - val_loss: 0.7097 - val_accuracy: 0.6414\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4851 - accuracy: 0.7642 - val_loss: 0.7227 - val_accuracy: 0.6368\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4694 - accuracy: 0.7744 - val_loss: 0.7409 - val_accuracy: 0.6483\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4575 - accuracy: 0.7837 - val_loss: 0.7710 - val_accuracy: 0.6115\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4391 - accuracy: 0.7923 - val_loss: 0.7918 - val_accuracy: 0.6414\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4559 - accuracy: 0.7772 - val_loss: 0.8104 - val_accuracy: 0.6184\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4170 - accuracy: 0.8053 - val_loss: 0.8128 - val_accuracy: 0.6184\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4041 - accuracy: 0.8126 - val_loss: 0.8805 - val_accuracy: 0.6092\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3996 - accuracy: 0.8175 - val_loss: 0.9079 - val_accuracy: 0.6207\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3888 - accuracy: 0.8167 - val_loss: 0.8620 - val_accuracy: 0.6299\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3769 - accuracy: 0.8293 - val_loss: 0.9633 - val_accuracy: 0.5931\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3594 - accuracy: 0.8341 - val_loss: 0.9489 - val_accuracy: 0.6414\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3636 - accuracy: 0.8301 - val_loss: 0.9644 - val_accuracy: 0.6069\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3508 - accuracy: 0.8419 - val_loss: 1.0099 - val_accuracy: 0.6046\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3368 - accuracy: 0.8419 - val_loss: 0.9937 - val_accuracy: 0.6276\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3213 - accuracy: 0.8537 - val_loss: 1.0242 - val_accuracy: 0.6322\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3155 - accuracy: 0.8630 - val_loss: 1.0277 - val_accuracy: 0.6115\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3097 - accuracy: 0.8553 - val_loss: 1.1082 - val_accuracy: 0.6161\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3076 - accuracy: 0.8626 - val_loss: 1.0514 - val_accuracy: 0.6322\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3054 - accuracy: 0.8663 - val_loss: 1.1253 - val_accuracy: 0.6138\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2881 - accuracy: 0.8646 - val_loss: 1.1536 - val_accuracy: 0.6253\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.2945 - accuracy: 0.8691 - val_loss: 1.2127 - val_accuracy: 0.5931\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3008 - accuracy: 0.8642 - val_loss: 1.2090 - val_accuracy: 0.6299\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.2741 - accuracy: 0.8817 - val_loss: 1.2149 - val_accuracy: 0.6046\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.2734 - accuracy: 0.8813 - val_loss: 1.2968 - val_accuracy: 0.6046\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.2682 - accuracy: 0.8801 - val_loss: 1.2823 - val_accuracy: 0.6069\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.2551 - accuracy: 0.8850 - val_loss: 1.3220 - val_accuracy: 0.5977\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.2530 - accuracy: 0.8911 - val_loss: 1.3861 - val_accuracy: 0.5954\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2503 - accuracy: 0.8923 - val_loss: 1.3465 - val_accuracy: 0.6138\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2396 - accuracy: 0.8972 - val_loss: 1.4376 - val_accuracy: 0.6161\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2507 - accuracy: 0.8902 - val_loss: 1.3959 - val_accuracy: 0.6161\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.2470 - accuracy: 0.8972 - val_loss: 1.4117 - val_accuracy: 0.6115\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.2197 - accuracy: 0.9033 - val_loss: 1.4432 - val_accuracy: 0.6368\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2386 - accuracy: 0.8955 - val_loss: 1.4651 - val_accuracy: 0.6046\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2311 - accuracy: 0.9024 - val_loss: 1.4713 - val_accuracy: 0.6046\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2117 - accuracy: 0.9098 - val_loss: 1.4796 - val_accuracy: 0.6069\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2058 - accuracy: 0.9150 - val_loss: 1.6082 - val_accuracy: 0.5770\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.2093 - accuracy: 0.9167 - val_loss: 1.5454 - val_accuracy: 0.6391\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.1986 - accuracy: 0.9163 - val_loss: 1.5552 - val_accuracy: 0.6207\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.2116 - accuracy: 0.9106 - val_loss: 1.6295 - val_accuracy: 0.6138\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1927 - accuracy: 0.9220 - val_loss: 1.6014 - val_accuracy: 0.6276\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1881 - accuracy: 0.9264 - val_loss: 1.6810 - val_accuracy: 0.6115\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.1869 - accuracy: 0.9179 - val_loss: 1.7142 - val_accuracy: 0.6138\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.1833 - accuracy: 0.9228 - val_loss: 1.7524 - val_accuracy: 0.6138\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1912 - accuracy: 0.9195 - val_loss: 1.8303 - val_accuracy: 0.6115\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.1945 - accuracy: 0.9199 - val_loss: 1.7262 - val_accuracy: 0.6230\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.1777 - accuracy: 0.9317 - val_loss: 1.7596 - val_accuracy: 0.6069\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1717 - accuracy: 0.9297 - val_loss: 1.7931 - val_accuracy: 0.6046\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1584 - accuracy: 0.9350 - val_loss: 1.8283 - val_accuracy: 0.6184\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1755 - accuracy: 0.9272 - val_loss: 1.8551 - val_accuracy: 0.6322\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1777 - accuracy: 0.9264 - val_loss: 1.8504 - val_accuracy: 0.6368\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.1644 - accuracy: 0.9362 - val_loss: 1.9551 - val_accuracy: 0.6253\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.1608 - accuracy: 0.9297 - val_loss: 1.9461 - val_accuracy: 0.6184\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.1774 - accuracy: 0.9285 - val_loss: 1.9084 - val_accuracy: 0.6207\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.1688 - accuracy: 0.9350 - val_loss: 1.9174 - val_accuracy: 0.6207\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.1605 - accuracy: 0.9325 - val_loss: 1.9688 - val_accuracy: 0.6115\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.1600 - accuracy: 0.9309 - val_loss: 2.0308 - val_accuracy: 0.6115\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.1622 - accuracy: 0.9358 - val_loss: 2.0940 - val_accuracy: 0.6184\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.1561 - accuracy: 0.9378 - val_loss: 2.0814 - val_accuracy: 0.6023\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 135us/sample - loss: 0.1421 - accuracy: 0.9431 - val_loss: 2.0407 - val_accuracy: 0.6414\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.1557 - accuracy: 0.9325 - val_loss: 2.0295 - val_accuracy: 0.6276\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.1612 - accuracy: 0.9390 - val_loss: 2.0681 - val_accuracy: 0.6253\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.1436 - accuracy: 0.9488 - val_loss: 2.0580 - val_accuracy: 0.6368\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.1417 - accuracy: 0.9427 - val_loss: 2.1490 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.1358 - accuracy: 0.9455 - val_loss: 2.1828 - val_accuracy: 0.6391\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.1471 - accuracy: 0.9394 - val_loss: 2.2353 - val_accuracy: 0.6092\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.1345 - accuracy: 0.9472 - val_loss: 2.2022 - val_accuracy: 0.6253\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.1277 - accuracy: 0.9476 - val_loss: 2.1752 - val_accuracy: 0.6276\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.1276 - accuracy: 0.9549 - val_loss: 2.2819 - val_accuracy: 0.6253\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.1346 - accuracy: 0.9419 - val_loss: 2.2537 - val_accuracy: 0.6345\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.1713 - accuracy: 0.9321 - val_loss: 2.1701 - val_accuracy: 0.6276\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.1474 - accuracy: 0.9411 - val_loss: 2.2941 - val_accuracy: 0.6023\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.1323 - accuracy: 0.9496 - val_loss: 2.3159 - val_accuracy: 0.6207\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.1120 - accuracy: 0.9537 - val_loss: 2.3218 - val_accuracy: 0.6138\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.1440 - accuracy: 0.9451 - val_loss: 2.2868 - val_accuracy: 0.6322\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.1409 - accuracy: 0.9370 - val_loss: 2.3753 - val_accuracy: 0.6276\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.1169 - accuracy: 0.9520 - val_loss: 2.4682 - val_accuracy: 0.5908\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.1168 - accuracy: 0.9561 - val_loss: 2.3908 - val_accuracy: 0.6230\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.1097 - accuracy: 0.9585 - val_loss: 2.4899 - val_accuracy: 0.5977\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.1239 - accuracy: 0.9512 - val_loss: 2.3912 - val_accuracy: 0.6368\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.1275 - accuracy: 0.9512 - val_loss: 2.4797 - val_accuracy: 0.6230\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.1107 - accuracy: 0.9549 - val_loss: 2.5197 - val_accuracy: 0.6276\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.1273 - accuracy: 0.9496 - val_loss: 2.6196 - val_accuracy: 0.6161\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.1287 - accuracy: 0.9472 - val_loss: 2.5258 - val_accuracy: 0.6161\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1152 - accuracy: 0.9561 - val_loss: 2.5480 - val_accuracy: 0.6161\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.1053 - accuracy: 0.9573 - val_loss: 2.5166 - val_accuracy: 0.6299\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1089 - accuracy: 0.9533 - val_loss: 2.6286 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1632 - accuracy: 0.9346 - val_loss: 2.5332 - val_accuracy: 0.6253\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1073 - accuracy: 0.9565 - val_loss: 2.6165 - val_accuracy: 0.6161\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1228 - accuracy: 0.9520 - val_loss: 2.7003 - val_accuracy: 0.6207\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.5286 - accuracy: 0.8922\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 310us/sample - loss: 0.8549 - accuracy: 0.5878 - val_loss: 0.7253 - val_accuracy: 0.6161\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6465 - accuracy: 0.6447 - val_loss: 0.6609 - val_accuracy: 0.6529\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6435 - accuracy: 0.6467 - val_loss: 0.7020 - val_accuracy: 0.6299\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6365 - accuracy: 0.6715 - val_loss: 0.7509 - val_accuracy: 0.5977\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 121us/sample - loss: 0.6338 - accuracy: 0.6695 - val_loss: 0.7078 - val_accuracy: 0.6092\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6348 - accuracy: 0.6626 - val_loss: 0.7065 - val_accuracy: 0.6184\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.6202 - accuracy: 0.6833 - val_loss: 0.7200 - val_accuracy: 0.6069\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5922 - accuracy: 0.6846 - val_loss: 0.8842 - val_accuracy: 0.5425\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5914 - accuracy: 0.6809 - val_loss: 0.7735 - val_accuracy: 0.6460\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5816 - accuracy: 0.7020 - val_loss: 0.7741 - val_accuracy: 0.6184\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5440 - accuracy: 0.7098 - val_loss: 0.9185 - val_accuracy: 0.6138\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5663 - accuracy: 0.7008 - val_loss: 0.7273 - val_accuracy: 0.6161\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5622 - accuracy: 0.6963 - val_loss: 0.7975 - val_accuracy: 0.6069\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5457 - accuracy: 0.7069 - val_loss: 0.7157 - val_accuracy: 0.5954\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5399 - accuracy: 0.7053 - val_loss: 0.8043 - val_accuracy: 0.5931\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5240 - accuracy: 0.7260 - val_loss: 0.8456 - val_accuracy: 0.5885\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5181 - accuracy: 0.7183 - val_loss: 0.8441 - val_accuracy: 0.5931\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5045 - accuracy: 0.7195 - val_loss: 1.0517 - val_accuracy: 0.5839\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5067 - accuracy: 0.7248 - val_loss: 0.9360 - val_accuracy: 0.6184\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4869 - accuracy: 0.7366 - val_loss: 0.9421 - val_accuracy: 0.6115\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4986 - accuracy: 0.7232 - val_loss: 0.8758 - val_accuracy: 0.5770\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4863 - accuracy: 0.7224 - val_loss: 0.9676 - val_accuracy: 0.5655\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4710 - accuracy: 0.7386 - val_loss: 1.0869 - val_accuracy: 0.6230\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4759 - accuracy: 0.7325 - val_loss: 1.0775 - val_accuracy: 0.6184\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4829 - accuracy: 0.7341 - val_loss: 0.9816 - val_accuracy: 0.5816\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.4797 - accuracy: 0.7175 - val_loss: 1.0444 - val_accuracy: 0.6207\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4720 - accuracy: 0.7244 - val_loss: 1.1062 - val_accuracy: 0.5540\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4557 - accuracy: 0.7362 - val_loss: 1.2654 - val_accuracy: 0.6230\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4439 - accuracy: 0.7402 - val_loss: 1.0617 - val_accuracy: 0.6184\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4563 - accuracy: 0.7390 - val_loss: 1.1830 - val_accuracy: 0.5862\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.4614 - accuracy: 0.7447 - val_loss: 1.2382 - val_accuracy: 0.5816\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4520 - accuracy: 0.7463 - val_loss: 1.1915 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4504 - accuracy: 0.7516 - val_loss: 1.1325 - val_accuracy: 0.5816\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4821 - accuracy: 0.7354 - val_loss: 1.1842 - val_accuracy: 0.6138\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4818 - accuracy: 0.7350 - val_loss: 1.3836 - val_accuracy: 0.6253\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4541 - accuracy: 0.7549 - val_loss: 1.0168 - val_accuracy: 0.6184\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4296 - accuracy: 0.7549 - val_loss: 1.4538 - val_accuracy: 0.6092\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4295 - accuracy: 0.7476 - val_loss: 1.5194 - val_accuracy: 0.6115\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4318 - accuracy: 0.7455 - val_loss: 1.2416 - val_accuracy: 0.5954\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.4407 - accuracy: 0.7451 - val_loss: 1.5425 - val_accuracy: 0.6161\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4498 - accuracy: 0.7427 - val_loss: 1.4762 - val_accuracy: 0.5908\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4248 - accuracy: 0.7455 - val_loss: 1.4853 - val_accuracy: 0.5816\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4165 - accuracy: 0.7500 - val_loss: 1.3618 - val_accuracy: 0.6161\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4191 - accuracy: 0.7618 - val_loss: 1.7285 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.4178 - accuracy: 0.7492 - val_loss: 1.7043 - val_accuracy: 0.5701\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4032 - accuracy: 0.7463 - val_loss: 1.5577 - val_accuracy: 0.6299\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.4090 - accuracy: 0.7508 - val_loss: 1.6161 - val_accuracy: 0.6092\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4073 - accuracy: 0.7516 - val_loss: 1.5274 - val_accuracy: 0.6138\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4295 - accuracy: 0.7350 - val_loss: 1.9559 - val_accuracy: 0.5954\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4468 - accuracy: 0.7549 - val_loss: 1.6090 - val_accuracy: 0.6276\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4343 - accuracy: 0.7378 - val_loss: 1.6818 - val_accuracy: 0.6276\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4200 - accuracy: 0.7581 - val_loss: 1.8475 - val_accuracy: 0.6046\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.4086 - accuracy: 0.7602 - val_loss: 1.6002 - val_accuracy: 0.6253\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3859 - accuracy: 0.7394 - val_loss: 2.0138 - val_accuracy: 0.6184\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3881 - accuracy: 0.7642 - val_loss: 2.3382 - val_accuracy: 0.5885\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4034 - accuracy: 0.7504 - val_loss: 1.9348 - val_accuracy: 0.6115\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4092 - accuracy: 0.7528 - val_loss: 2.2484 - val_accuracy: 0.5908\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4090 - accuracy: 0.7423 - val_loss: 1.5833 - val_accuracy: 0.5793\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4213 - accuracy: 0.7500 - val_loss: 1.8908 - val_accuracy: 0.6092\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4007 - accuracy: 0.7480 - val_loss: 1.7956 - val_accuracy: 0.5724\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4057 - accuracy: 0.7516 - val_loss: 1.9457 - val_accuracy: 0.5770\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.4205 - accuracy: 0.7508 - val_loss: 1.9335 - val_accuracy: 0.6115\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3971 - accuracy: 0.7565 - val_loss: 2.2863 - val_accuracy: 0.5954\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3830 - accuracy: 0.7626 - val_loss: 2.4430 - val_accuracy: 0.6046\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4128 - accuracy: 0.7541 - val_loss: 1.7968 - val_accuracy: 0.6023\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3720 - accuracy: 0.7711 - val_loss: 2.2677 - val_accuracy: 0.5701\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3751 - accuracy: 0.7610 - val_loss: 2.1690 - val_accuracy: 0.5816\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4106 - accuracy: 0.7573 - val_loss: 2.2568 - val_accuracy: 0.5632\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4197 - accuracy: 0.7459 - val_loss: 1.9619 - val_accuracy: 0.5954\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4045 - accuracy: 0.7496 - val_loss: 2.4203 - val_accuracy: 0.6046\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3915 - accuracy: 0.7459 - val_loss: 2.3962 - val_accuracy: 0.6092\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3803 - accuracy: 0.7606 - val_loss: 2.4076 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3761 - accuracy: 0.7524 - val_loss: 2.4284 - val_accuracy: 0.5655\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3870 - accuracy: 0.7618 - val_loss: 2.3643 - val_accuracy: 0.6046\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4188 - accuracy: 0.7683 - val_loss: 2.4151 - val_accuracy: 0.5885\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4210 - accuracy: 0.7337 - val_loss: 2.7281 - val_accuracy: 0.6023\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4093 - accuracy: 0.7573 - val_loss: 2.0209 - val_accuracy: 0.6092\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4267 - accuracy: 0.7394 - val_loss: 2.3781 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3987 - accuracy: 0.7419 - val_loss: 1.9705 - val_accuracy: 0.5816\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3720 - accuracy: 0.7467 - val_loss: 2.7336 - val_accuracy: 0.5724\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3659 - accuracy: 0.7516 - val_loss: 2.7420 - val_accuracy: 0.5517\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.3629 - accuracy: 0.7528 - val_loss: 2.6872 - val_accuracy: 0.5839\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3613 - accuracy: 0.7736 - val_loss: 2.6249 - val_accuracy: 0.5793\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3572 - accuracy: 0.7545 - val_loss: 3.0794 - val_accuracy: 0.5977\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3599 - accuracy: 0.7630 - val_loss: 2.6271 - val_accuracy: 0.6046\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3567 - accuracy: 0.7561 - val_loss: 2.6813 - val_accuracy: 0.5954\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3576 - accuracy: 0.7626 - val_loss: 3.3644 - val_accuracy: 0.6046\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3584 - accuracy: 0.7650 - val_loss: 3.4738 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4280 - accuracy: 0.7528 - val_loss: 3.1425 - val_accuracy: 0.5678\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3846 - accuracy: 0.7638 - val_loss: 3.4693 - val_accuracy: 0.5954\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3858 - accuracy: 0.7589 - val_loss: 3.1627 - val_accuracy: 0.6046\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3810 - accuracy: 0.7472 - val_loss: 2.9250 - val_accuracy: 0.6046\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3760 - accuracy: 0.7516 - val_loss: 3.3132 - val_accuracy: 0.5770\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.3781 - accuracy: 0.7606 - val_loss: 3.1195 - val_accuracy: 0.5563\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4102 - accuracy: 0.7467 - val_loss: 3.1889 - val_accuracy: 0.6092\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3871 - accuracy: 0.7496 - val_loss: 3.2265 - val_accuracy: 0.5609\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3905 - accuracy: 0.7577 - val_loss: 3.8505 - val_accuracy: 0.6069\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4292 - accuracy: 0.7537 - val_loss: 3.4338 - val_accuracy: 0.5586\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4148 - accuracy: 0.7455 - val_loss: 3.5952 - val_accuracy: 0.5632\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3901 - accuracy: 0.7472 - val_loss: 3.2671 - val_accuracy: 0.6184\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.8052 - accuracy: 0.7482\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 136us/sample - loss: 7.6336 - accuracy: 0.4967 - val_loss: 1.6744 - val_accuracy: 0.5425\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.0529 - accuracy: 0.5232 - val_loss: 0.7218 - val_accuracy: 0.5448\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7688 - accuracy: 0.5325 - val_loss: 0.9200 - val_accuracy: 0.5471\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7488 - accuracy: 0.5333 - val_loss: 0.8140 - val_accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7644 - accuracy: 0.4988 - val_loss: 0.7526 - val_accuracy: 0.5379\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7051 - accuracy: 0.5537 - val_loss: 0.7174 - val_accuracy: 0.4736\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.7159 - accuracy: 0.5341 - val_loss: 0.7119 - val_accuracy: 0.5471\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7588 - accuracy: 0.5134 - val_loss: 0.7086 - val_accuracy: 0.5264\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7396 - accuracy: 0.5211 - val_loss: 0.7174 - val_accuracy: 0.4644\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7068 - accuracy: 0.5195 - val_loss: 0.7221 - val_accuracy: 0.5425\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7153 - accuracy: 0.5073 - val_loss: 0.7288 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7259 - accuracy: 0.5126 - val_loss: 0.7127 - val_accuracy: 0.4529\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7060 - accuracy: 0.5093 - val_loss: 0.7190 - val_accuracy: 0.5425\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7401 - accuracy: 0.5089 - val_loss: 0.6968 - val_accuracy: 0.5402\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7011 - accuracy: 0.5195 - val_loss: 0.7254 - val_accuracy: 0.4529\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7331 - accuracy: 0.5033 - val_loss: 0.7098 - val_accuracy: 0.4529\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7134 - accuracy: 0.5012 - val_loss: 0.6968 - val_accuracy: 0.5402\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7030 - accuracy: 0.5085 - val_loss: 0.7148 - val_accuracy: 0.4529\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7075 - accuracy: 0.5167 - val_loss: 0.7240 - val_accuracy: 0.5425\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7024 - accuracy: 0.5232 - val_loss: 0.7006 - val_accuracy: 0.4529\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.7014 - accuracy: 0.5171 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.6976 - accuracy: 0.5175 - val_loss: 0.7001 - val_accuracy: 0.5402\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7207 - accuracy: 0.5106 - val_loss: 0.6968 - val_accuracy: 0.5402\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.7183 - accuracy: 0.5236 - val_loss: 0.7162 - val_accuracy: 0.4529\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.7093 - accuracy: 0.5089 - val_loss: 0.7030 - val_accuracy: 0.4529\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7029 - accuracy: 0.5187 - val_loss: 0.6989 - val_accuracy: 0.5379\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7664 - accuracy: 0.5089 - val_loss: 0.6983 - val_accuracy: 0.5402\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7236 - accuracy: 0.5118 - val_loss: 0.7102 - val_accuracy: 0.5425\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.6556 - accuracy: 0.5321 - val_loss: 0.7288 - val_accuracy: 0.5425\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8344 - accuracy: 0.5093 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6986 - accuracy: 0.5317 - val_loss: 0.7209 - val_accuracy: 0.4529\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7039 - accuracy: 0.5150 - val_loss: 0.7020 - val_accuracy: 0.5402\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.7110 - accuracy: 0.5089 - val_loss: 0.7345 - val_accuracy: 0.4529\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7077 - accuracy: 0.5028 - val_loss: 0.6985 - val_accuracy: 0.5402\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7037 - accuracy: 0.5041 - val_loss: 0.7016 - val_accuracy: 0.4529\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.7100 - accuracy: 0.5106 - val_loss: 0.7389 - val_accuracy: 0.4529\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7032 - accuracy: 0.5354 - val_loss: 0.7314 - val_accuracy: 0.4529\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7851 - accuracy: 0.5142 - val_loss: 0.7722 - val_accuracy: 0.4529\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.7044 - accuracy: 0.5183 - val_loss: 0.6973 - val_accuracy: 0.5402\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7137 - accuracy: 0.5207 - val_loss: 0.7096 - val_accuracy: 0.5425\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.7189 - accuracy: 0.5016 - val_loss: 0.7142 - val_accuracy: 0.4529\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7256 - accuracy: 0.5102 - val_loss: 0.7080 - val_accuracy: 0.4529\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7251 - accuracy: 0.5057 - val_loss: 0.7593 - val_accuracy: 0.4529\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7057 - accuracy: 0.5110 - val_loss: 0.7098 - val_accuracy: 0.4529\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7349 - accuracy: 0.5053 - val_loss: 0.8264 - val_accuracy: 0.5425\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7087 - accuracy: 0.5130 - val_loss: 0.6994 - val_accuracy: 0.5379\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7171 - accuracy: 0.5215 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7216 - accuracy: 0.5187 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7293 - accuracy: 0.5081 - val_loss: 0.7283 - val_accuracy: 0.4529\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7073 - accuracy: 0.5171 - val_loss: 0.7409 - val_accuracy: 0.4529\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.7166 - accuracy: 0.5065 - val_loss: 0.7123 - val_accuracy: 0.4529\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7079 - accuracy: 0.5154 - val_loss: 0.6983 - val_accuracy: 0.5402\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7047 - accuracy: 0.5077 - val_loss: 0.6989 - val_accuracy: 0.5379\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7004 - accuracy: 0.5098 - val_loss: 0.7508 - val_accuracy: 0.4529\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7130 - accuracy: 0.5057 - val_loss: 0.7042 - val_accuracy: 0.5402\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7304 - accuracy: 0.5240 - val_loss: 0.7339 - val_accuracy: 0.5425\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7035 - accuracy: 0.5093 - val_loss: 0.7145 - val_accuracy: 0.5425\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7146 - accuracy: 0.5110 - val_loss: 0.8832 - val_accuracy: 0.5425\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7241 - accuracy: 0.5187 - val_loss: 0.7055 - val_accuracy: 0.5402\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7042 - accuracy: 0.5272 - val_loss: 0.7310 - val_accuracy: 0.4529\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7112 - accuracy: 0.5232 - val_loss: 0.7198 - val_accuracy: 0.4529\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7184 - accuracy: 0.5272 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7031 - accuracy: 0.5341 - val_loss: 0.7304 - val_accuracy: 0.4529\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7219 - accuracy: 0.5179 - val_loss: 0.8497 - val_accuracy: 0.5425\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.7514 - accuracy: 0.5114 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.7276 - accuracy: 0.5118 - val_loss: 0.7105 - val_accuracy: 0.5425\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7010 - accuracy: 0.5317 - val_loss: 0.7373 - val_accuracy: 0.5425\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7168 - accuracy: 0.5224 - val_loss: 0.7109 - val_accuracy: 0.4529\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7112 - accuracy: 0.5272 - val_loss: 0.7116 - val_accuracy: 0.5425\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7060 - accuracy: 0.5378 - val_loss: 0.7058 - val_accuracy: 0.5402\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7132 - accuracy: 0.4988 - val_loss: 0.7035 - val_accuracy: 0.4529\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7188 - accuracy: 0.5138 - val_loss: 0.7822 - val_accuracy: 0.4529\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7001 - accuracy: 0.5122 - val_loss: 0.6971 - val_accuracy: 0.5402\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7038 - accuracy: 0.5232 - val_loss: 0.6980 - val_accuracy: 0.5402\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7085 - accuracy: 0.5236 - val_loss: 0.6988 - val_accuracy: 0.5402\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7143 - accuracy: 0.5069 - val_loss: 0.7023 - val_accuracy: 0.5402\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7014 - accuracy: 0.5366 - val_loss: 0.6969 - val_accuracy: 0.5425\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.7062 - accuracy: 0.5329 - val_loss: 0.7073 - val_accuracy: 0.4529\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7169 - accuracy: 0.5061 - val_loss: 0.7407 - val_accuracy: 0.4529\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7205 - accuracy: 0.4947 - val_loss: 0.7516 - val_accuracy: 0.5425\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7104 - accuracy: 0.5134 - val_loss: 0.7031 - val_accuracy: 0.4529\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7091 - accuracy: 0.5061 - val_loss: 0.6986 - val_accuracy: 0.5425\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7179 - accuracy: 0.5211 - val_loss: 0.6984 - val_accuracy: 0.5425\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7339 - accuracy: 0.5057 - val_loss: 0.7081 - val_accuracy: 0.4529\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7102 - accuracy: 0.5138 - val_loss: 0.7049 - val_accuracy: 0.5402\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7040 - accuracy: 0.5240 - val_loss: 0.6971 - val_accuracy: 0.5425\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7068 - accuracy: 0.5163 - val_loss: 0.7289 - val_accuracy: 0.4529\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7215 - accuracy: 0.5293 - val_loss: 0.6962 - val_accuracy: 0.5425\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7059 - accuracy: 0.5297 - val_loss: 0.7697 - val_accuracy: 0.4529\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7446 - accuracy: 0.5179 - val_loss: 0.7046 - val_accuracy: 0.5425\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7151 - accuracy: 0.4992 - val_loss: 0.6966 - val_accuracy: 0.5402\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.7031 - accuracy: 0.5134 - val_loss: 0.6970 - val_accuracy: 0.5402\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7092 - accuracy: 0.5171 - val_loss: 0.7370 - val_accuracy: 0.5425\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7039 - accuracy: 0.5220 - val_loss: 0.7300 - val_accuracy: 0.5425\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7301 - accuracy: 0.5236 - val_loss: 0.7682 - val_accuracy: 0.5425\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7204 - accuracy: 0.5154 - val_loss: 0.7089 - val_accuracy: 0.4529\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7477 - accuracy: 0.5077 - val_loss: 0.6975 - val_accuracy: 0.5425\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7205 - accuracy: 0.5187 - val_loss: 0.7249 - val_accuracy: 0.4529\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7132 - accuracy: 0.5224 - val_loss: 0.7643 - val_accuracy: 0.5425\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7034 - accuracy: 0.5199 - val_loss: 0.7321 - val_accuracy: 0.5448\n",
      "2895/2895 [==============================] - 0s 24us/sample - loss: 0.7221 - accuracy: 0.5478\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 117us/sample - loss: 3.5694 - accuracy: 0.0033 - val_loss: 3.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.5592 - accuracy: 0.0053 - val_loss: 3.5682 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.5490 - accuracy: 0.0053 - val_loss: 3.5579 - val_accuracy: 0.0023\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 3.5388 - accuracy: 0.0057 - val_loss: 3.5477 - val_accuracy: 0.0046\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.5287 - accuracy: 0.0073 - val_loss: 3.5374 - val_accuracy: 0.0046\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.5186 - accuracy: 0.0085 - val_loss: 3.5272 - val_accuracy: 0.0046\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5085 - accuracy: 0.0114 - val_loss: 3.5170 - val_accuracy: 0.0069\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.4984 - accuracy: 0.0150 - val_loss: 3.5068 - val_accuracy: 0.0069\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.4883 - accuracy: 0.0179 - val_loss: 3.4967 - val_accuracy: 0.0069\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.4782 - accuracy: 0.0199 - val_loss: 3.4865 - val_accuracy: 0.0092\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.4682 - accuracy: 0.0244 - val_loss: 3.4764 - val_accuracy: 0.0115\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.4581 - accuracy: 0.0260 - val_loss: 3.4663 - val_accuracy: 0.0115\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.4481 - accuracy: 0.0280 - val_loss: 3.4561 - val_accuracy: 0.0161\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.4381 - accuracy: 0.0346 - val_loss: 3.4460 - val_accuracy: 0.0161\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.4281 - accuracy: 0.0374 - val_loss: 3.4360 - val_accuracy: 0.0161\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.4181 - accuracy: 0.0435 - val_loss: 3.4259 - val_accuracy: 0.0207\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.4081 - accuracy: 0.0512 - val_loss: 3.4158 - val_accuracy: 0.0299\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.3982 - accuracy: 0.0622 - val_loss: 3.4057 - val_accuracy: 0.0299\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.3882 - accuracy: 0.0724 - val_loss: 3.3957 - val_accuracy: 0.0414\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.3783 - accuracy: 0.0850 - val_loss: 3.3857 - val_accuracy: 0.0621\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.3683 - accuracy: 0.0988 - val_loss: 3.3756 - val_accuracy: 0.0690\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.3584 - accuracy: 0.1093 - val_loss: 3.3656 - val_accuracy: 0.0782\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.3485 - accuracy: 0.1203 - val_loss: 3.3556 - val_accuracy: 0.0897\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.3386 - accuracy: 0.1305 - val_loss: 3.3456 - val_accuracy: 0.1103\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.3286 - accuracy: 0.1451 - val_loss: 3.3356 - val_accuracy: 0.1264\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.3187 - accuracy: 0.1549 - val_loss: 3.3256 - val_accuracy: 0.1379\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.3088 - accuracy: 0.1687 - val_loss: 3.3156 - val_accuracy: 0.1517\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.2990 - accuracy: 0.1809 - val_loss: 3.3056 - val_accuracy: 0.1655\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.2891 - accuracy: 0.1967 - val_loss: 3.2957 - val_accuracy: 0.1816\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.2792 - accuracy: 0.2126 - val_loss: 3.2857 - val_accuracy: 0.1931\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.2693 - accuracy: 0.2256 - val_loss: 3.2757 - val_accuracy: 0.2115\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.2594 - accuracy: 0.2394 - val_loss: 3.2658 - val_accuracy: 0.2322\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.2496 - accuracy: 0.2561 - val_loss: 3.2558 - val_accuracy: 0.2414\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.2397 - accuracy: 0.2748 - val_loss: 3.2459 - val_accuracy: 0.2529\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.2299 - accuracy: 0.2870 - val_loss: 3.2360 - val_accuracy: 0.2690\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.2200 - accuracy: 0.2984 - val_loss: 3.2260 - val_accuracy: 0.2805\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.2101 - accuracy: 0.3179 - val_loss: 3.2161 - val_accuracy: 0.2897\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.2003 - accuracy: 0.3325 - val_loss: 3.2062 - val_accuracy: 0.3034\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.1905 - accuracy: 0.3484 - val_loss: 3.1962 - val_accuracy: 0.3149\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.1806 - accuracy: 0.3606 - val_loss: 3.1863 - val_accuracy: 0.3471\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.1708 - accuracy: 0.3736 - val_loss: 3.1764 - val_accuracy: 0.3563\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.1609 - accuracy: 0.3870 - val_loss: 3.1664 - val_accuracy: 0.3678\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.1511 - accuracy: 0.4004 - val_loss: 3.1565 - val_accuracy: 0.3724\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 3.1412 - accuracy: 0.4102 - val_loss: 3.1466 - val_accuracy: 0.3793\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.1314 - accuracy: 0.4207 - val_loss: 3.1367 - val_accuracy: 0.3954\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.1216 - accuracy: 0.4309 - val_loss: 3.1267 - val_accuracy: 0.4069\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.1117 - accuracy: 0.4398 - val_loss: 3.1168 - val_accuracy: 0.4092\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.1019 - accuracy: 0.4496 - val_loss: 3.1069 - val_accuracy: 0.4115\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.0920 - accuracy: 0.4585 - val_loss: 3.0970 - val_accuracy: 0.4184\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.0822 - accuracy: 0.4650 - val_loss: 3.0870 - val_accuracy: 0.4253\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.0723 - accuracy: 0.4748 - val_loss: 3.0771 - val_accuracy: 0.4391\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.0625 - accuracy: 0.4821 - val_loss: 3.0672 - val_accuracy: 0.4483\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.0527 - accuracy: 0.4882 - val_loss: 3.0573 - val_accuracy: 0.4506\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.0428 - accuracy: 0.4959 - val_loss: 3.0473 - val_accuracy: 0.4552\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.0330 - accuracy: 0.4988 - val_loss: 3.0374 - val_accuracy: 0.4598\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.0231 - accuracy: 0.5085 - val_loss: 3.0275 - val_accuracy: 0.4621\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 111us/sample - loss: 3.0133 - accuracy: 0.5150 - val_loss: 3.0175 - val_accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.0034 - accuracy: 0.5211 - val_loss: 3.0076 - val_accuracy: 0.4713\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.9936 - accuracy: 0.5256 - val_loss: 2.9977 - val_accuracy: 0.4759\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.9837 - accuracy: 0.5285 - val_loss: 2.9878 - val_accuracy: 0.4828\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.9739 - accuracy: 0.5309 - val_loss: 2.9778 - val_accuracy: 0.4828\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.9640 - accuracy: 0.5337 - val_loss: 2.9679 - val_accuracy: 0.4828\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.9542 - accuracy: 0.5362 - val_loss: 2.9580 - val_accuracy: 0.4897\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.9443 - accuracy: 0.5374 - val_loss: 2.9480 - val_accuracy: 0.4920\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.9345 - accuracy: 0.5439 - val_loss: 2.9381 - val_accuracy: 0.4920\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 2.9246 - accuracy: 0.5447 - val_loss: 2.9282 - val_accuracy: 0.5057\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.9148 - accuracy: 0.5476 - val_loss: 2.9182 - val_accuracy: 0.5103\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.9049 - accuracy: 0.5496 - val_loss: 2.9083 - val_accuracy: 0.5103\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 2.8951 - accuracy: 0.5528 - val_loss: 2.8984 - val_accuracy: 0.5080\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.8852 - accuracy: 0.5545 - val_loss: 2.8884 - val_accuracy: 0.5103\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.8754 - accuracy: 0.5561 - val_loss: 2.8785 - val_accuracy: 0.5149\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 2.8655 - accuracy: 0.5569 - val_loss: 2.8686 - val_accuracy: 0.5172\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.8556 - accuracy: 0.5581 - val_loss: 2.8586 - val_accuracy: 0.5195\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.8458 - accuracy: 0.5577 - val_loss: 2.8487 - val_accuracy: 0.5241\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.8359 - accuracy: 0.5610 - val_loss: 2.8388 - val_accuracy: 0.5241\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.8261 - accuracy: 0.5610 - val_loss: 2.8288 - val_accuracy: 0.5264\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.8162 - accuracy: 0.5610 - val_loss: 2.8189 - val_accuracy: 0.5264\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.8063 - accuracy: 0.5606 - val_loss: 2.8090 - val_accuracy: 0.5264\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 2.7965 - accuracy: 0.5606 - val_loss: 2.7990 - val_accuracy: 0.5287\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.7866 - accuracy: 0.5614 - val_loss: 2.7891 - val_accuracy: 0.5310\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 2.7768 - accuracy: 0.5630 - val_loss: 2.7792 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 2.7669 - accuracy: 0.5634 - val_loss: 2.7692 - val_accuracy: 0.5356\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 2.7571 - accuracy: 0.5618 - val_loss: 2.7593 - val_accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.7472 - accuracy: 0.5622 - val_loss: 2.7494 - val_accuracy: 0.5356\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.7373 - accuracy: 0.5626 - val_loss: 2.7395 - val_accuracy: 0.5356\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.7275 - accuracy: 0.5626 - val_loss: 2.7295 - val_accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.7176 - accuracy: 0.5634 - val_loss: 2.7196 - val_accuracy: 0.5379\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.7078 - accuracy: 0.5642 - val_loss: 2.7097 - val_accuracy: 0.5379\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 2.6979 - accuracy: 0.5638 - val_loss: 2.6998 - val_accuracy: 0.5379\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.6881 - accuracy: 0.5638 - val_loss: 2.6899 - val_accuracy: 0.5425\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.6783 - accuracy: 0.5630 - val_loss: 2.6800 - val_accuracy: 0.5448\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.6684 - accuracy: 0.5634 - val_loss: 2.6701 - val_accuracy: 0.5448\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 2.6586 - accuracy: 0.5634 - val_loss: 2.6602 - val_accuracy: 0.5471\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 2.6488 - accuracy: 0.5626 - val_loss: 2.6503 - val_accuracy: 0.5517\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 2.6389 - accuracy: 0.5630 - val_loss: 2.6404 - val_accuracy: 0.5540\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.6291 - accuracy: 0.5634 - val_loss: 2.6305 - val_accuracy: 0.5540\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.6193 - accuracy: 0.5650 - val_loss: 2.6206 - val_accuracy: 0.5540\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 2.6095 - accuracy: 0.5650 - val_loss: 2.6108 - val_accuracy: 0.5563\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.5997 - accuracy: 0.5659 - val_loss: 2.6009 - val_accuracy: 0.5563\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.5899 - accuracy: 0.5654 - val_loss: 2.5910 - val_accuracy: 0.5563\n",
      "2895/2895 [==============================] - 0s 22us/sample - loss: 2.5859 - accuracy: 0.5648\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 193us/sample - loss: 3.6628 - accuracy: 0.0110 - val_loss: 3.6133 - val_accuracy: 0.0207\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.5681 - accuracy: 0.0285 - val_loss: 3.5189 - val_accuracy: 0.0529\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 3.4756 - accuracy: 0.0854 - val_loss: 3.4264 - val_accuracy: 0.1264\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.3847 - accuracy: 0.1829 - val_loss: 3.3353 - val_accuracy: 0.2529\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.2951 - accuracy: 0.3004 - val_loss: 3.2452 - val_accuracy: 0.3540\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.2062 - accuracy: 0.4093 - val_loss: 3.1558 - val_accuracy: 0.4690\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.1179 - accuracy: 0.4663 - val_loss: 3.0669 - val_accuracy: 0.4943\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.0298 - accuracy: 0.4951 - val_loss: 2.9782 - val_accuracy: 0.5103\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 2.9418 - accuracy: 0.5069 - val_loss: 2.8894 - val_accuracy: 0.5195\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 2.8537 - accuracy: 0.5122 - val_loss: 2.8007 - val_accuracy: 0.5218\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.7656 - accuracy: 0.5207 - val_loss: 2.7120 - val_accuracy: 0.5172\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.6776 - accuracy: 0.5260 - val_loss: 2.6236 - val_accuracy: 0.5264\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.5897 - accuracy: 0.5321 - val_loss: 2.5355 - val_accuracy: 0.5310\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 2.5024 - accuracy: 0.5366 - val_loss: 2.4482 - val_accuracy: 0.5356\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 2.4158 - accuracy: 0.5354 - val_loss: 2.3619 - val_accuracy: 0.5425\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.3303 - accuracy: 0.5402 - val_loss: 2.2769 - val_accuracy: 0.5448\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.2462 - accuracy: 0.5382 - val_loss: 2.1938 - val_accuracy: 0.5471\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.1637 - accuracy: 0.5390 - val_loss: 2.1125 - val_accuracy: 0.5448\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.0832 - accuracy: 0.5415 - val_loss: 2.0334 - val_accuracy: 0.5448\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 2.0049 - accuracy: 0.5423 - val_loss: 1.9567 - val_accuracy: 0.5471\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 1.9291 - accuracy: 0.5443 - val_loss: 1.8827 - val_accuracy: 0.5471\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 1.8559 - accuracy: 0.5443 - val_loss: 1.8113 - val_accuracy: 0.5517\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.7854 - accuracy: 0.5447 - val_loss: 1.7428 - val_accuracy: 0.5517\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.7177 - accuracy: 0.5467 - val_loss: 1.6771 - val_accuracy: 0.5540\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.6529 - accuracy: 0.5484 - val_loss: 1.6144 - val_accuracy: 0.5494\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.5911 - accuracy: 0.5500 - val_loss: 1.5547 - val_accuracy: 0.5494\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.5323 - accuracy: 0.5520 - val_loss: 1.4981 - val_accuracy: 0.5494\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.4766 - accuracy: 0.5512 - val_loss: 1.4446 - val_accuracy: 0.5517\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 1.4239 - accuracy: 0.5512 - val_loss: 1.3941 - val_accuracy: 0.5563\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.3744 - accuracy: 0.5512 - val_loss: 1.3467 - val_accuracy: 0.5609\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 1.3278 - accuracy: 0.5512 - val_loss: 1.3023 - val_accuracy: 0.5586\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 1.2843 - accuracy: 0.5524 - val_loss: 1.2609 - val_accuracy: 0.5655\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.2437 - accuracy: 0.5545 - val_loss: 1.2223 - val_accuracy: 0.5701\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.2058 - accuracy: 0.5561 - val_loss: 1.1865 - val_accuracy: 0.5816\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.1707 - accuracy: 0.5585 - val_loss: 1.1532 - val_accuracy: 0.5862\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.1381 - accuracy: 0.5663 - val_loss: 1.1224 - val_accuracy: 0.5839\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.1080 - accuracy: 0.5679 - val_loss: 1.0940 - val_accuracy: 0.5885\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.0801 - accuracy: 0.5675 - val_loss: 1.0677 - val_accuracy: 0.5954\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 1.0544 - accuracy: 0.5711 - val_loss: 1.0435 - val_accuracy: 0.6046\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.0307 - accuracy: 0.5752 - val_loss: 1.0211 - val_accuracy: 0.6092\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 1.0088 - accuracy: 0.5780 - val_loss: 1.0005 - val_accuracy: 0.6023\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.9886 - accuracy: 0.5780 - val_loss: 0.9814 - val_accuracy: 0.5954\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.9698 - accuracy: 0.5805 - val_loss: 0.9638 - val_accuracy: 0.5954\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.9526 - accuracy: 0.5817 - val_loss: 0.9476 - val_accuracy: 0.5954\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.9366 - accuracy: 0.5837 - val_loss: 0.9325 - val_accuracy: 0.5954\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.9218 - accuracy: 0.5858 - val_loss: 0.9186 - val_accuracy: 0.5908\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.9081 - accuracy: 0.5841 - val_loss: 0.9057 - val_accuracy: 0.5885\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8953 - accuracy: 0.5878 - val_loss: 0.8937 - val_accuracy: 0.5977\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8835 - accuracy: 0.5898 - val_loss: 0.8825 - val_accuracy: 0.5908\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8725 - accuracy: 0.5915 - val_loss: 0.8721 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8622 - accuracy: 0.5943 - val_loss: 0.8625 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.8527 - accuracy: 0.5947 - val_loss: 0.8534 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.8437 - accuracy: 0.5959 - val_loss: 0.8450 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.8353 - accuracy: 0.5947 - val_loss: 0.8371 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.8275 - accuracy: 0.5972 - val_loss: 0.8297 - val_accuracy: 0.6023\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.8201 - accuracy: 0.5972 - val_loss: 0.8227 - val_accuracy: 0.6023\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.8132 - accuracy: 0.5959 - val_loss: 0.8162 - val_accuracy: 0.6023\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8067 - accuracy: 0.5988 - val_loss: 0.8101 - val_accuracy: 0.6023\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8005 - accuracy: 0.6024 - val_loss: 0.8043 - val_accuracy: 0.6046\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7948 - accuracy: 0.6012 - val_loss: 0.7988 - val_accuracy: 0.6046\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.7893 - accuracy: 0.6008 - val_loss: 0.7936 - val_accuracy: 0.6069\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7842 - accuracy: 0.6024 - val_loss: 0.7888 - val_accuracy: 0.6069\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7793 - accuracy: 0.6045 - val_loss: 0.7842 - val_accuracy: 0.6069\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7746 - accuracy: 0.6037 - val_loss: 0.7798 - val_accuracy: 0.6092\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7702 - accuracy: 0.6049 - val_loss: 0.7757 - val_accuracy: 0.6069\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.7661 - accuracy: 0.6073 - val_loss: 0.7717 - val_accuracy: 0.6069\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7621 - accuracy: 0.6077 - val_loss: 0.7680 - val_accuracy: 0.6069\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7583 - accuracy: 0.6106 - val_loss: 0.7644 - val_accuracy: 0.6069\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7547 - accuracy: 0.6106 - val_loss: 0.7611 - val_accuracy: 0.6069\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7513 - accuracy: 0.6098 - val_loss: 0.7579 - val_accuracy: 0.6069\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7480 - accuracy: 0.6122 - val_loss: 0.7548 - val_accuracy: 0.6092\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7448 - accuracy: 0.6114 - val_loss: 0.7518 - val_accuracy: 0.6092\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.7418 - accuracy: 0.6114 - val_loss: 0.7490 - val_accuracy: 0.6115\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7390 - accuracy: 0.6154 - val_loss: 0.7463 - val_accuracy: 0.6138\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.7362 - accuracy: 0.6130 - val_loss: 0.7437 - val_accuracy: 0.6138\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7335 - accuracy: 0.6154 - val_loss: 0.7412 - val_accuracy: 0.6138\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7310 - accuracy: 0.6159 - val_loss: 0.7389 - val_accuracy: 0.6184\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.7285 - accuracy: 0.6154 - val_loss: 0.7366 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7262 - accuracy: 0.6142 - val_loss: 0.7344 - val_accuracy: 0.6230\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7239 - accuracy: 0.6171 - val_loss: 0.7323 - val_accuracy: 0.6230\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7217 - accuracy: 0.6171 - val_loss: 0.7302 - val_accuracy: 0.6230\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.7196 - accuracy: 0.6175 - val_loss: 0.7283 - val_accuracy: 0.6253\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7176 - accuracy: 0.6195 - val_loss: 0.7264 - val_accuracy: 0.6253\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.7156 - accuracy: 0.6171 - val_loss: 0.7246 - val_accuracy: 0.6276\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7137 - accuracy: 0.6203 - val_loss: 0.7228 - val_accuracy: 0.6276\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.7118 - accuracy: 0.6211 - val_loss: 0.7211 - val_accuracy: 0.6276\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7101 - accuracy: 0.6207 - val_loss: 0.7194 - val_accuracy: 0.6276\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7084 - accuracy: 0.6215 - val_loss: 0.7178 - val_accuracy: 0.6276\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7067 - accuracy: 0.6220 - val_loss: 0.7163 - val_accuracy: 0.6276\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7050 - accuracy: 0.6215 - val_loss: 0.7148 - val_accuracy: 0.6276\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7035 - accuracy: 0.6252 - val_loss: 0.7133 - val_accuracy: 0.6276\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.7020 - accuracy: 0.6244 - val_loss: 0.7119 - val_accuracy: 0.6276\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7004 - accuracy: 0.6268 - val_loss: 0.7106 - val_accuracy: 0.6276\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.6990 - accuracy: 0.6268 - val_loss: 0.7093 - val_accuracy: 0.6253\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.6976 - accuracy: 0.6280 - val_loss: 0.7080 - val_accuracy: 0.6253\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6962 - accuracy: 0.6268 - val_loss: 0.7067 - val_accuracy: 0.6276\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6949 - accuracy: 0.6285 - val_loss: 0.7055 - val_accuracy: 0.6253\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6936 - accuracy: 0.6268 - val_loss: 0.7043 - val_accuracy: 0.6253\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6923 - accuracy: 0.6289 - val_loss: 0.7032 - val_accuracy: 0.6253\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6911 - accuracy: 0.6301 - val_loss: 0.7021 - val_accuracy: 0.6253\n",
      "2895/2895 [==============================] - 0s 26us/sample - loss: 0.6921 - accuracy: 0.6297\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 126us/sample - loss: 2.9492 - accuracy: 0.4004 - val_loss: 2.4563 - val_accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.0234 - accuracy: 0.5553 - val_loss: 1.6258 - val_accuracy: 0.5563\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.3711 - accuracy: 0.5614 - val_loss: 1.1639 - val_accuracy: 0.5517\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.0391 - accuracy: 0.5752 - val_loss: 0.9464 - val_accuracy: 0.5655\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.8814 - accuracy: 0.5870 - val_loss: 0.8407 - val_accuracy: 0.5724\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.8008 - accuracy: 0.5963 - val_loss: 0.7831 - val_accuracy: 0.5885\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7549 - accuracy: 0.5988 - val_loss: 0.7492 - val_accuracy: 0.6046\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7257 - accuracy: 0.6142 - val_loss: 0.7290 - val_accuracy: 0.5977\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7075 - accuracy: 0.6207 - val_loss: 0.7123 - val_accuracy: 0.6115\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.6928 - accuracy: 0.6280 - val_loss: 0.7004 - val_accuracy: 0.6184\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.6820 - accuracy: 0.6337 - val_loss: 0.6910 - val_accuracy: 0.6253\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.6726 - accuracy: 0.6358 - val_loss: 0.6844 - val_accuracy: 0.6207\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.6653 - accuracy: 0.6431 - val_loss: 0.6774 - val_accuracy: 0.6230\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6585 - accuracy: 0.6435 - val_loss: 0.6733 - val_accuracy: 0.6184\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6534 - accuracy: 0.6476 - val_loss: 0.6694 - val_accuracy: 0.6230\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6485 - accuracy: 0.6459 - val_loss: 0.6657 - val_accuracy: 0.6253\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6450 - accuracy: 0.6557 - val_loss: 0.6615 - val_accuracy: 0.6437\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6404 - accuracy: 0.6545 - val_loss: 0.6580 - val_accuracy: 0.6368\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6360 - accuracy: 0.6573 - val_loss: 0.6598 - val_accuracy: 0.6253\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6345 - accuracy: 0.6541 - val_loss: 0.6537 - val_accuracy: 0.6460\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.6311 - accuracy: 0.6630 - val_loss: 0.6515 - val_accuracy: 0.6598\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6284 - accuracy: 0.6589 - val_loss: 0.6492 - val_accuracy: 0.6529\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6262 - accuracy: 0.6610 - val_loss: 0.6469 - val_accuracy: 0.6552\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6234 - accuracy: 0.6642 - val_loss: 0.6454 - val_accuracy: 0.6460\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.6218 - accuracy: 0.6614 - val_loss: 0.6436 - val_accuracy: 0.6529\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6192 - accuracy: 0.6679 - val_loss: 0.6431 - val_accuracy: 0.6575\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6178 - accuracy: 0.6654 - val_loss: 0.6409 - val_accuracy: 0.6644\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6148 - accuracy: 0.6703 - val_loss: 0.6421 - val_accuracy: 0.6552\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6143 - accuracy: 0.6675 - val_loss: 0.6380 - val_accuracy: 0.6621\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.6123 - accuracy: 0.6707 - val_loss: 0.6367 - val_accuracy: 0.6621\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6107 - accuracy: 0.6732 - val_loss: 0.6376 - val_accuracy: 0.6529\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6099 - accuracy: 0.6732 - val_loss: 0.6346 - val_accuracy: 0.6598\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.6082 - accuracy: 0.6776 - val_loss: 0.6339 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.6070 - accuracy: 0.6724 - val_loss: 0.6335 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.6055 - accuracy: 0.6720 - val_loss: 0.6316 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.6043 - accuracy: 0.6789 - val_loss: 0.6305 - val_accuracy: 0.6644\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6033 - accuracy: 0.6756 - val_loss: 0.6299 - val_accuracy: 0.6644\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6025 - accuracy: 0.6760 - val_loss: 0.6297 - val_accuracy: 0.6713\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.6008 - accuracy: 0.6785 - val_loss: 0.6283 - val_accuracy: 0.6621\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5996 - accuracy: 0.6764 - val_loss: 0.6276 - val_accuracy: 0.6713\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5989 - accuracy: 0.6793 - val_loss: 0.6272 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5978 - accuracy: 0.6789 - val_loss: 0.6263 - val_accuracy: 0.6690\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5966 - accuracy: 0.6825 - val_loss: 0.6257 - val_accuracy: 0.6644\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5958 - accuracy: 0.6854 - val_loss: 0.6242 - val_accuracy: 0.6736\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5945 - accuracy: 0.6837 - val_loss: 0.6253 - val_accuracy: 0.6598\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5938 - accuracy: 0.6866 - val_loss: 0.6242 - val_accuracy: 0.6644\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5931 - accuracy: 0.6805 - val_loss: 0.6235 - val_accuracy: 0.6598\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5924 - accuracy: 0.6841 - val_loss: 0.6237 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5918 - accuracy: 0.6911 - val_loss: 0.6217 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5913 - accuracy: 0.6858 - val_loss: 0.6208 - val_accuracy: 0.6690\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5899 - accuracy: 0.6894 - val_loss: 0.6213 - val_accuracy: 0.6575\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5900 - accuracy: 0.6870 - val_loss: 0.6199 - val_accuracy: 0.6713\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5889 - accuracy: 0.6915 - val_loss: 0.6192 - val_accuracy: 0.6690\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5880 - accuracy: 0.6939 - val_loss: 0.6188 - val_accuracy: 0.6713\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5872 - accuracy: 0.6915 - val_loss: 0.6197 - val_accuracy: 0.6598\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5866 - accuracy: 0.6927 - val_loss: 0.6185 - val_accuracy: 0.6759\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5860 - accuracy: 0.6886 - val_loss: 0.6188 - val_accuracy: 0.6736\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5854 - accuracy: 0.6894 - val_loss: 0.6183 - val_accuracy: 0.6736\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5854 - accuracy: 0.6898 - val_loss: 0.6175 - val_accuracy: 0.6598\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5845 - accuracy: 0.6935 - val_loss: 0.6161 - val_accuracy: 0.6759\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5839 - accuracy: 0.6935 - val_loss: 0.6161 - val_accuracy: 0.6690\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5836 - accuracy: 0.6976 - val_loss: 0.6154 - val_accuracy: 0.6644\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5825 - accuracy: 0.6939 - val_loss: 0.6153 - val_accuracy: 0.6782\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5817 - accuracy: 0.6996 - val_loss: 0.6157 - val_accuracy: 0.6621\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5812 - accuracy: 0.6972 - val_loss: 0.6165 - val_accuracy: 0.6644\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5817 - accuracy: 0.6955 - val_loss: 0.6141 - val_accuracy: 0.6690\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5812 - accuracy: 0.6935 - val_loss: 0.6139 - val_accuracy: 0.6644\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5796 - accuracy: 0.7033 - val_loss: 0.6159 - val_accuracy: 0.6552\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5800 - accuracy: 0.6923 - val_loss: 0.6131 - val_accuracy: 0.6713\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5796 - accuracy: 0.7016 - val_loss: 0.6132 - val_accuracy: 0.6598\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5797 - accuracy: 0.6980 - val_loss: 0.6139 - val_accuracy: 0.6552\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5790 - accuracy: 0.7004 - val_loss: 0.6151 - val_accuracy: 0.6644\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5787 - accuracy: 0.7008 - val_loss: 0.6135 - val_accuracy: 0.6598\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5778 - accuracy: 0.7033 - val_loss: 0.6135 - val_accuracy: 0.6575\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5770 - accuracy: 0.7008 - val_loss: 0.6132 - val_accuracy: 0.6736\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5770 - accuracy: 0.7073 - val_loss: 0.6114 - val_accuracy: 0.6828\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5769 - accuracy: 0.7061 - val_loss: 0.6124 - val_accuracy: 0.6621\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5768 - accuracy: 0.7000 - val_loss: 0.6117 - val_accuracy: 0.6621\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5761 - accuracy: 0.7028 - val_loss: 0.6110 - val_accuracy: 0.6713\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5767 - accuracy: 0.7016 - val_loss: 0.6120 - val_accuracy: 0.6621\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5758 - accuracy: 0.7053 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5755 - accuracy: 0.7061 - val_loss: 0.6117 - val_accuracy: 0.6644\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5752 - accuracy: 0.7061 - val_loss: 0.6118 - val_accuracy: 0.6621\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5750 - accuracy: 0.7057 - val_loss: 0.6108 - val_accuracy: 0.6644\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5745 - accuracy: 0.7049 - val_loss: 0.6113 - val_accuracy: 0.6598\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5748 - accuracy: 0.7065 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5739 - accuracy: 0.7077 - val_loss: 0.6111 - val_accuracy: 0.6621\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5739 - accuracy: 0.7065 - val_loss: 0.6107 - val_accuracy: 0.6621\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5734 - accuracy: 0.7073 - val_loss: 0.6129 - val_accuracy: 0.6713\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5733 - accuracy: 0.7037 - val_loss: 0.6096 - val_accuracy: 0.6713\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5726 - accuracy: 0.7073 - val_loss: 0.6099 - val_accuracy: 0.6644\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5727 - accuracy: 0.7065 - val_loss: 0.6098 - val_accuracy: 0.6644\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5728 - accuracy: 0.7065 - val_loss: 0.6108 - val_accuracy: 0.6621\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5716 - accuracy: 0.7085 - val_loss: 0.6137 - val_accuracy: 0.6598\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5717 - accuracy: 0.7069 - val_loss: 0.6110 - val_accuracy: 0.6644\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5717 - accuracy: 0.7061 - val_loss: 0.6104 - val_accuracy: 0.6759\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5712 - accuracy: 0.7093 - val_loss: 0.6096 - val_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5711 - accuracy: 0.7077 - val_loss: 0.6108 - val_accuracy: 0.6644\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5707 - accuracy: 0.7098 - val_loss: 0.6119 - val_accuracy: 0.6713\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5708 - accuracy: 0.7057 - val_loss: 0.6110 - val_accuracy: 0.6667\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.5753 - accuracy: 0.7022\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 178us/sample - loss: 1.1678 - accuracy: 0.5524 - val_loss: 0.7033 - val_accuracy: 0.6161\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6670 - accuracy: 0.6175 - val_loss: 0.6643 - val_accuracy: 0.6161\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6388 - accuracy: 0.6455 - val_loss: 0.6479 - val_accuracy: 0.6552\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.6201 - accuracy: 0.6618 - val_loss: 0.6479 - val_accuracy: 0.6391\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6137 - accuracy: 0.6646 - val_loss: 0.6348 - val_accuracy: 0.6437\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.6026 - accuracy: 0.6817 - val_loss: 0.6379 - val_accuracy: 0.6414\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5981 - accuracy: 0.6829 - val_loss: 0.6200 - val_accuracy: 0.6575\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5997 - accuracy: 0.6809 - val_loss: 0.6160 - val_accuracy: 0.6598\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5887 - accuracy: 0.6902 - val_loss: 0.6246 - val_accuracy: 0.6713\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5915 - accuracy: 0.6854 - val_loss: 0.6299 - val_accuracy: 0.6575\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5785 - accuracy: 0.7024 - val_loss: 0.6353 - val_accuracy: 0.6506\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5822 - accuracy: 0.6959 - val_loss: 0.6459 - val_accuracy: 0.6529\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5789 - accuracy: 0.6967 - val_loss: 0.6276 - val_accuracy: 0.6621\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5799 - accuracy: 0.6967 - val_loss: 0.6266 - val_accuracy: 0.6506\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5710 - accuracy: 0.6980 - val_loss: 0.6217 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5766 - accuracy: 0.7008 - val_loss: 0.6125 - val_accuracy: 0.6598\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5710 - accuracy: 0.6980 - val_loss: 0.6146 - val_accuracy: 0.6713\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5718 - accuracy: 0.7004 - val_loss: 0.6114 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5695 - accuracy: 0.7037 - val_loss: 0.6194 - val_accuracy: 0.6552\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5688 - accuracy: 0.6976 - val_loss: 0.6244 - val_accuracy: 0.6575\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5698 - accuracy: 0.6988 - val_loss: 0.6466 - val_accuracy: 0.6598\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5704 - accuracy: 0.6992 - val_loss: 0.6179 - val_accuracy: 0.6713\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5672 - accuracy: 0.7037 - val_loss: 0.6212 - val_accuracy: 0.6598\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5650 - accuracy: 0.7041 - val_loss: 0.6155 - val_accuracy: 0.6644\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5627 - accuracy: 0.7085 - val_loss: 0.6231 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5614 - accuracy: 0.7110 - val_loss: 0.6173 - val_accuracy: 0.6736\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5550 - accuracy: 0.7146 - val_loss: 0.6136 - val_accuracy: 0.6621\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5599 - accuracy: 0.7061 - val_loss: 0.6401 - val_accuracy: 0.6437\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5527 - accuracy: 0.7073 - val_loss: 0.6183 - val_accuracy: 0.6690\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5546 - accuracy: 0.7114 - val_loss: 0.6215 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5560 - accuracy: 0.7061 - val_loss: 0.6262 - val_accuracy: 0.6690\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5557 - accuracy: 0.7098 - val_loss: 0.6291 - val_accuracy: 0.6483\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5495 - accuracy: 0.7126 - val_loss: 0.6329 - val_accuracy: 0.6621\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5500 - accuracy: 0.7199 - val_loss: 0.6202 - val_accuracy: 0.6736\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5477 - accuracy: 0.7110 - val_loss: 0.6269 - val_accuracy: 0.6782\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5486 - accuracy: 0.7195 - val_loss: 0.6255 - val_accuracy: 0.6828\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5443 - accuracy: 0.7224 - val_loss: 0.6291 - val_accuracy: 0.6782\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5457 - accuracy: 0.7187 - val_loss: 0.6234 - val_accuracy: 0.6552\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5406 - accuracy: 0.7224 - val_loss: 0.6252 - val_accuracy: 0.6713\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5423 - accuracy: 0.7171 - val_loss: 0.6397 - val_accuracy: 0.6644\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5390 - accuracy: 0.7207 - val_loss: 0.6690 - val_accuracy: 0.6230\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5361 - accuracy: 0.7256 - val_loss: 0.6274 - val_accuracy: 0.6736\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5350 - accuracy: 0.7215 - val_loss: 0.6347 - val_accuracy: 0.6598\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5330 - accuracy: 0.7276 - val_loss: 0.6233 - val_accuracy: 0.6805\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5314 - accuracy: 0.7289 - val_loss: 0.6330 - val_accuracy: 0.6529\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5240 - accuracy: 0.7329 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5238 - accuracy: 0.7346 - val_loss: 0.6346 - val_accuracy: 0.6690\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5233 - accuracy: 0.7301 - val_loss: 0.6446 - val_accuracy: 0.6529\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5212 - accuracy: 0.7333 - val_loss: 0.6624 - val_accuracy: 0.6483\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5221 - accuracy: 0.7390 - val_loss: 0.6320 - val_accuracy: 0.6736\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5241 - accuracy: 0.7374 - val_loss: 0.6375 - val_accuracy: 0.6621\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5185 - accuracy: 0.7423 - val_loss: 0.6378 - val_accuracy: 0.6621\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5235 - accuracy: 0.7398 - val_loss: 0.6549 - val_accuracy: 0.6690\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5195 - accuracy: 0.7317 - val_loss: 0.6629 - val_accuracy: 0.6460\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5082 - accuracy: 0.7427 - val_loss: 0.6465 - val_accuracy: 0.6621\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5127 - accuracy: 0.7329 - val_loss: 0.6422 - val_accuracy: 0.6621\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5156 - accuracy: 0.7378 - val_loss: 0.6527 - val_accuracy: 0.6621\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5128 - accuracy: 0.7427 - val_loss: 0.6846 - val_accuracy: 0.6391\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5029 - accuracy: 0.7492 - val_loss: 0.6757 - val_accuracy: 0.6345\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5023 - accuracy: 0.7496 - val_loss: 0.6494 - val_accuracy: 0.6736\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4968 - accuracy: 0.7598 - val_loss: 0.6791 - val_accuracy: 0.6644\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5106 - accuracy: 0.7455 - val_loss: 0.6593 - val_accuracy: 0.6529\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4946 - accuracy: 0.7561 - val_loss: 0.6899 - val_accuracy: 0.6253\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4915 - accuracy: 0.7545 - val_loss: 0.6672 - val_accuracy: 0.6483\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4904 - accuracy: 0.7561 - val_loss: 0.6641 - val_accuracy: 0.6621\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4883 - accuracy: 0.7606 - val_loss: 0.6780 - val_accuracy: 0.6529\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4891 - accuracy: 0.7614 - val_loss: 0.6970 - val_accuracy: 0.6368\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4962 - accuracy: 0.7496 - val_loss: 0.8039 - val_accuracy: 0.6391\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4925 - accuracy: 0.7553 - val_loss: 0.6910 - val_accuracy: 0.6253\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4915 - accuracy: 0.7484 - val_loss: 0.6861 - val_accuracy: 0.6322\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.4831 - accuracy: 0.7663 - val_loss: 0.7417 - val_accuracy: 0.6552\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4852 - accuracy: 0.7687 - val_loss: 0.6754 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4815 - accuracy: 0.7699 - val_loss: 0.6801 - val_accuracy: 0.6644\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4784 - accuracy: 0.7557 - val_loss: 0.6815 - val_accuracy: 0.6506\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4731 - accuracy: 0.7667 - val_loss: 0.6904 - val_accuracy: 0.6414\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4731 - accuracy: 0.7659 - val_loss: 0.6840 - val_accuracy: 0.6575\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4810 - accuracy: 0.7602 - val_loss: 0.7000 - val_accuracy: 0.6437\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4775 - accuracy: 0.7728 - val_loss: 0.7189 - val_accuracy: 0.6575\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.4824 - accuracy: 0.7659 - val_loss: 0.6962 - val_accuracy: 0.6621\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4643 - accuracy: 0.7772 - val_loss: 0.7280 - val_accuracy: 0.6161\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4769 - accuracy: 0.7650 - val_loss: 0.7472 - val_accuracy: 0.6069\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.4774 - accuracy: 0.7683 - val_loss: 0.7290 - val_accuracy: 0.6345\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4747 - accuracy: 0.7626 - val_loss: 0.7021 - val_accuracy: 0.6644\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4638 - accuracy: 0.7724 - val_loss: 0.7283 - val_accuracy: 0.6207\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4687 - accuracy: 0.7752 - val_loss: 0.7152 - val_accuracy: 0.6690\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4569 - accuracy: 0.7720 - val_loss: 0.7417 - val_accuracy: 0.6322\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.7074 - val_accuracy: 0.6368\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4595 - accuracy: 0.7728 - val_loss: 0.7065 - val_accuracy: 0.6483\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4532 - accuracy: 0.7886 - val_loss: 0.7156 - val_accuracy: 0.6483\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.7084 - val_accuracy: 0.6483\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4506 - accuracy: 0.7846 - val_loss: 0.7298 - val_accuracy: 0.6552\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.4619 - accuracy: 0.7780 - val_loss: 0.7270 - val_accuracy: 0.6437\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4479 - accuracy: 0.7886 - val_loss: 0.7276 - val_accuracy: 0.6506\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4486 - accuracy: 0.7878 - val_loss: 0.7540 - val_accuracy: 0.6529\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4471 - accuracy: 0.7841 - val_loss: 0.7384 - val_accuracy: 0.6322\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4545 - accuracy: 0.7821 - val_loss: 0.8396 - val_accuracy: 0.5885\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.7841 - val_loss: 0.7377 - val_accuracy: 0.6460\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4486 - accuracy: 0.7858 - val_loss: 0.7349 - val_accuracy: 0.6437\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4345 - accuracy: 0.7866 - val_loss: 0.7276 - val_accuracy: 0.6345\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4340 - accuracy: 0.7911 - val_loss: 0.7702 - val_accuracy: 0.6575\n",
      "2895/2895 [==============================] - 0s 27us/sample - loss: 0.4828 - accuracy: 0.7807\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 139us/sample - loss: 0.8580 - accuracy: 0.5715 - val_loss: 0.6571 - val_accuracy: 0.6575\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6743 - accuracy: 0.6366 - val_loss: 0.6086 - val_accuracy: 0.6644\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6377 - accuracy: 0.6533 - val_loss: 0.6285 - val_accuracy: 0.6552\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6217 - accuracy: 0.6606 - val_loss: 0.6850 - val_accuracy: 0.6276\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 0.6192 - accuracy: 0.6663 - val_loss: 0.6677 - val_accuracy: 0.6414\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6040 - accuracy: 0.6789 - val_loss: 0.6597 - val_accuracy: 0.6414\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6038 - accuracy: 0.6785 - val_loss: 0.6314 - val_accuracy: 0.6483\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6035 - accuracy: 0.6789 - val_loss: 0.6394 - val_accuracy: 0.6552\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5852 - accuracy: 0.6874 - val_loss: 0.6295 - val_accuracy: 0.6391\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5877 - accuracy: 0.6850 - val_loss: 0.6254 - val_accuracy: 0.6575\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5803 - accuracy: 0.6955 - val_loss: 0.6534 - val_accuracy: 0.6391\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.5727 - accuracy: 0.6980 - val_loss: 0.6423 - val_accuracy: 0.6713\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5648 - accuracy: 0.7085 - val_loss: 0.6586 - val_accuracy: 0.6506\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5696 - accuracy: 0.7089 - val_loss: 0.6547 - val_accuracy: 0.6230\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5564 - accuracy: 0.7110 - val_loss: 0.6596 - val_accuracy: 0.6437\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5482 - accuracy: 0.7211 - val_loss: 0.6625 - val_accuracy: 0.6345\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5535 - accuracy: 0.7199 - val_loss: 0.6722 - val_accuracy: 0.6598\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5484 - accuracy: 0.7232 - val_loss: 0.6704 - val_accuracy: 0.6460\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5388 - accuracy: 0.7370 - val_loss: 0.6452 - val_accuracy: 0.6368\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5360 - accuracy: 0.7321 - val_loss: 0.6819 - val_accuracy: 0.6414\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5242 - accuracy: 0.7362 - val_loss: 0.6830 - val_accuracy: 0.6483\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5296 - accuracy: 0.7411 - val_loss: 0.7098 - val_accuracy: 0.6552\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5100 - accuracy: 0.7463 - val_loss: 0.7398 - val_accuracy: 0.6414\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5158 - accuracy: 0.7451 - val_loss: 0.6857 - val_accuracy: 0.6322\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5027 - accuracy: 0.7598 - val_loss: 0.7252 - val_accuracy: 0.6161\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5170 - accuracy: 0.7476 - val_loss: 0.7162 - val_accuracy: 0.6460\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5108 - accuracy: 0.7593 - val_loss: 0.7116 - val_accuracy: 0.6621\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5047 - accuracy: 0.7589 - val_loss: 0.7446 - val_accuracy: 0.6184\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4931 - accuracy: 0.7675 - val_loss: 0.7606 - val_accuracy: 0.6598\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4952 - accuracy: 0.7691 - val_loss: 0.7280 - val_accuracy: 0.6460\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4715 - accuracy: 0.7797 - val_loss: 0.7515 - val_accuracy: 0.6506\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4903 - accuracy: 0.7691 - val_loss: 0.7781 - val_accuracy: 0.6598\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.4665 - accuracy: 0.7805 - val_loss: 0.7821 - val_accuracy: 0.6644\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4669 - accuracy: 0.7846 - val_loss: 0.8235 - val_accuracy: 0.6483\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4583 - accuracy: 0.7829 - val_loss: 0.7535 - val_accuracy: 0.6437\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4581 - accuracy: 0.7846 - val_loss: 0.8205 - val_accuracy: 0.6023\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4662 - accuracy: 0.7878 - val_loss: 0.7919 - val_accuracy: 0.6460\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4532 - accuracy: 0.7972 - val_loss: 0.8395 - val_accuracy: 0.6092\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.4533 - accuracy: 0.7963 - val_loss: 0.7939 - val_accuracy: 0.6230\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4518 - accuracy: 0.7915 - val_loss: 0.8403 - val_accuracy: 0.6621\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4385 - accuracy: 0.8008 - val_loss: 0.8117 - val_accuracy: 0.6345\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4380 - accuracy: 0.7980 - val_loss: 0.8490 - val_accuracy: 0.6092\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4334 - accuracy: 0.8004 - val_loss: 0.8653 - val_accuracy: 0.6184\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4599 - accuracy: 0.7976 - val_loss: 0.8096 - val_accuracy: 0.6368\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4204 - accuracy: 0.8073 - val_loss: 0.8442 - val_accuracy: 0.6506\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.4064 - accuracy: 0.8065 - val_loss: 0.8710 - val_accuracy: 0.6506\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4080 - accuracy: 0.8179 - val_loss: 0.8387 - val_accuracy: 0.6575\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4470 - accuracy: 0.7972 - val_loss: 0.8623 - val_accuracy: 0.6276\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4028 - accuracy: 0.8159 - val_loss: 0.9180 - val_accuracy: 0.6368\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3841 - accuracy: 0.8313 - val_loss: 0.9936 - val_accuracy: 0.6046\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.4122 - accuracy: 0.8187 - val_loss: 0.9538 - val_accuracy: 0.6069\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3962 - accuracy: 0.8150 - val_loss: 0.9025 - val_accuracy: 0.6207\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.3815 - accuracy: 0.8402 - val_loss: 0.9902 - val_accuracy: 0.6230\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3738 - accuracy: 0.8346 - val_loss: 1.0500 - val_accuracy: 0.6437\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4044 - accuracy: 0.8199 - val_loss: 0.9403 - val_accuracy: 0.6322\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4031 - accuracy: 0.8268 - val_loss: 0.9335 - val_accuracy: 0.6276\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3863 - accuracy: 0.8329 - val_loss: 0.9151 - val_accuracy: 0.6184\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3715 - accuracy: 0.8394 - val_loss: 0.9389 - val_accuracy: 0.6322\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.3690 - accuracy: 0.8390 - val_loss: 1.0028 - val_accuracy: 0.6437\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3761 - accuracy: 0.8333 - val_loss: 1.0181 - val_accuracy: 0.6299\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.3501 - accuracy: 0.8476 - val_loss: 1.0384 - val_accuracy: 0.6437\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3699 - accuracy: 0.8354 - val_loss: 0.9707 - val_accuracy: 0.6138\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.3734 - accuracy: 0.8382 - val_loss: 0.9879 - val_accuracy: 0.6414\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3604 - accuracy: 0.8346 - val_loss: 1.1360 - val_accuracy: 0.5977\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3682 - accuracy: 0.8305 - val_loss: 1.0388 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3312 - accuracy: 0.8533 - val_loss: 1.0685 - val_accuracy: 0.6414\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.3549 - accuracy: 0.8362 - val_loss: 1.0586 - val_accuracy: 0.6276\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3293 - accuracy: 0.8585 - val_loss: 1.1300 - val_accuracy: 0.6207\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3758 - accuracy: 0.8309 - val_loss: 1.1089 - val_accuracy: 0.6437\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3517 - accuracy: 0.8423 - val_loss: 1.0207 - val_accuracy: 0.6322\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3260 - accuracy: 0.8549 - val_loss: 1.0950 - val_accuracy: 0.6529\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3531 - accuracy: 0.8520 - val_loss: 1.0495 - val_accuracy: 0.6276\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3192 - accuracy: 0.8626 - val_loss: 1.1936 - val_accuracy: 0.6069\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3530 - accuracy: 0.8484 - val_loss: 1.1065 - val_accuracy: 0.6414\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.3214 - accuracy: 0.8606 - val_loss: 1.2871 - val_accuracy: 0.5885\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3369 - accuracy: 0.8646 - val_loss: 1.1438 - val_accuracy: 0.6506\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3150 - accuracy: 0.8569 - val_loss: 1.1651 - val_accuracy: 0.6138\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3229 - accuracy: 0.8667 - val_loss: 1.1369 - val_accuracy: 0.6299\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3384 - accuracy: 0.8492 - val_loss: 1.1205 - val_accuracy: 0.6575\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3258 - accuracy: 0.8622 - val_loss: 1.2951 - val_accuracy: 0.6506\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3085 - accuracy: 0.8638 - val_loss: 1.3056 - val_accuracy: 0.6069\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3193 - accuracy: 0.8646 - val_loss: 1.1880 - val_accuracy: 0.6621\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3047 - accuracy: 0.8622 - val_loss: 1.2988 - val_accuracy: 0.6069\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3202 - accuracy: 0.8626 - val_loss: 1.1803 - val_accuracy: 0.6253\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.2687 - accuracy: 0.8829 - val_loss: 1.3482 - val_accuracy: 0.6115\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3030 - accuracy: 0.8720 - val_loss: 1.3122 - val_accuracy: 0.6092\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3215 - accuracy: 0.8634 - val_loss: 1.2792 - val_accuracy: 0.6345\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3079 - accuracy: 0.8675 - val_loss: 1.2565 - val_accuracy: 0.6322\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3058 - accuracy: 0.8598 - val_loss: 1.2179 - val_accuracy: 0.6276\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3182 - accuracy: 0.8679 - val_loss: 1.3640 - val_accuracy: 0.6391\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.2913 - accuracy: 0.8740 - val_loss: 1.2913 - val_accuracy: 0.6345\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.2698 - accuracy: 0.8850 - val_loss: 1.3540 - val_accuracy: 0.6253\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.2883 - accuracy: 0.8821 - val_loss: 1.5430 - val_accuracy: 0.5655\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 0.3032 - accuracy: 0.8752 - val_loss: 1.2993 - val_accuracy: 0.6345\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.2825 - accuracy: 0.8813 - val_loss: 1.3863 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2616 - accuracy: 0.8866 - val_loss: 1.4764 - val_accuracy: 0.6092\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3010 - accuracy: 0.8785 - val_loss: 1.4238 - val_accuracy: 0.6253\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.2632 - accuracy: 0.8850 - val_loss: 1.3728 - val_accuracy: 0.6621\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3043 - accuracy: 0.8748 - val_loss: 1.3316 - val_accuracy: 0.6437\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.2709 - accuracy: 0.8890 - val_loss: 1.4080 - val_accuracy: 0.6414\n",
      "2895/2895 [==============================] - 0s 27us/sample - loss: 0.4000 - accuracy: 0.8674\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 130us/sample - loss: 3.7802 - accuracy: 0.0024 - val_loss: 3.7882 - val_accuracy: 0.0023\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.7799 - accuracy: 0.0024 - val_loss: 3.7879 - val_accuracy: 0.0023\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7797 - accuracy: 0.0024 - val_loss: 3.7876 - val_accuracy: 0.0023\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.7794 - accuracy: 0.0024 - val_loss: 3.7873 - val_accuracy: 0.0023\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.7791 - accuracy: 0.0024 - val_loss: 3.7870 - val_accuracy: 0.0023\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7788 - accuracy: 0.0024 - val_loss: 3.7867 - val_accuracy: 0.0023\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 3.7785 - accuracy: 0.0024 - val_loss: 3.7864 - val_accuracy: 0.0023\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.7781 - accuracy: 0.0024 - val_loss: 3.7860 - val_accuracy: 0.0023\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.7778 - accuracy: 0.0024 - val_loss: 3.7857 - val_accuracy: 0.0023\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.7775 - accuracy: 0.0024 - val_loss: 3.7853 - val_accuracy: 0.0023\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.7771 - accuracy: 0.0024 - val_loss: 3.7850 - val_accuracy: 0.0023\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7768 - accuracy: 0.0024 - val_loss: 3.7847 - val_accuracy: 0.0023\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7765 - accuracy: 0.0024 - val_loss: 3.7843 - val_accuracy: 0.0023\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.7761 - accuracy: 0.0024 - val_loss: 3.7840 - val_accuracy: 0.0023\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7758 - accuracy: 0.0024 - val_loss: 3.7836 - val_accuracy: 0.0023\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 3.7754 - accuracy: 0.0024 - val_loss: 3.7832 - val_accuracy: 0.0023\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.7751 - accuracy: 0.0024 - val_loss: 3.7829 - val_accuracy: 0.0023\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.7747 - accuracy: 0.0024 - val_loss: 3.7825 - val_accuracy: 0.0023\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.7743 - accuracy: 0.0024 - val_loss: 3.7821 - val_accuracy: 0.0023\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.7740 - accuracy: 0.0024 - val_loss: 3.7818 - val_accuracy: 0.0023\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 3.7736 - accuracy: 0.0024 - val_loss: 3.7814 - val_accuracy: 0.0023\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 3.7732 - accuracy: 0.0024 - val_loss: 3.7810 - val_accuracy: 0.0023\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7729 - accuracy: 0.0024 - val_loss: 3.7806 - val_accuracy: 0.0023\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7725 - accuracy: 0.0024 - val_loss: 3.7802 - val_accuracy: 0.0023\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 3.7721 - accuracy: 0.0024 - val_loss: 3.7799 - val_accuracy: 0.0023\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.7717 - accuracy: 0.0024 - val_loss: 3.7795 - val_accuracy: 0.0023\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7714 - accuracy: 0.0024 - val_loss: 3.7791 - val_accuracy: 0.0023\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 3.7710 - accuracy: 0.0028 - val_loss: 3.7787 - val_accuracy: 0.0023\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.7706 - accuracy: 0.0028 - val_loss: 3.7783 - val_accuracy: 0.0023\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7702 - accuracy: 0.0028 - val_loss: 3.7779 - val_accuracy: 0.0023\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 3.7699 - accuracy: 0.0028 - val_loss: 3.7775 - val_accuracy: 0.0023\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.7695 - accuracy: 0.0028 - val_loss: 3.7771 - val_accuracy: 0.0023\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.7691 - accuracy: 0.0028 - val_loss: 3.7768 - val_accuracy: 0.0023\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.7687 - accuracy: 0.0028 - val_loss: 3.7764 - val_accuracy: 0.0023\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7683 - accuracy: 0.0028 - val_loss: 3.7760 - val_accuracy: 0.0023\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7679 - accuracy: 0.0028 - val_loss: 3.7756 - val_accuracy: 0.0023\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.7675 - accuracy: 0.0033 - val_loss: 3.7752 - val_accuracy: 0.0023\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7671 - accuracy: 0.0037 - val_loss: 3.7748 - val_accuracy: 0.0023\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.7668 - accuracy: 0.0037 - val_loss: 3.7744 - val_accuracy: 0.0023\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.7664 - accuracy: 0.0037 - val_loss: 3.7740 - val_accuracy: 0.0023\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.7660 - accuracy: 0.0037 - val_loss: 3.7736 - val_accuracy: 0.0023\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7656 - accuracy: 0.0041 - val_loss: 3.7732 - val_accuracy: 0.0023\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.7652 - accuracy: 0.0041 - val_loss: 3.7728 - val_accuracy: 0.0023\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.7648 - accuracy: 0.0041 - val_loss: 3.7724 - val_accuracy: 0.0023\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7644 - accuracy: 0.0041 - val_loss: 3.7720 - val_accuracy: 0.0023\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.7640 - accuracy: 0.0041 - val_loss: 3.7716 - val_accuracy: 0.0023\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.7636 - accuracy: 0.0041 - val_loss: 3.7712 - val_accuracy: 0.0023\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7632 - accuracy: 0.0041 - val_loss: 3.7708 - val_accuracy: 0.0023\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.7628 - accuracy: 0.0041 - val_loss: 3.7704 - val_accuracy: 0.0023\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.7624 - accuracy: 0.0041 - val_loss: 3.7700 - val_accuracy: 0.0023\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.7620 - accuracy: 0.0041 - val_loss: 3.7696 - val_accuracy: 0.0023\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7616 - accuracy: 0.0041 - val_loss: 3.7691 - val_accuracy: 0.0023\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.7612 - accuracy: 0.0041 - val_loss: 3.7687 - val_accuracy: 0.0023\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 3.7608 - accuracy: 0.0041 - val_loss: 3.7683 - val_accuracy: 0.0023\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.7604 - accuracy: 0.0041 - val_loss: 3.7679 - val_accuracy: 0.0023\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.7600 - accuracy: 0.0045 - val_loss: 3.7675 - val_accuracy: 0.0023\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7596 - accuracy: 0.0045 - val_loss: 3.7671 - val_accuracy: 0.0023\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7592 - accuracy: 0.0045 - val_loss: 3.7667 - val_accuracy: 0.0023\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.7588 - accuracy: 0.0045 - val_loss: 3.7663 - val_accuracy: 0.0023\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 3.7584 - accuracy: 0.0045 - val_loss: 3.7659 - val_accuracy: 0.0023\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7580 - accuracy: 0.0045 - val_loss: 3.7655 - val_accuracy: 0.0023\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.7576 - accuracy: 0.0045 - val_loss: 3.7651 - val_accuracy: 0.0023\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 3.7572 - accuracy: 0.0045 - val_loss: 3.7647 - val_accuracy: 0.0023\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.7568 - accuracy: 0.0045 - val_loss: 3.7642 - val_accuracy: 0.0023\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.7564 - accuracy: 0.0045 - val_loss: 3.7638 - val_accuracy: 0.0023\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 3.7560 - accuracy: 0.0045 - val_loss: 3.7634 - val_accuracy: 0.0023\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.7556 - accuracy: 0.0045 - val_loss: 3.7630 - val_accuracy: 0.0023\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7552 - accuracy: 0.0045 - val_loss: 3.7626 - val_accuracy: 0.0023\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 3.7548 - accuracy: 0.0045 - val_loss: 3.7622 - val_accuracy: 0.0023\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.7544 - accuracy: 0.0045 - val_loss: 3.7618 - val_accuracy: 0.0023\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 3.7540 - accuracy: 0.0049 - val_loss: 3.7614 - val_accuracy: 0.0023\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.7536 - accuracy: 0.0049 - val_loss: 3.7610 - val_accuracy: 0.0023\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.7532 - accuracy: 0.0049 - val_loss: 3.7605 - val_accuracy: 0.0023\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7528 - accuracy: 0.0049 - val_loss: 3.7601 - val_accuracy: 0.0023\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.7524 - accuracy: 0.0049 - val_loss: 3.7597 - val_accuracy: 0.0023\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 3.7520 - accuracy: 0.0049 - val_loss: 3.7593 - val_accuracy: 0.0023\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 3.7516 - accuracy: 0.0049 - val_loss: 3.7589 - val_accuracy: 0.0023\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7512 - accuracy: 0.0049 - val_loss: 3.7585 - val_accuracy: 0.0023\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.7507 - accuracy: 0.0049 - val_loss: 3.7581 - val_accuracy: 0.0023\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.7503 - accuracy: 0.0049 - val_loss: 3.7576 - val_accuracy: 0.0023\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.7499 - accuracy: 0.0049 - val_loss: 3.7572 - val_accuracy: 0.0023\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 3.7495 - accuracy: 0.0049 - val_loss: 3.7568 - val_accuracy: 0.0023\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.7491 - accuracy: 0.0049 - val_loss: 3.7564 - val_accuracy: 0.0023\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7487 - accuracy: 0.0053 - val_loss: 3.7560 - val_accuracy: 0.0023\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7483 - accuracy: 0.0053 - val_loss: 3.7555 - val_accuracy: 0.0023\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7479 - accuracy: 0.0053 - val_loss: 3.7551 - val_accuracy: 0.0023\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.7475 - accuracy: 0.0053 - val_loss: 3.7547 - val_accuracy: 0.0023\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 3.7471 - accuracy: 0.0057 - val_loss: 3.7543 - val_accuracy: 0.0023\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 3.7466 - accuracy: 0.0057 - val_loss: 3.7539 - val_accuracy: 0.0023\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7462 - accuracy: 0.0057 - val_loss: 3.7535 - val_accuracy: 0.0023\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.7458 - accuracy: 0.0061 - val_loss: 3.7530 - val_accuracy: 0.0023\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 3.7454 - accuracy: 0.0061 - val_loss: 3.7526 - val_accuracy: 0.0023\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.7450 - accuracy: 0.0061 - val_loss: 3.7522 - val_accuracy: 0.0023\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.7446 - accuracy: 0.0061 - val_loss: 3.7518 - val_accuracy: 0.0023\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.7442 - accuracy: 0.0061 - val_loss: 3.7513 - val_accuracy: 0.0023\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.7437 - accuracy: 0.0061 - val_loss: 3.7509 - val_accuracy: 0.0023\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.7433 - accuracy: 0.0061 - val_loss: 3.7505 - val_accuracy: 0.0023\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 3.7429 - accuracy: 0.0061 - val_loss: 3.7501 - val_accuracy: 0.0023\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 3.7425 - accuracy: 0.0061 - val_loss: 3.7497 - val_accuracy: 0.0023\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.7421 - accuracy: 0.0065 - val_loss: 3.7492 - val_accuracy: 0.0023\n",
      "2895/2895 [==============================] - 0s 26us/sample - loss: 3.7430 - accuracy: 0.0059\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 126us/sample - loss: 3.6177 - accuracy: 0.0065 - val_loss: 3.6297 - val_accuracy: 0.0092\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.6147 - accuracy: 0.0065 - val_loss: 3.6266 - val_accuracy: 0.0092\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.6115 - accuracy: 0.0065 - val_loss: 3.6233 - val_accuracy: 0.0092\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 3.6083 - accuracy: 0.0065 - val_loss: 3.6201 - val_accuracy: 0.0092\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.6050 - accuracy: 0.0065 - val_loss: 3.6167 - val_accuracy: 0.0092\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.6016 - accuracy: 0.0065 - val_loss: 3.6133 - val_accuracy: 0.0092\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5982 - accuracy: 0.0065 - val_loss: 3.6098 - val_accuracy: 0.0092\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.5947 - accuracy: 0.0069 - val_loss: 3.6062 - val_accuracy: 0.0092\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 3.5912 - accuracy: 0.0069 - val_loss: 3.6026 - val_accuracy: 0.0092\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.5876 - accuracy: 0.0069 - val_loss: 3.5990 - val_accuracy: 0.0092\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.5840 - accuracy: 0.0073 - val_loss: 3.5953 - val_accuracy: 0.0092\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5803 - accuracy: 0.0073 - val_loss: 3.5915 - val_accuracy: 0.0092\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5766 - accuracy: 0.0073 - val_loss: 3.5878 - val_accuracy: 0.0092\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.5728 - accuracy: 0.0073 - val_loss: 3.5839 - val_accuracy: 0.0115\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 3.5690 - accuracy: 0.0085 - val_loss: 3.5801 - val_accuracy: 0.0115\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5652 - accuracy: 0.0089 - val_loss: 3.5763 - val_accuracy: 0.0115\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.5614 - accuracy: 0.0093 - val_loss: 3.5724 - val_accuracy: 0.0115\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5576 - accuracy: 0.0093 - val_loss: 3.5685 - val_accuracy: 0.0115\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5537 - accuracy: 0.0093 - val_loss: 3.5646 - val_accuracy: 0.0115\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.5498 - accuracy: 0.0093 - val_loss: 3.5606 - val_accuracy: 0.0115\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 3.5459 - accuracy: 0.0106 - val_loss: 3.5566 - val_accuracy: 0.0115\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5419 - accuracy: 0.0114 - val_loss: 3.5526 - val_accuracy: 0.0115\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.5380 - accuracy: 0.0114 - val_loss: 3.5486 - val_accuracy: 0.0115\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.5340 - accuracy: 0.0122 - val_loss: 3.5446 - val_accuracy: 0.0115\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5300 - accuracy: 0.0130 - val_loss: 3.5406 - val_accuracy: 0.0115\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 3.5260 - accuracy: 0.0138 - val_loss: 3.5365 - val_accuracy: 0.0115\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.5220 - accuracy: 0.0150 - val_loss: 3.5324 - val_accuracy: 0.0161\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 3.5179 - accuracy: 0.0154 - val_loss: 3.5284 - val_accuracy: 0.0161\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.5139 - accuracy: 0.0159 - val_loss: 3.5243 - val_accuracy: 0.0161\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.5098 - accuracy: 0.0163 - val_loss: 3.5201 - val_accuracy: 0.0161\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5057 - accuracy: 0.0183 - val_loss: 3.5160 - val_accuracy: 0.0184\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 3.5016 - accuracy: 0.0187 - val_loss: 3.5119 - val_accuracy: 0.0230\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.4975 - accuracy: 0.0195 - val_loss: 3.5077 - val_accuracy: 0.0276\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.4934 - accuracy: 0.0207 - val_loss: 3.5036 - val_accuracy: 0.0276\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 3.4893 - accuracy: 0.0232 - val_loss: 3.4994 - val_accuracy: 0.0276\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.4852 - accuracy: 0.0240 - val_loss: 3.4953 - val_accuracy: 0.0299\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.4811 - accuracy: 0.0260 - val_loss: 3.4911 - val_accuracy: 0.0322\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 3.4769 - accuracy: 0.0264 - val_loss: 3.4869 - val_accuracy: 0.0322\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.4728 - accuracy: 0.0285 - val_loss: 3.4827 - val_accuracy: 0.0322\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.4686 - accuracy: 0.0309 - val_loss: 3.4785 - val_accuracy: 0.0322\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.4645 - accuracy: 0.0317 - val_loss: 3.4743 - val_accuracy: 0.0391\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.4603 - accuracy: 0.0333 - val_loss: 3.4701 - val_accuracy: 0.0437\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 3.4561 - accuracy: 0.0350 - val_loss: 3.4658 - val_accuracy: 0.0437\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 125us/sample - loss: 3.4519 - accuracy: 0.0366 - val_loss: 3.4616 - val_accuracy: 0.0460\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 3.4476 - accuracy: 0.0382 - val_loss: 3.4573 - val_accuracy: 0.0506\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.4434 - accuracy: 0.0407 - val_loss: 3.4530 - val_accuracy: 0.0506\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 3.4392 - accuracy: 0.0427 - val_loss: 3.4487 - val_accuracy: 0.0529\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 121us/sample - loss: 3.4349 - accuracy: 0.0451 - val_loss: 3.4445 - val_accuracy: 0.0529\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.4307 - accuracy: 0.0472 - val_loss: 3.4402 - val_accuracy: 0.0552\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.4264 - accuracy: 0.0496 - val_loss: 3.4359 - val_accuracy: 0.0552\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4222 - accuracy: 0.0524 - val_loss: 3.4316 - val_accuracy: 0.0598\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4179 - accuracy: 0.0557 - val_loss: 3.4272 - val_accuracy: 0.0690\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 3.4136 - accuracy: 0.0569 - val_loss: 3.4229 - val_accuracy: 0.0759\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 3.4093 - accuracy: 0.0622 - val_loss: 3.4186 - val_accuracy: 0.0782\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.4051 - accuracy: 0.0642 - val_loss: 3.4143 - val_accuracy: 0.0851\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.4008 - accuracy: 0.0659 - val_loss: 3.4100 - val_accuracy: 0.0874\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 3.3966 - accuracy: 0.0687 - val_loss: 3.4057 - val_accuracy: 0.0897\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 3.3923 - accuracy: 0.0752 - val_loss: 3.4014 - val_accuracy: 0.0897\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.3880 - accuracy: 0.0793 - val_loss: 3.3971 - val_accuracy: 0.0920\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 3.3837 - accuracy: 0.0833 - val_loss: 3.3927 - val_accuracy: 0.0920\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.3794 - accuracy: 0.0854 - val_loss: 3.3884 - val_accuracy: 0.1011\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 135us/sample - loss: 3.3751 - accuracy: 0.0866 - val_loss: 3.3840 - val_accuracy: 0.1011\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.3708 - accuracy: 0.0907 - val_loss: 3.3796 - val_accuracy: 0.1034\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.3664 - accuracy: 0.0931 - val_loss: 3.3752 - val_accuracy: 0.1034\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.3621 - accuracy: 0.0980 - val_loss: 3.3709 - val_accuracy: 0.1057\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.3577 - accuracy: 0.1008 - val_loss: 3.3665 - val_accuracy: 0.1057\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 3.3534 - accuracy: 0.1057 - val_loss: 3.3621 - val_accuracy: 0.1057\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.3490 - accuracy: 0.1114 - val_loss: 3.3577 - val_accuracy: 0.1126\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.3447 - accuracy: 0.1159 - val_loss: 3.3533 - val_accuracy: 0.1172\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.3403 - accuracy: 0.1175 - val_loss: 3.3488 - val_accuracy: 0.1241\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.3359 - accuracy: 0.1199 - val_loss: 3.3444 - val_accuracy: 0.1310\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.3315 - accuracy: 0.1224 - val_loss: 3.3400 - val_accuracy: 0.1333\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.3272 - accuracy: 0.1248 - val_loss: 3.3356 - val_accuracy: 0.1356\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.3227 - accuracy: 0.1289 - val_loss: 3.3311 - val_accuracy: 0.1356\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 3.3183 - accuracy: 0.1346 - val_loss: 3.3267 - val_accuracy: 0.1379\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.3139 - accuracy: 0.1411 - val_loss: 3.3222 - val_accuracy: 0.1494\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.3095 - accuracy: 0.1476 - val_loss: 3.3178 - val_accuracy: 0.1517\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 3.3051 - accuracy: 0.1528 - val_loss: 3.3133 - val_accuracy: 0.1563\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.3007 - accuracy: 0.1557 - val_loss: 3.3089 - val_accuracy: 0.1609\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 3.2963 - accuracy: 0.1589 - val_loss: 3.3044 - val_accuracy: 0.1724\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.2919 - accuracy: 0.1630 - val_loss: 3.2999 - val_accuracy: 0.1747\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 3.2875 - accuracy: 0.1663 - val_loss: 3.2955 - val_accuracy: 0.1839\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.2830 - accuracy: 0.1699 - val_loss: 3.2910 - val_accuracy: 0.1839\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.2786 - accuracy: 0.1764 - val_loss: 3.2865 - val_accuracy: 0.1862\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.2742 - accuracy: 0.1833 - val_loss: 3.2820 - val_accuracy: 0.1977\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.2697 - accuracy: 0.1866 - val_loss: 3.2775 - val_accuracy: 0.2046\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.2652 - accuracy: 0.1935 - val_loss: 3.2730 - val_accuracy: 0.2092\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 3.2608 - accuracy: 0.1988 - val_loss: 3.2685 - val_accuracy: 0.2161\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.2563 - accuracy: 0.2049 - val_loss: 3.2639 - val_accuracy: 0.2207\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.2518 - accuracy: 0.2069 - val_loss: 3.2594 - val_accuracy: 0.2230\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.2473 - accuracy: 0.2154 - val_loss: 3.2549 - val_accuracy: 0.2276\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.2428 - accuracy: 0.2211 - val_loss: 3.2503 - val_accuracy: 0.2322\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 3.2383 - accuracy: 0.2256 - val_loss: 3.2458 - val_accuracy: 0.2345\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.2338 - accuracy: 0.2313 - val_loss: 3.2412 - val_accuracy: 0.2391\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.2293 - accuracy: 0.2386 - val_loss: 3.2367 - val_accuracy: 0.2437\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.2248 - accuracy: 0.2439 - val_loss: 3.2321 - val_accuracy: 0.2483\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.2203 - accuracy: 0.2512 - val_loss: 3.2276 - val_accuracy: 0.2529\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.2158 - accuracy: 0.2593 - val_loss: 3.2230 - val_accuracy: 0.2621\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 3.2113 - accuracy: 0.2646 - val_loss: 3.2185 - val_accuracy: 0.2644\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.2067 - accuracy: 0.2724 - val_loss: 3.2139 - val_accuracy: 0.2713\n",
      "2895/2895 [==============================] - 0s 27us/sample - loss: 3.2059 - accuracy: 0.2736\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 135us/sample - loss: 3.3672 - accuracy: 0.1919 - val_loss: 3.3484 - val_accuracy: 0.1793\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.3367 - accuracy: 0.2077 - val_loss: 3.3169 - val_accuracy: 0.2046\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.3053 - accuracy: 0.2240 - val_loss: 3.2845 - val_accuracy: 0.2207\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 3.2730 - accuracy: 0.2455 - val_loss: 3.2513 - val_accuracy: 0.2253\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.2399 - accuracy: 0.2715 - val_loss: 3.2173 - val_accuracy: 0.2529\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 3.2059 - accuracy: 0.2976 - val_loss: 3.1824 - val_accuracy: 0.2828\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.1712 - accuracy: 0.3232 - val_loss: 3.1467 - val_accuracy: 0.3103\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.1357 - accuracy: 0.3541 - val_loss: 3.1102 - val_accuracy: 0.3402\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 3.0994 - accuracy: 0.3789 - val_loss: 3.0728 - val_accuracy: 0.3655\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.0622 - accuracy: 0.4073 - val_loss: 3.0346 - val_accuracy: 0.4138\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.0241 - accuracy: 0.4325 - val_loss: 2.9954 - val_accuracy: 0.4437\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 2.9851 - accuracy: 0.4504 - val_loss: 2.9554 - val_accuracy: 0.4598\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 2.9454 - accuracy: 0.4711 - val_loss: 2.9146 - val_accuracy: 0.4805\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 2.9049 - accuracy: 0.4837 - val_loss: 2.8730 - val_accuracy: 0.4943\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 2.8636 - accuracy: 0.4951 - val_loss: 2.8307 - val_accuracy: 0.5057\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 2.8217 - accuracy: 0.5004 - val_loss: 2.7877 - val_accuracy: 0.5080\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 2.7790 - accuracy: 0.5085 - val_loss: 2.7441 - val_accuracy: 0.5103\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 2.7358 - accuracy: 0.5146 - val_loss: 2.6999 - val_accuracy: 0.5126\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.6920 - accuracy: 0.5175 - val_loss: 2.6551 - val_accuracy: 0.5195\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.6475 - accuracy: 0.5220 - val_loss: 2.6097 - val_accuracy: 0.5218\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.6025 - accuracy: 0.5215 - val_loss: 2.5638 - val_accuracy: 0.5218\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 2.5570 - accuracy: 0.5244 - val_loss: 2.5175 - val_accuracy: 0.5241\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 2.5112 - accuracy: 0.5297 - val_loss: 2.4709 - val_accuracy: 0.5241\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 2.4650 - accuracy: 0.5293 - val_loss: 2.4239 - val_accuracy: 0.5195\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 2.4187 - accuracy: 0.5313 - val_loss: 2.3769 - val_accuracy: 0.5172\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.3722 - accuracy: 0.5305 - val_loss: 2.3297 - val_accuracy: 0.5241\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.3255 - accuracy: 0.5325 - val_loss: 2.2825 - val_accuracy: 0.5287\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 2.2788 - accuracy: 0.5366 - val_loss: 2.2352 - val_accuracy: 0.5264\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 2.2321 - accuracy: 0.5382 - val_loss: 2.1881 - val_accuracy: 0.5218\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.1856 - accuracy: 0.5427 - val_loss: 2.1413 - val_accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.1395 - accuracy: 0.5423 - val_loss: 2.0950 - val_accuracy: 0.5425\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 2.0937 - accuracy: 0.5415 - val_loss: 2.0489 - val_accuracy: 0.5494\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.0481 - accuracy: 0.5480 - val_loss: 2.0032 - val_accuracy: 0.5517\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 2.0030 - accuracy: 0.5467 - val_loss: 1.9581 - val_accuracy: 0.5517\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 1.9585 - accuracy: 0.5463 - val_loss: 1.9137 - val_accuracy: 0.5517\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 1.9146 - accuracy: 0.5488 - val_loss: 1.8701 - val_accuracy: 0.5517\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.8716 - accuracy: 0.5476 - val_loss: 1.8274 - val_accuracy: 0.5517\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.8294 - accuracy: 0.5512 - val_loss: 1.7856 - val_accuracy: 0.5471\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 1.7880 - accuracy: 0.5512 - val_loss: 1.7447 - val_accuracy: 0.5517\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.7475 - accuracy: 0.5533 - val_loss: 1.7047 - val_accuracy: 0.5517\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 1.7080 - accuracy: 0.5533 - val_loss: 1.6657 - val_accuracy: 0.5540\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 1.6694 - accuracy: 0.5549 - val_loss: 1.6278 - val_accuracy: 0.5563\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 1.6317 - accuracy: 0.5561 - val_loss: 1.5909 - val_accuracy: 0.5540\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.5950 - accuracy: 0.5565 - val_loss: 1.5551 - val_accuracy: 0.5586\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.5595 - accuracy: 0.5565 - val_loss: 1.5205 - val_accuracy: 0.5563\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.5250 - accuracy: 0.5537 - val_loss: 1.4869 - val_accuracy: 0.5563\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.4916 - accuracy: 0.5528 - val_loss: 1.4546 - val_accuracy: 0.5563\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 1.4594 - accuracy: 0.5516 - val_loss: 1.4234 - val_accuracy: 0.5586\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.4282 - accuracy: 0.5508 - val_loss: 1.3932 - val_accuracy: 0.5655\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.3980 - accuracy: 0.5528 - val_loss: 1.3640 - val_accuracy: 0.5632\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.3687 - accuracy: 0.5528 - val_loss: 1.3358 - val_accuracy: 0.5655\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 1.3405 - accuracy: 0.5533 - val_loss: 1.3087 - val_accuracy: 0.5655\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 1.3132 - accuracy: 0.5516 - val_loss: 1.2825 - val_accuracy: 0.5701\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 1.2869 - accuracy: 0.5541 - val_loss: 1.2573 - val_accuracy: 0.5724\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.2616 - accuracy: 0.5516 - val_loss: 1.2332 - val_accuracy: 0.5701\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.2373 - accuracy: 0.5528 - val_loss: 1.2101 - val_accuracy: 0.5701\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 1.2140 - accuracy: 0.5516 - val_loss: 1.1880 - val_accuracy: 0.5747\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 1.1917 - accuracy: 0.5533 - val_loss: 1.1669 - val_accuracy: 0.5747\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.1704 - accuracy: 0.5520 - val_loss: 1.1466 - val_accuracy: 0.5793\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.1499 - accuracy: 0.5512 - val_loss: 1.1271 - val_accuracy: 0.5793\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.1302 - accuracy: 0.5549 - val_loss: 1.1085 - val_accuracy: 0.5770\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 1.1113 - accuracy: 0.5561 - val_loss: 1.0907 - val_accuracy: 0.5770\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 1.0932 - accuracy: 0.5569 - val_loss: 1.0736 - val_accuracy: 0.5793\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.0759 - accuracy: 0.5557 - val_loss: 1.0572 - val_accuracy: 0.5816\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 1.0592 - accuracy: 0.5569 - val_loss: 1.0414 - val_accuracy: 0.5839\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.0432 - accuracy: 0.5577 - val_loss: 1.0264 - val_accuracy: 0.5793\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.0280 - accuracy: 0.5589 - val_loss: 1.0121 - val_accuracy: 0.5770\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 1.0135 - accuracy: 0.5602 - val_loss: 0.9984 - val_accuracy: 0.5770\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.9996 - accuracy: 0.5610 - val_loss: 0.9853 - val_accuracy: 0.5770\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.9863 - accuracy: 0.5626 - val_loss: 0.9728 - val_accuracy: 0.5793\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.9736 - accuracy: 0.5626 - val_loss: 0.9609 - val_accuracy: 0.5816\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.9615 - accuracy: 0.5630 - val_loss: 0.9495 - val_accuracy: 0.5816\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.9499 - accuracy: 0.5638 - val_loss: 0.9386 - val_accuracy: 0.5862\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.9389 - accuracy: 0.5654 - val_loss: 0.9282 - val_accuracy: 0.5862\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.9283 - accuracy: 0.5654 - val_loss: 0.9183 - val_accuracy: 0.5862\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.9181 - accuracy: 0.5667 - val_loss: 0.9087 - val_accuracy: 0.5862\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.9084 - accuracy: 0.5687 - val_loss: 0.8996 - val_accuracy: 0.5862\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8991 - accuracy: 0.5699 - val_loss: 0.8908 - val_accuracy: 0.5862\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.8902 - accuracy: 0.5683 - val_loss: 0.8824 - val_accuracy: 0.5839\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8816 - accuracy: 0.5715 - val_loss: 0.8743 - val_accuracy: 0.5793\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.8734 - accuracy: 0.5732 - val_loss: 0.8666 - val_accuracy: 0.5793\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.8655 - accuracy: 0.5744 - val_loss: 0.8593 - val_accuracy: 0.5770\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8581 - accuracy: 0.5768 - val_loss: 0.8523 - val_accuracy: 0.5724\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.8509 - accuracy: 0.5776 - val_loss: 0.8455 - val_accuracy: 0.5678\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.8440 - accuracy: 0.5785 - val_loss: 0.8391 - val_accuracy: 0.5701\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.8374 - accuracy: 0.5817 - val_loss: 0.8329 - val_accuracy: 0.5678\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8311 - accuracy: 0.5817 - val_loss: 0.8270 - val_accuracy: 0.5701\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8251 - accuracy: 0.5813 - val_loss: 0.8213 - val_accuracy: 0.5701\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.8194 - accuracy: 0.5813 - val_loss: 0.8159 - val_accuracy: 0.5724\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8139 - accuracy: 0.5825 - val_loss: 0.8108 - val_accuracy: 0.5724\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.8086 - accuracy: 0.5829 - val_loss: 0.8058 - val_accuracy: 0.5747\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.8035 - accuracy: 0.5850 - val_loss: 0.8010 - val_accuracy: 0.5793\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.7986 - accuracy: 0.5837 - val_loss: 0.7964 - val_accuracy: 0.5747\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7939 - accuracy: 0.5821 - val_loss: 0.7920 - val_accuracy: 0.5747\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7894 - accuracy: 0.5841 - val_loss: 0.7878 - val_accuracy: 0.5747\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.7851 - accuracy: 0.5833 - val_loss: 0.7838 - val_accuracy: 0.5770\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7809 - accuracy: 0.5841 - val_loss: 0.7799 - val_accuracy: 0.5770\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7769 - accuracy: 0.5850 - val_loss: 0.7762 - val_accuracy: 0.5793\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.7731 - accuracy: 0.5862 - val_loss: 0.7725 - val_accuracy: 0.5793\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.7694 - accuracy: 0.5866 - val_loss: 0.7691 - val_accuracy: 0.5793\n",
      "2895/2895 [==============================] - 0s 73us/sample - loss: 0.7677 - accuracy: 0.5869\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 139us/sample - loss: 3.4977 - accuracy: 0.0187 - val_loss: 3.3515 - val_accuracy: 0.0644\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.1983 - accuracy: 0.2069 - val_loss: 3.0285 - val_accuracy: 0.3494\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 2.8517 - accuracy: 0.4415 - val_loss: 2.6457 - val_accuracy: 0.4598\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 2.4455 - accuracy: 0.4837 - val_loss: 2.2148 - val_accuracy: 0.4828\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 111us/sample - loss: 2.0190 - accuracy: 0.5041 - val_loss: 1.8047 - val_accuracy: 0.5149\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.6441 - accuracy: 0.5386 - val_loss: 1.4754 - val_accuracy: 0.5540\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.3558 - accuracy: 0.5524 - val_loss: 1.2352 - val_accuracy: 0.5586\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 1.1498 - accuracy: 0.5610 - val_loss: 1.0675 - val_accuracy: 0.5839\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.0079 - accuracy: 0.5740 - val_loss: 0.9534 - val_accuracy: 0.5839\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 114us/sample - loss: 0.9110 - accuracy: 0.5768 - val_loss: 0.8750 - val_accuracy: 0.5908\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8443 - accuracy: 0.5870 - val_loss: 0.8206 - val_accuracy: 0.5885\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7979 - accuracy: 0.5898 - val_loss: 0.7826 - val_accuracy: 0.5954\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7646 - accuracy: 0.5951 - val_loss: 0.7548 - val_accuracy: 0.6069\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.7397 - accuracy: 0.6041 - val_loss: 0.7341 - val_accuracy: 0.6138\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7208 - accuracy: 0.6130 - val_loss: 0.7180 - val_accuracy: 0.6207\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.7059 - accuracy: 0.6183 - val_loss: 0.7053 - val_accuracy: 0.6207\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6937 - accuracy: 0.6305 - val_loss: 0.6951 - val_accuracy: 0.6345\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6839 - accuracy: 0.6386 - val_loss: 0.6866 - val_accuracy: 0.6437\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6754 - accuracy: 0.6407 - val_loss: 0.6792 - val_accuracy: 0.6460\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.6682 - accuracy: 0.6472 - val_loss: 0.6730 - val_accuracy: 0.6483\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6617 - accuracy: 0.6496 - val_loss: 0.6675 - val_accuracy: 0.6414\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6560 - accuracy: 0.6549 - val_loss: 0.6627 - val_accuracy: 0.6414\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6507 - accuracy: 0.6581 - val_loss: 0.6583 - val_accuracy: 0.6414\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.6462 - accuracy: 0.6618 - val_loss: 0.6544 - val_accuracy: 0.6437\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6418 - accuracy: 0.6642 - val_loss: 0.6509 - val_accuracy: 0.6437\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6379 - accuracy: 0.6687 - val_loss: 0.6475 - val_accuracy: 0.6437\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6341 - accuracy: 0.6699 - val_loss: 0.6444 - val_accuracy: 0.6506\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6306 - accuracy: 0.6724 - val_loss: 0.6415 - val_accuracy: 0.6437\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.6272 - accuracy: 0.6772 - val_loss: 0.6389 - val_accuracy: 0.6414\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6241 - accuracy: 0.6740 - val_loss: 0.6364 - val_accuracy: 0.6414\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6213 - accuracy: 0.6760 - val_loss: 0.6341 - val_accuracy: 0.6437\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6185 - accuracy: 0.6780 - val_loss: 0.6320 - val_accuracy: 0.6437\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6159 - accuracy: 0.6825 - val_loss: 0.6298 - val_accuracy: 0.6552\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.6134 - accuracy: 0.6821 - val_loss: 0.6279 - val_accuracy: 0.6460\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6111 - accuracy: 0.6797 - val_loss: 0.6262 - val_accuracy: 0.6552\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6088 - accuracy: 0.6837 - val_loss: 0.6246 - val_accuracy: 0.6483\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.6068 - accuracy: 0.6862 - val_loss: 0.6231 - val_accuracy: 0.6621\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6048 - accuracy: 0.6866 - val_loss: 0.6216 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.6028 - accuracy: 0.6862 - val_loss: 0.6201 - val_accuracy: 0.6575\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6010 - accuracy: 0.6882 - val_loss: 0.6189 - val_accuracy: 0.6644\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5994 - accuracy: 0.6890 - val_loss: 0.6179 - val_accuracy: 0.6598\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5977 - accuracy: 0.6911 - val_loss: 0.6167 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5962 - accuracy: 0.6919 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5947 - accuracy: 0.6874 - val_loss: 0.6148 - val_accuracy: 0.6598\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5934 - accuracy: 0.6915 - val_loss: 0.6139 - val_accuracy: 0.6575\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5921 - accuracy: 0.6919 - val_loss: 0.6130 - val_accuracy: 0.6598\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5908 - accuracy: 0.6919 - val_loss: 0.6124 - val_accuracy: 0.6598\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5895 - accuracy: 0.6927 - val_loss: 0.6117 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5884 - accuracy: 0.6931 - val_loss: 0.6109 - val_accuracy: 0.6575\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5873 - accuracy: 0.6931 - val_loss: 0.6103 - val_accuracy: 0.6552\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5864 - accuracy: 0.6955 - val_loss: 0.6097 - val_accuracy: 0.6575\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5853 - accuracy: 0.7004 - val_loss: 0.6091 - val_accuracy: 0.6506\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5844 - accuracy: 0.6988 - val_loss: 0.6085 - val_accuracy: 0.6575\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5834 - accuracy: 0.6972 - val_loss: 0.6080 - val_accuracy: 0.6621\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5827 - accuracy: 0.6980 - val_loss: 0.6076 - val_accuracy: 0.6575\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5819 - accuracy: 0.7000 - val_loss: 0.6072 - val_accuracy: 0.6575\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5810 - accuracy: 0.7000 - val_loss: 0.6067 - val_accuracy: 0.6506\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5803 - accuracy: 0.6980 - val_loss: 0.6066 - val_accuracy: 0.6552\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5795 - accuracy: 0.7008 - val_loss: 0.6061 - val_accuracy: 0.6552\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5788 - accuracy: 0.7000 - val_loss: 0.6059 - val_accuracy: 0.6598\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5782 - accuracy: 0.7008 - val_loss: 0.6057 - val_accuracy: 0.6552\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5774 - accuracy: 0.7004 - val_loss: 0.6051 - val_accuracy: 0.6460\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5770 - accuracy: 0.7041 - val_loss: 0.6050 - val_accuracy: 0.6529\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5763 - accuracy: 0.7024 - val_loss: 0.6047 - val_accuracy: 0.6460\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5758 - accuracy: 0.7049 - val_loss: 0.6046 - val_accuracy: 0.6598\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5751 - accuracy: 0.7045 - val_loss: 0.6043 - val_accuracy: 0.6529\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5748 - accuracy: 0.7065 - val_loss: 0.6041 - val_accuracy: 0.6506\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5743 - accuracy: 0.7061 - val_loss: 0.6041 - val_accuracy: 0.6575\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5737 - accuracy: 0.7049 - val_loss: 0.6038 - val_accuracy: 0.6575\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5732 - accuracy: 0.7069 - val_loss: 0.6038 - val_accuracy: 0.6575\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.5729 - accuracy: 0.7049 - val_loss: 0.6037 - val_accuracy: 0.6621\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5724 - accuracy: 0.7049 - val_loss: 0.6037 - val_accuracy: 0.6575\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5720 - accuracy: 0.7057 - val_loss: 0.6037 - val_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5715 - accuracy: 0.7041 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5712 - accuracy: 0.7053 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.5708 - accuracy: 0.7061 - val_loss: 0.6032 - val_accuracy: 0.6644\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5703 - accuracy: 0.7081 - val_loss: 0.6035 - val_accuracy: 0.6713\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5701 - accuracy: 0.7061 - val_loss: 0.6034 - val_accuracy: 0.6713\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5696 - accuracy: 0.7085 - val_loss: 0.6030 - val_accuracy: 0.6690\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5692 - accuracy: 0.7085 - val_loss: 0.6032 - val_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5689 - accuracy: 0.7081 - val_loss: 0.6030 - val_accuracy: 0.6690\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5686 - accuracy: 0.7069 - val_loss: 0.6029 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5684 - accuracy: 0.7085 - val_loss: 0.6030 - val_accuracy: 0.6805\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5680 - accuracy: 0.7065 - val_loss: 0.6032 - val_accuracy: 0.6713\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.5677 - accuracy: 0.7073 - val_loss: 0.6030 - val_accuracy: 0.6805\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5675 - accuracy: 0.7089 - val_loss: 0.6030 - val_accuracy: 0.6851\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5670 - accuracy: 0.7106 - val_loss: 0.6032 - val_accuracy: 0.6759\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.5667 - accuracy: 0.7102 - val_loss: 0.6032 - val_accuracy: 0.6782\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5666 - accuracy: 0.7106 - val_loss: 0.6031 - val_accuracy: 0.6782\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5661 - accuracy: 0.7089 - val_loss: 0.6033 - val_accuracy: 0.6805\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5660 - accuracy: 0.7110 - val_loss: 0.6034 - val_accuracy: 0.6759\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5657 - accuracy: 0.7098 - val_loss: 0.6035 - val_accuracy: 0.6782\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5653 - accuracy: 0.7098 - val_loss: 0.6033 - val_accuracy: 0.6736\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5650 - accuracy: 0.7122 - val_loss: 0.6032 - val_accuracy: 0.6736\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5649 - accuracy: 0.7102 - val_loss: 0.6031 - val_accuracy: 0.6782\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5646 - accuracy: 0.7102 - val_loss: 0.6032 - val_accuracy: 0.6759\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5644 - accuracy: 0.7098 - val_loss: 0.6031 - val_accuracy: 0.6782\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5640 - accuracy: 0.7126 - val_loss: 0.6034 - val_accuracy: 0.6690\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5639 - accuracy: 0.7118 - val_loss: 0.6033 - val_accuracy: 0.6759\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5636 - accuracy: 0.7102 - val_loss: 0.6034 - val_accuracy: 0.6690\n",
      "2895/2895 [==============================] - 0s 26us/sample - loss: 0.5687 - accuracy: 0.7057\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 133us/sample - loss: 2.0220 - accuracy: 0.4634 - val_loss: 0.8679 - val_accuracy: 0.6230\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.7379 - accuracy: 0.6175 - val_loss: 0.6646 - val_accuracy: 0.6828\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6357 - val_accuracy: 0.6598\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6115 - accuracy: 0.6846 - val_loss: 0.6189 - val_accuracy: 0.6621\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5963 - accuracy: 0.6785 - val_loss: 0.6056 - val_accuracy: 0.6736\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5872 - accuracy: 0.6841 - val_loss: 0.6037 - val_accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5807 - accuracy: 0.6931 - val_loss: 0.6127 - val_accuracy: 0.6690\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5761 - accuracy: 0.6939 - val_loss: 0.6082 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5735 - accuracy: 0.7008 - val_loss: 0.6063 - val_accuracy: 0.6598\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5713 - accuracy: 0.7061 - val_loss: 0.6054 - val_accuracy: 0.6713\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5672 - accuracy: 0.7049 - val_loss: 0.6039 - val_accuracy: 0.6782\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5672 - accuracy: 0.7045 - val_loss: 0.6068 - val_accuracy: 0.6759\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5648 - accuracy: 0.7077 - val_loss: 0.6128 - val_accuracy: 0.6736\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5639 - accuracy: 0.7049 - val_loss: 0.6041 - val_accuracy: 0.6690\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5603 - accuracy: 0.7081 - val_loss: 0.6054 - val_accuracy: 0.6736\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5593 - accuracy: 0.7118 - val_loss: 0.6072 - val_accuracy: 0.6644\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5579 - accuracy: 0.7110 - val_loss: 0.6122 - val_accuracy: 0.6713\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5561 - accuracy: 0.7195 - val_loss: 0.6088 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5542 - accuracy: 0.7110 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5525 - accuracy: 0.7130 - val_loss: 0.6087 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5513 - accuracy: 0.7187 - val_loss: 0.6085 - val_accuracy: 0.6690\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5504 - accuracy: 0.7167 - val_loss: 0.6091 - val_accuracy: 0.6782\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5474 - accuracy: 0.7167 - val_loss: 0.6107 - val_accuracy: 0.6759\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5451 - accuracy: 0.7187 - val_loss: 0.6148 - val_accuracy: 0.6759\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5447 - accuracy: 0.7260 - val_loss: 0.6104 - val_accuracy: 0.6782\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5422 - accuracy: 0.7220 - val_loss: 0.6189 - val_accuracy: 0.6621\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5419 - accuracy: 0.7252 - val_loss: 0.6117 - val_accuracy: 0.6805\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5384 - accuracy: 0.7215 - val_loss: 0.6146 - val_accuracy: 0.6690\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5367 - accuracy: 0.7313 - val_loss: 0.6150 - val_accuracy: 0.6713\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5353 - accuracy: 0.7232 - val_loss: 0.6163 - val_accuracy: 0.6690\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5331 - accuracy: 0.7264 - val_loss: 0.6135 - val_accuracy: 0.6920\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5301 - accuracy: 0.7313 - val_loss: 0.6229 - val_accuracy: 0.6690\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5309 - accuracy: 0.7337 - val_loss: 0.6158 - val_accuracy: 0.6828\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5273 - accuracy: 0.7309 - val_loss: 0.6259 - val_accuracy: 0.6644\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.6162 - val_accuracy: 0.6759\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5246 - accuracy: 0.7317 - val_loss: 0.6256 - val_accuracy: 0.6736\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5233 - accuracy: 0.7362 - val_loss: 0.6218 - val_accuracy: 0.6782\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.5220 - accuracy: 0.7321 - val_loss: 0.6206 - val_accuracy: 0.6828\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5191 - accuracy: 0.7354 - val_loss: 0.6214 - val_accuracy: 0.6897\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5158 - accuracy: 0.7382 - val_loss: 0.6221 - val_accuracy: 0.6736\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5148 - accuracy: 0.7427 - val_loss: 0.6317 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.5136 - accuracy: 0.7431 - val_loss: 0.6329 - val_accuracy: 0.6529\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5133 - accuracy: 0.7415 - val_loss: 0.6272 - val_accuracy: 0.6736\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5104 - accuracy: 0.7439 - val_loss: 0.6299 - val_accuracy: 0.6575\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5097 - accuracy: 0.7415 - val_loss: 0.6290 - val_accuracy: 0.6782\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5069 - accuracy: 0.7476 - val_loss: 0.6292 - val_accuracy: 0.6690\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5049 - accuracy: 0.7435 - val_loss: 0.6317 - val_accuracy: 0.6690\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5054 - accuracy: 0.7443 - val_loss: 0.6318 - val_accuracy: 0.6759\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5028 - accuracy: 0.7520 - val_loss: 0.6323 - val_accuracy: 0.6782\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.4998 - accuracy: 0.7565 - val_loss: 0.6344 - val_accuracy: 0.6644\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.4983 - accuracy: 0.7524 - val_loss: 0.6348 - val_accuracy: 0.6828\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4987 - accuracy: 0.7537 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4961 - accuracy: 0.7508 - val_loss: 0.6406 - val_accuracy: 0.6736\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4925 - accuracy: 0.7565 - val_loss: 0.6405 - val_accuracy: 0.6736\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4918 - accuracy: 0.7593 - val_loss: 0.6403 - val_accuracy: 0.6690\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4899 - accuracy: 0.7545 - val_loss: 0.6426 - val_accuracy: 0.6644\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4875 - accuracy: 0.7642 - val_loss: 0.6427 - val_accuracy: 0.6690\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4866 - accuracy: 0.7602 - val_loss: 0.6461 - val_accuracy: 0.6690\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4838 - accuracy: 0.7614 - val_loss: 0.6478 - val_accuracy: 0.6621\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.4830 - accuracy: 0.7654 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4798 - accuracy: 0.7646 - val_loss: 0.6515 - val_accuracy: 0.6506\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4796 - accuracy: 0.7695 - val_loss: 0.6491 - val_accuracy: 0.6598\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4761 - accuracy: 0.7695 - val_loss: 0.6573 - val_accuracy: 0.6483\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.4764 - accuracy: 0.7671 - val_loss: 0.6638 - val_accuracy: 0.6483\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4754 - accuracy: 0.7642 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4741 - accuracy: 0.7683 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4710 - accuracy: 0.7695 - val_loss: 0.6609 - val_accuracy: 0.6621\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.4696 - accuracy: 0.7724 - val_loss: 0.6596 - val_accuracy: 0.6644\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4667 - accuracy: 0.7724 - val_loss: 0.6700 - val_accuracy: 0.6598\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.4650 - accuracy: 0.7764 - val_loss: 0.6636 - val_accuracy: 0.6483\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 0.4637 - accuracy: 0.7776 - val_loss: 0.6666 - val_accuracy: 0.6621\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4619 - accuracy: 0.7752 - val_loss: 0.6693 - val_accuracy: 0.6483\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4606 - accuracy: 0.7703 - val_loss: 0.6682 - val_accuracy: 0.6644\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.4586 - accuracy: 0.7732 - val_loss: 0.6691 - val_accuracy: 0.6644\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4566 - accuracy: 0.7862 - val_loss: 0.6710 - val_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4555 - accuracy: 0.7854 - val_loss: 0.6787 - val_accuracy: 0.6529\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4530 - accuracy: 0.7874 - val_loss: 0.6728 - val_accuracy: 0.6552\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4536 - accuracy: 0.7801 - val_loss: 0.6760 - val_accuracy: 0.6575\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4515 - accuracy: 0.7874 - val_loss: 0.6791 - val_accuracy: 0.6529\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4467 - accuracy: 0.7825 - val_loss: 0.6785 - val_accuracy: 0.6460\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.4463 - accuracy: 0.7886 - val_loss: 0.6958 - val_accuracy: 0.6460\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4445 - accuracy: 0.7943 - val_loss: 0.6819 - val_accuracy: 0.6529\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4433 - accuracy: 0.7866 - val_loss: 0.6838 - val_accuracy: 0.6575\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4425 - accuracy: 0.7894 - val_loss: 0.6850 - val_accuracy: 0.6506\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4402 - accuracy: 0.7866 - val_loss: 0.6987 - val_accuracy: 0.6460\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4358 - accuracy: 0.8004 - val_loss: 0.6949 - val_accuracy: 0.6506\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4384 - accuracy: 0.7870 - val_loss: 0.6900 - val_accuracy: 0.6460\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4344 - accuracy: 0.7980 - val_loss: 0.6932 - val_accuracy: 0.6437\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4347 - accuracy: 0.7947 - val_loss: 0.6972 - val_accuracy: 0.6414\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4301 - accuracy: 0.8012 - val_loss: 0.7039 - val_accuracy: 0.6368\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4316 - accuracy: 0.8041 - val_loss: 0.6996 - val_accuracy: 0.6483\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4290 - accuracy: 0.8041 - val_loss: 0.7003 - val_accuracy: 0.6483\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4297 - accuracy: 0.8033 - val_loss: 0.7029 - val_accuracy: 0.6437\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4263 - accuracy: 0.7947 - val_loss: 0.7047 - val_accuracy: 0.6437\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4243 - accuracy: 0.7963 - val_loss: 0.7097 - val_accuracy: 0.6460\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.4221 - accuracy: 0.8085 - val_loss: 0.7059 - val_accuracy: 0.6506\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4212 - accuracy: 0.8098 - val_loss: 0.7072 - val_accuracy: 0.6368\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4189 - accuracy: 0.8069 - val_loss: 0.7110 - val_accuracy: 0.6414\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4182 - accuracy: 0.8049 - val_loss: 0.7121 - val_accuracy: 0.6483\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4178 - accuracy: 0.8024 - val_loss: 0.7232 - val_accuracy: 0.6322\n",
      "2895/2895 [==============================] - 0s 24us/sample - loss: 0.4547 - accuracy: 0.7879\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 172us/sample - loss: 3.5524 - accuracy: 0.0098 - val_loss: 3.4572 - val_accuracy: 0.0299\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 3.3391 - accuracy: 0.1154 - val_loss: 3.2436 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.1284 - accuracy: 0.3451 - val_loss: 3.0302 - val_accuracy: 0.4345\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.9179 - accuracy: 0.5240 - val_loss: 2.8167 - val_accuracy: 0.5241\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 2.7046 - accuracy: 0.5736 - val_loss: 2.6009 - val_accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 2.4905 - accuracy: 0.5793 - val_loss: 2.3865 - val_accuracy: 0.5448\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 2.2795 - accuracy: 0.5809 - val_loss: 2.1764 - val_accuracy: 0.5494\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.0725 - accuracy: 0.5793 - val_loss: 1.9734 - val_accuracy: 0.5494\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.8748 - accuracy: 0.5785 - val_loss: 1.7820 - val_accuracy: 0.5448\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 1.6896 - accuracy: 0.5801 - val_loss: 1.6053 - val_accuracy: 0.5563\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 1.5203 - accuracy: 0.5833 - val_loss: 1.4468 - val_accuracy: 0.5632\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.3680 - accuracy: 0.5858 - val_loss: 1.3049 - val_accuracy: 0.5655\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.2348 - accuracy: 0.5919 - val_loss: 1.1836 - val_accuracy: 0.5678\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.1208 - accuracy: 0.5980 - val_loss: 1.0796 - val_accuracy: 0.5632\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 1.0239 - accuracy: 0.6045 - val_loss: 0.9922 - val_accuracy: 0.5793\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.9439 - accuracy: 0.6102 - val_loss: 0.9209 - val_accuracy: 0.5885\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.8784 - accuracy: 0.6163 - val_loss: 0.8624 - val_accuracy: 0.5816\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8260 - accuracy: 0.6211 - val_loss: 0.8165 - val_accuracy: 0.5908\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7846 - accuracy: 0.6268 - val_loss: 0.7797 - val_accuracy: 0.5931\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.7518 - accuracy: 0.6362 - val_loss: 0.7507 - val_accuracy: 0.5954\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7256 - accuracy: 0.6419 - val_loss: 0.7278 - val_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7049 - accuracy: 0.6480 - val_loss: 0.7097 - val_accuracy: 0.6069\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6884 - accuracy: 0.6492 - val_loss: 0.6953 - val_accuracy: 0.6161\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6749 - accuracy: 0.6533 - val_loss: 0.6836 - val_accuracy: 0.6276\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6640 - accuracy: 0.6565 - val_loss: 0.6741 - val_accuracy: 0.6276\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6549 - accuracy: 0.6659 - val_loss: 0.6664 - val_accuracy: 0.6322\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6474 - accuracy: 0.6606 - val_loss: 0.6601 - val_accuracy: 0.6322\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.6411 - accuracy: 0.6703 - val_loss: 0.6548 - val_accuracy: 0.6368\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6355 - accuracy: 0.6679 - val_loss: 0.6501 - val_accuracy: 0.6368\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6306 - accuracy: 0.6744 - val_loss: 0.6461 - val_accuracy: 0.6483\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6263 - accuracy: 0.6740 - val_loss: 0.6424 - val_accuracy: 0.6529\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.6225 - accuracy: 0.6768 - val_loss: 0.6393 - val_accuracy: 0.6575\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6191 - accuracy: 0.6793 - val_loss: 0.6366 - val_accuracy: 0.6644\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6159 - accuracy: 0.6878 - val_loss: 0.6342 - val_accuracy: 0.6644\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6130 - accuracy: 0.6846 - val_loss: 0.6319 - val_accuracy: 0.6575\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.6102 - accuracy: 0.6854 - val_loss: 0.6297 - val_accuracy: 0.6621\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.6076 - accuracy: 0.6878 - val_loss: 0.6279 - val_accuracy: 0.6575\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6052 - accuracy: 0.6866 - val_loss: 0.6262 - val_accuracy: 0.6598\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.6030 - accuracy: 0.6907 - val_loss: 0.6246 - val_accuracy: 0.6552\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.6008 - accuracy: 0.6886 - val_loss: 0.6231 - val_accuracy: 0.6598\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5989 - accuracy: 0.6898 - val_loss: 0.6216 - val_accuracy: 0.6552\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5969 - accuracy: 0.6911 - val_loss: 0.6204 - val_accuracy: 0.6552\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5951 - accuracy: 0.6927 - val_loss: 0.6192 - val_accuracy: 0.6575\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.5934 - accuracy: 0.6911 - val_loss: 0.6180 - val_accuracy: 0.6506\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5918 - accuracy: 0.6935 - val_loss: 0.6171 - val_accuracy: 0.6483\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5904 - accuracy: 0.6931 - val_loss: 0.6163 - val_accuracy: 0.6483\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5889 - accuracy: 0.6923 - val_loss: 0.6154 - val_accuracy: 0.6529\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5875 - accuracy: 0.6947 - val_loss: 0.6145 - val_accuracy: 0.6552\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5862 - accuracy: 0.6939 - val_loss: 0.6138 - val_accuracy: 0.6552\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5849 - accuracy: 0.6943 - val_loss: 0.6129 - val_accuracy: 0.6552\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5836 - accuracy: 0.6939 - val_loss: 0.6121 - val_accuracy: 0.6575\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5825 - accuracy: 0.6992 - val_loss: 0.6116 - val_accuracy: 0.6575\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5815 - accuracy: 0.7000 - val_loss: 0.6110 - val_accuracy: 0.6552\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5804 - accuracy: 0.6972 - val_loss: 0.6104 - val_accuracy: 0.6529\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5794 - accuracy: 0.7000 - val_loss: 0.6099 - val_accuracy: 0.6529\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5785 - accuracy: 0.6980 - val_loss: 0.6095 - val_accuracy: 0.6506\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5775 - accuracy: 0.6976 - val_loss: 0.6092 - val_accuracy: 0.6506\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5767 - accuracy: 0.6980 - val_loss: 0.6088 - val_accuracy: 0.6529\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5759 - accuracy: 0.7012 - val_loss: 0.6084 - val_accuracy: 0.6529\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5750 - accuracy: 0.7004 - val_loss: 0.6081 - val_accuracy: 0.6506\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5743 - accuracy: 0.6980 - val_loss: 0.6077 - val_accuracy: 0.6575\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5736 - accuracy: 0.7004 - val_loss: 0.6074 - val_accuracy: 0.6552\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5729 - accuracy: 0.7008 - val_loss: 0.6072 - val_accuracy: 0.6529\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5722 - accuracy: 0.7037 - val_loss: 0.6070 - val_accuracy: 0.6552\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5717 - accuracy: 0.7045 - val_loss: 0.6067 - val_accuracy: 0.6552\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5709 - accuracy: 0.7028 - val_loss: 0.6065 - val_accuracy: 0.6644\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5703 - accuracy: 0.7065 - val_loss: 0.6062 - val_accuracy: 0.6575\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5699 - accuracy: 0.7081 - val_loss: 0.6061 - val_accuracy: 0.6644\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5693 - accuracy: 0.7053 - val_loss: 0.6061 - val_accuracy: 0.6598\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5688 - accuracy: 0.7053 - val_loss: 0.6059 - val_accuracy: 0.6598\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5682 - accuracy: 0.7073 - val_loss: 0.6058 - val_accuracy: 0.6552\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5677 - accuracy: 0.7069 - val_loss: 0.6056 - val_accuracy: 0.6552\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5674 - accuracy: 0.7049 - val_loss: 0.6058 - val_accuracy: 0.6575\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5669 - accuracy: 0.7069 - val_loss: 0.6058 - val_accuracy: 0.6575\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5664 - accuracy: 0.7077 - val_loss: 0.6059 - val_accuracy: 0.6575\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5660 - accuracy: 0.7073 - val_loss: 0.6057 - val_accuracy: 0.6575\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5655 - accuracy: 0.7077 - val_loss: 0.6058 - val_accuracy: 0.6598\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5651 - accuracy: 0.7061 - val_loss: 0.6057 - val_accuracy: 0.6621\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5648 - accuracy: 0.7106 - val_loss: 0.6056 - val_accuracy: 0.6575\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5644 - accuracy: 0.7098 - val_loss: 0.6059 - val_accuracy: 0.6575\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5640 - accuracy: 0.7085 - val_loss: 0.6059 - val_accuracy: 0.6575\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5637 - accuracy: 0.7077 - val_loss: 0.6057 - val_accuracy: 0.6598\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5633 - accuracy: 0.7110 - val_loss: 0.6059 - val_accuracy: 0.6552\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5631 - accuracy: 0.7069 - val_loss: 0.6059 - val_accuracy: 0.6552\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5627 - accuracy: 0.7106 - val_loss: 0.6057 - val_accuracy: 0.6598\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5625 - accuracy: 0.7102 - val_loss: 0.6058 - val_accuracy: 0.6575\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.7081 - val_loss: 0.6058 - val_accuracy: 0.6575\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5617 - accuracy: 0.7073 - val_loss: 0.6061 - val_accuracy: 0.6529\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5616 - accuracy: 0.7102 - val_loss: 0.6059 - val_accuracy: 0.6598\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5611 - accuracy: 0.7106 - val_loss: 0.6060 - val_accuracy: 0.6575\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5609 - accuracy: 0.7122 - val_loss: 0.6060 - val_accuracy: 0.6552\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5606 - accuracy: 0.7122 - val_loss: 0.6061 - val_accuracy: 0.6552\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5603 - accuracy: 0.7118 - val_loss: 0.6060 - val_accuracy: 0.6575\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5600 - accuracy: 0.7118 - val_loss: 0.6061 - val_accuracy: 0.6575\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5597 - accuracy: 0.7118 - val_loss: 0.6062 - val_accuracy: 0.6575\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5594 - accuracy: 0.7110 - val_loss: 0.6063 - val_accuracy: 0.6552\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5592 - accuracy: 0.7098 - val_loss: 0.6066 - val_accuracy: 0.6552\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5589 - accuracy: 0.7122 - val_loss: 0.6064 - val_accuracy: 0.6575\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5586 - accuracy: 0.7118 - val_loss: 0.6065 - val_accuracy: 0.6552\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5583 - accuracy: 0.7134 - val_loss: 0.6067 - val_accuracy: 0.6644\n",
      "2895/2895 [==============================] - 0s 29us/sample - loss: 0.5648 - accuracy: 0.7054\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 229us/sample - loss: 2.5393 - accuracy: 0.4553 - val_loss: 1.5452 - val_accuracy: 0.5609\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 1.0664 - accuracy: 0.5898 - val_loss: 0.7610 - val_accuracy: 0.6161\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6874 - accuracy: 0.6398 - val_loss: 0.6453 - val_accuracy: 0.6736\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6207 - accuracy: 0.6703 - val_loss: 0.6194 - val_accuracy: 0.6713\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5973 - accuracy: 0.6939 - val_loss: 0.6208 - val_accuracy: 0.6552\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.5879 - accuracy: 0.6886 - val_loss: 0.6102 - val_accuracy: 0.6552\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5799 - accuracy: 0.6963 - val_loss: 0.6058 - val_accuracy: 0.6713\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5763 - accuracy: 0.6967 - val_loss: 0.6052 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 139us/sample - loss: 0.5719 - accuracy: 0.6915 - val_loss: 0.6049 - val_accuracy: 0.6759\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5697 - accuracy: 0.7041 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5680 - accuracy: 0.6939 - val_loss: 0.6075 - val_accuracy: 0.6805\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 132us/sample - loss: 0.5657 - accuracy: 0.6988 - val_loss: 0.6101 - val_accuracy: 0.6874\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5640 - accuracy: 0.7045 - val_loss: 0.6083 - val_accuracy: 0.6851\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5626 - accuracy: 0.7045 - val_loss: 0.6081 - val_accuracy: 0.6851\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5593 - accuracy: 0.7077 - val_loss: 0.6091 - val_accuracy: 0.6851\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5578 - accuracy: 0.7045 - val_loss: 0.6114 - val_accuracy: 0.6851\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5563 - accuracy: 0.7093 - val_loss: 0.6101 - val_accuracy: 0.6805\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5553 - accuracy: 0.7102 - val_loss: 0.6093 - val_accuracy: 0.6782\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5516 - accuracy: 0.7183 - val_loss: 0.6117 - val_accuracy: 0.6851\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5511 - accuracy: 0.7159 - val_loss: 0.6153 - val_accuracy: 0.6897\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5492 - accuracy: 0.7150 - val_loss: 0.6119 - val_accuracy: 0.6943\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5476 - accuracy: 0.7130 - val_loss: 0.6116 - val_accuracy: 0.6897\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5451 - accuracy: 0.7175 - val_loss: 0.6128 - val_accuracy: 0.6713\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5437 - accuracy: 0.7215 - val_loss: 0.6219 - val_accuracy: 0.6690\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5416 - accuracy: 0.7228 - val_loss: 0.6164 - val_accuracy: 0.6920\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5401 - accuracy: 0.7163 - val_loss: 0.6179 - val_accuracy: 0.6920\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5393 - accuracy: 0.7211 - val_loss: 0.6207 - val_accuracy: 0.6713\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5353 - accuracy: 0.7228 - val_loss: 0.6214 - val_accuracy: 0.6759\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5346 - accuracy: 0.7248 - val_loss: 0.6191 - val_accuracy: 0.6851\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5310 - accuracy: 0.7325 - val_loss: 0.6199 - val_accuracy: 0.6759\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5306 - accuracy: 0.7240 - val_loss: 0.6251 - val_accuracy: 0.6506\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5290 - accuracy: 0.7256 - val_loss: 0.6207 - val_accuracy: 0.6713\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5277 - accuracy: 0.7313 - val_loss: 0.6206 - val_accuracy: 0.6897\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5258 - accuracy: 0.7354 - val_loss: 0.6199 - val_accuracy: 0.6782\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5208 - accuracy: 0.7341 - val_loss: 0.6214 - val_accuracy: 0.6828\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5221 - accuracy: 0.7280 - val_loss: 0.6212 - val_accuracy: 0.6897\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5203 - accuracy: 0.7354 - val_loss: 0.6210 - val_accuracy: 0.6736\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5181 - accuracy: 0.7341 - val_loss: 0.6230 - val_accuracy: 0.6805\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5160 - accuracy: 0.7386 - val_loss: 0.6244 - val_accuracy: 0.6874\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5145 - accuracy: 0.7394 - val_loss: 0.6285 - val_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5125 - accuracy: 0.7390 - val_loss: 0.6298 - val_accuracy: 0.6805\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5103 - accuracy: 0.7439 - val_loss: 0.6315 - val_accuracy: 0.6874\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5078 - accuracy: 0.7398 - val_loss: 0.6362 - val_accuracy: 0.6805\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.6297 - val_accuracy: 0.6874\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5047 - accuracy: 0.7447 - val_loss: 0.6319 - val_accuracy: 0.6851\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.4996 - accuracy: 0.7447 - val_loss: 0.6492 - val_accuracy: 0.6759\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5019 - accuracy: 0.7492 - val_loss: 0.6370 - val_accuracy: 0.6897\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5003 - accuracy: 0.7467 - val_loss: 0.6347 - val_accuracy: 0.6759\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4965 - accuracy: 0.7537 - val_loss: 0.6357 - val_accuracy: 0.6759\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.4942 - accuracy: 0.7557 - val_loss: 0.6350 - val_accuracy: 0.6805\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4928 - accuracy: 0.7557 - val_loss: 0.6360 - val_accuracy: 0.6690\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.4911 - accuracy: 0.7549 - val_loss: 0.6381 - val_accuracy: 0.6759\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4877 - accuracy: 0.7569 - val_loss: 0.6439 - val_accuracy: 0.6759\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.4855 - accuracy: 0.7569 - val_loss: 0.6501 - val_accuracy: 0.6897\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4849 - accuracy: 0.7492 - val_loss: 0.6414 - val_accuracy: 0.6759\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4828 - accuracy: 0.7630 - val_loss: 0.6434 - val_accuracy: 0.6759\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4804 - accuracy: 0.7638 - val_loss: 0.6446 - val_accuracy: 0.6759\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4785 - accuracy: 0.7626 - val_loss: 0.6453 - val_accuracy: 0.6621\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.4765 - accuracy: 0.7606 - val_loss: 0.6480 - val_accuracy: 0.6575\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4748 - accuracy: 0.7659 - val_loss: 0.6517 - val_accuracy: 0.6828\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4722 - accuracy: 0.7663 - val_loss: 0.6528 - val_accuracy: 0.6621\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4697 - accuracy: 0.7671 - val_loss: 0.6498 - val_accuracy: 0.6713\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.4693 - accuracy: 0.7703 - val_loss: 0.6536 - val_accuracy: 0.6506\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4667 - accuracy: 0.7764 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4646 - accuracy: 0.7744 - val_loss: 0.6681 - val_accuracy: 0.6391\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4632 - accuracy: 0.7671 - val_loss: 0.6572 - val_accuracy: 0.6483\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.4612 - accuracy: 0.7809 - val_loss: 0.6611 - val_accuracy: 0.6805\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4586 - accuracy: 0.7797 - val_loss: 0.6591 - val_accuracy: 0.6506\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4570 - accuracy: 0.7793 - val_loss: 0.6602 - val_accuracy: 0.6529\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4548 - accuracy: 0.7829 - val_loss: 0.6664 - val_accuracy: 0.6460\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.4524 - accuracy: 0.7813 - val_loss: 0.6645 - val_accuracy: 0.6483\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4518 - accuracy: 0.7825 - val_loss: 0.6674 - val_accuracy: 0.6414\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.4489 - accuracy: 0.7862 - val_loss: 0.6685 - val_accuracy: 0.6621\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4478 - accuracy: 0.7874 - val_loss: 0.6714 - val_accuracy: 0.6644\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4454 - accuracy: 0.7939 - val_loss: 0.6729 - val_accuracy: 0.6621\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4430 - accuracy: 0.7939 - val_loss: 0.6756 - val_accuracy: 0.6483\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4425 - accuracy: 0.7858 - val_loss: 0.6793 - val_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4400 - accuracy: 0.7939 - val_loss: 0.6812 - val_accuracy: 0.6644\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.6802 - val_accuracy: 0.6598\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.4355 - accuracy: 0.7931 - val_loss: 0.6800 - val_accuracy: 0.6414\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4342 - accuracy: 0.7955 - val_loss: 0.6817 - val_accuracy: 0.6598\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4334 - accuracy: 0.7959 - val_loss: 0.6831 - val_accuracy: 0.6575\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4314 - accuracy: 0.8008 - val_loss: 0.6863 - val_accuracy: 0.6322\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.4283 - accuracy: 0.7972 - val_loss: 0.6961 - val_accuracy: 0.6276\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4275 - accuracy: 0.8004 - val_loss: 0.6874 - val_accuracy: 0.6460\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4241 - accuracy: 0.8016 - val_loss: 0.6929 - val_accuracy: 0.6483\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.4235 - accuracy: 0.8098 - val_loss: 0.6953 - val_accuracy: 0.6391\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4213 - accuracy: 0.8085 - val_loss: 0.6972 - val_accuracy: 0.6552\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4192 - accuracy: 0.8069 - val_loss: 0.6963 - val_accuracy: 0.6391\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4179 - accuracy: 0.8089 - val_loss: 0.6977 - val_accuracy: 0.6368\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.4160 - accuracy: 0.8093 - val_loss: 0.7004 - val_accuracy: 0.6391\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4142 - accuracy: 0.8085 - val_loss: 0.7002 - val_accuracy: 0.6437\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.4126 - accuracy: 0.8150 - val_loss: 0.7049 - val_accuracy: 0.6368\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4106 - accuracy: 0.8146 - val_loss: 0.7107 - val_accuracy: 0.6368\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4084 - accuracy: 0.8150 - val_loss: 0.7256 - val_accuracy: 0.6437\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4073 - accuracy: 0.8102 - val_loss: 0.7146 - val_accuracy: 0.6529\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4066 - accuracy: 0.8130 - val_loss: 0.7114 - val_accuracy: 0.6391\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4028 - accuracy: 0.8232 - val_loss: 0.7147 - val_accuracy: 0.6345\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4033 - accuracy: 0.8248 - val_loss: 0.7130 - val_accuracy: 0.6391\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4020 - accuracy: 0.8191 - val_loss: 0.7159 - val_accuracy: 0.6414\n",
      "2895/2895 [==============================] - 0s 22us/sample - loss: 0.4351 - accuracy: 0.8031\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 180us/sample - loss: 0.7974 - accuracy: 0.6114 - val_loss: 0.6699 - val_accuracy: 0.6276\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.6194 - accuracy: 0.6553 - val_loss: 0.6213 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5942 - accuracy: 0.6821 - val_loss: 0.6362 - val_accuracy: 0.6529\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5825 - accuracy: 0.6927 - val_loss: 0.6329 - val_accuracy: 0.6529\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.5693 - accuracy: 0.7008 - val_loss: 0.6267 - val_accuracy: 0.6736\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5599 - accuracy: 0.7081 - val_loss: 0.6366 - val_accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5500 - accuracy: 0.7191 - val_loss: 0.6433 - val_accuracy: 0.6644\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5392 - accuracy: 0.7232 - val_loss: 0.6389 - val_accuracy: 0.6644\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5241 - accuracy: 0.7341 - val_loss: 0.6735 - val_accuracy: 0.6621\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5113 - accuracy: 0.7463 - val_loss: 0.6720 - val_accuracy: 0.6644\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5050 - accuracy: 0.7476 - val_loss: 0.6821 - val_accuracy: 0.6736\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4887 - accuracy: 0.7650 - val_loss: 0.7182 - val_accuracy: 0.6690\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4806 - accuracy: 0.7569 - val_loss: 0.7079 - val_accuracy: 0.6529\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4708 - accuracy: 0.7789 - val_loss: 0.7367 - val_accuracy: 0.6414\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4513 - accuracy: 0.7797 - val_loss: 0.7578 - val_accuracy: 0.6368\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 119us/sample - loss: 0.4446 - accuracy: 0.7878 - val_loss: 0.7933 - val_accuracy: 0.6529\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4294 - accuracy: 0.7894 - val_loss: 0.8078 - val_accuracy: 0.6391\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4155 - accuracy: 0.8098 - val_loss: 0.8610 - val_accuracy: 0.6184\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4028 - accuracy: 0.8028 - val_loss: 0.8753 - val_accuracy: 0.6322\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.3996 - accuracy: 0.8138 - val_loss: 0.8833 - val_accuracy: 0.6345\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3846 - accuracy: 0.8207 - val_loss: 0.9143 - val_accuracy: 0.6230\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3713 - accuracy: 0.8248 - val_loss: 1.0073 - val_accuracy: 0.6322\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3649 - accuracy: 0.8272 - val_loss: 0.9832 - val_accuracy: 0.6207\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3537 - accuracy: 0.8394 - val_loss: 1.0142 - val_accuracy: 0.6092\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3486 - accuracy: 0.8463 - val_loss: 1.0719 - val_accuracy: 0.6161\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3378 - accuracy: 0.8463 - val_loss: 1.0813 - val_accuracy: 0.5977\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3261 - accuracy: 0.8516 - val_loss: 1.1044 - val_accuracy: 0.6207\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3207 - accuracy: 0.8541 - val_loss: 1.1051 - val_accuracy: 0.6092\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3157 - accuracy: 0.8585 - val_loss: 1.1268 - val_accuracy: 0.6253\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3057 - accuracy: 0.8663 - val_loss: 1.1829 - val_accuracy: 0.6115\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2988 - accuracy: 0.8626 - val_loss: 1.2353 - val_accuracy: 0.5977\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.2891 - accuracy: 0.8703 - val_loss: 1.2672 - val_accuracy: 0.6207\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.2856 - accuracy: 0.8760 - val_loss: 1.2745 - val_accuracy: 0.6138\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.2805 - accuracy: 0.8833 - val_loss: 1.2799 - val_accuracy: 0.6138\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.2772 - accuracy: 0.8764 - val_loss: 1.3746 - val_accuracy: 0.6046\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2716 - accuracy: 0.8793 - val_loss: 1.3750 - val_accuracy: 0.6046\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.2649 - accuracy: 0.8817 - val_loss: 1.4295 - val_accuracy: 0.5931\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.2591 - accuracy: 0.8894 - val_loss: 1.4196 - val_accuracy: 0.6092\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.2498 - accuracy: 0.8951 - val_loss: 1.4534 - val_accuracy: 0.6207\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.2503 - accuracy: 0.8943 - val_loss: 1.5100 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.2501 - accuracy: 0.8890 - val_loss: 1.5755 - val_accuracy: 0.6184\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.2349 - accuracy: 0.9004 - val_loss: 1.5549 - val_accuracy: 0.6069\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.2343 - accuracy: 0.8992 - val_loss: 1.6450 - val_accuracy: 0.5885\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2347 - accuracy: 0.9028 - val_loss: 1.5939 - val_accuracy: 0.5954\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2275 - accuracy: 0.8992 - val_loss: 1.5928 - val_accuracy: 0.6092\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.2230 - accuracy: 0.9114 - val_loss: 1.6731 - val_accuracy: 0.5839\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.2160 - accuracy: 0.9057 - val_loss: 1.7488 - val_accuracy: 0.5862\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2231 - accuracy: 0.9049 - val_loss: 1.7555 - val_accuracy: 0.5908\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.2154 - accuracy: 0.9077 - val_loss: 1.7589 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.2106 - accuracy: 0.9126 - val_loss: 1.7979 - val_accuracy: 0.5954\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.2070 - accuracy: 0.9126 - val_loss: 1.8121 - val_accuracy: 0.6046\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.2053 - accuracy: 0.9146 - val_loss: 1.8625 - val_accuracy: 0.5977\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.2043 - accuracy: 0.9167 - val_loss: 1.8748 - val_accuracy: 0.6207\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.1910 - accuracy: 0.9228 - val_loss: 1.9832 - val_accuracy: 0.6069\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 0.1979 - accuracy: 0.9159 - val_loss: 1.8980 - val_accuracy: 0.5977\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.1888 - accuracy: 0.9220 - val_loss: 2.0016 - val_accuracy: 0.5816\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1919 - accuracy: 0.9175 - val_loss: 2.0243 - val_accuracy: 0.6069\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1890 - accuracy: 0.9252 - val_loss: 2.0376 - val_accuracy: 0.5908\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.1896 - accuracy: 0.9252 - val_loss: 2.1073 - val_accuracy: 0.5931\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.1794 - accuracy: 0.9285 - val_loss: 2.0964 - val_accuracy: 0.6092\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.1719 - accuracy: 0.9256 - val_loss: 2.1639 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.1809 - accuracy: 0.9260 - val_loss: 2.1018 - val_accuracy: 0.5954\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.1818 - accuracy: 0.9280 - val_loss: 2.1772 - val_accuracy: 0.6046\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1741 - accuracy: 0.9325 - val_loss: 2.1996 - val_accuracy: 0.5954\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.1760 - accuracy: 0.9297 - val_loss: 2.2048 - val_accuracy: 0.6046\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1715 - accuracy: 0.9341 - val_loss: 2.2650 - val_accuracy: 0.5793\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.1623 - accuracy: 0.9341 - val_loss: 2.2167 - val_accuracy: 0.6023\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1685 - accuracy: 0.9362 - val_loss: 2.2490 - val_accuracy: 0.5908\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.1640 - accuracy: 0.9378 - val_loss: 2.4238 - val_accuracy: 0.6092\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1571 - accuracy: 0.9362 - val_loss: 2.3568 - val_accuracy: 0.6046\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.1618 - accuracy: 0.9325 - val_loss: 2.4489 - val_accuracy: 0.5954\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.1573 - accuracy: 0.9386 - val_loss: 2.4766 - val_accuracy: 0.5885\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.1563 - accuracy: 0.9431 - val_loss: 2.4268 - val_accuracy: 0.6023\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1517 - accuracy: 0.9382 - val_loss: 2.5203 - val_accuracy: 0.6069\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1538 - accuracy: 0.9390 - val_loss: 2.4066 - val_accuracy: 0.6023\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.1523 - accuracy: 0.9439 - val_loss: 2.4730 - val_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1590 - accuracy: 0.9407 - val_loss: 2.4346 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.1553 - accuracy: 0.9451 - val_loss: 2.5443 - val_accuracy: 0.5931\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1425 - accuracy: 0.9467 - val_loss: 2.5382 - val_accuracy: 0.5885\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.1523 - accuracy: 0.9390 - val_loss: 2.6068 - val_accuracy: 0.5770\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.1462 - accuracy: 0.9484 - val_loss: 2.5182 - val_accuracy: 0.5908\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.1503 - accuracy: 0.9447 - val_loss: 2.6231 - val_accuracy: 0.5862\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.1506 - accuracy: 0.9407 - val_loss: 2.6395 - val_accuracy: 0.5862\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.1362 - accuracy: 0.9467 - val_loss: 2.6546 - val_accuracy: 0.6092\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.1357 - accuracy: 0.9439 - val_loss: 2.5482 - val_accuracy: 0.5862\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1463 - accuracy: 0.9463 - val_loss: 2.6688 - val_accuracy: 0.5885\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.1323 - accuracy: 0.9476 - val_loss: 2.7086 - val_accuracy: 0.5724\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.1303 - accuracy: 0.9476 - val_loss: 2.6953 - val_accuracy: 0.5954\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.1324 - accuracy: 0.9463 - val_loss: 2.7722 - val_accuracy: 0.5931\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1339 - accuracy: 0.9476 - val_loss: 2.7871 - val_accuracy: 0.5816\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1337 - accuracy: 0.9463 - val_loss: 2.8709 - val_accuracy: 0.6069\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.1361 - accuracy: 0.9504 - val_loss: 2.8080 - val_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1324 - accuracy: 0.9484 - val_loss: 2.7731 - val_accuracy: 0.6069\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.1320 - accuracy: 0.9435 - val_loss: 2.8794 - val_accuracy: 0.6023\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.1205 - accuracy: 0.9472 - val_loss: 2.9881 - val_accuracy: 0.5954\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.1344 - accuracy: 0.9451 - val_loss: 3.0090 - val_accuracy: 0.6092\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.1228 - accuracy: 0.9524 - val_loss: 3.0214 - val_accuracy: 0.6092\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.1274 - accuracy: 0.9508 - val_loss: 3.1566 - val_accuracy: 0.5793\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.1276 - accuracy: 0.9520 - val_loss: 3.1861 - val_accuracy: 0.5816\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1255 - accuracy: 0.9512 - val_loss: 3.0479 - val_accuracy: 0.6000\n",
      "2895/2895 [==============================] - 0s 24us/sample - loss: 0.5366 - accuracy: 0.9123\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 298us/sample - loss: 1.0422 - accuracy: 0.5565 - val_loss: 0.7614 - val_accuracy: 0.5632\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7331 - accuracy: 0.6142 - val_loss: 0.7068 - val_accuracy: 0.6184\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.7025 - accuracy: 0.6435 - val_loss: 0.8064 - val_accuracy: 0.6161\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.6722 - accuracy: 0.6545 - val_loss: 0.7383 - val_accuracy: 0.6184\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.6562 - accuracy: 0.6561 - val_loss: 0.7623 - val_accuracy: 0.6345\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6272 - accuracy: 0.6679 - val_loss: 0.7504 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5987 - accuracy: 0.6915 - val_loss: 0.9135 - val_accuracy: 0.6115\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6144 - accuracy: 0.6931 - val_loss: 1.0910 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5948 - accuracy: 0.6972 - val_loss: 0.8513 - val_accuracy: 0.5977\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5607 - accuracy: 0.7077 - val_loss: 0.9164 - val_accuracy: 0.6161\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5542 - accuracy: 0.7150 - val_loss: 0.9101 - val_accuracy: 0.6023\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5414 - accuracy: 0.7293 - val_loss: 0.8517 - val_accuracy: 0.6138\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5581 - accuracy: 0.7248 - val_loss: 0.8955 - val_accuracy: 0.6161\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5251 - accuracy: 0.7264 - val_loss: 1.0825 - val_accuracy: 0.5885\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 133us/sample - loss: 0.5287 - accuracy: 0.7228 - val_loss: 0.8750 - val_accuracy: 0.6023\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5254 - accuracy: 0.7280 - val_loss: 0.9264 - val_accuracy: 0.6046\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5024 - accuracy: 0.7480 - val_loss: 1.0657 - val_accuracy: 0.6161\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.4911 - accuracy: 0.7431 - val_loss: 1.0864 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4944 - accuracy: 0.7443 - val_loss: 1.1166 - val_accuracy: 0.5747\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4864 - accuracy: 0.7537 - val_loss: 1.0110 - val_accuracy: 0.6138\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4860 - accuracy: 0.7370 - val_loss: 1.5177 - val_accuracy: 0.6023\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4949 - accuracy: 0.7480 - val_loss: 1.2064 - val_accuracy: 0.5632\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4676 - accuracy: 0.7549 - val_loss: 1.2467 - val_accuracy: 0.6299\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4630 - accuracy: 0.7671 - val_loss: 1.3212 - val_accuracy: 0.6115\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4689 - accuracy: 0.7573 - val_loss: 1.2050 - val_accuracy: 0.5977\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.4590 - accuracy: 0.7724 - val_loss: 1.3842 - val_accuracy: 0.6092\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.4548 - accuracy: 0.7679 - val_loss: 1.3231 - val_accuracy: 0.6161\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4508 - accuracy: 0.7638 - val_loss: 1.3604 - val_accuracy: 0.6184\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4274 - accuracy: 0.7711 - val_loss: 1.6592 - val_accuracy: 0.5885\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.4373 - accuracy: 0.7793 - val_loss: 1.5147 - val_accuracy: 0.6023\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4231 - accuracy: 0.7707 - val_loss: 1.5478 - val_accuracy: 0.6414\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4342 - accuracy: 0.7675 - val_loss: 2.0220 - val_accuracy: 0.5793\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4357 - accuracy: 0.7756 - val_loss: 1.7990 - val_accuracy: 0.5954\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.4215 - accuracy: 0.7862 - val_loss: 1.7283 - val_accuracy: 0.5839\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4172 - accuracy: 0.7724 - val_loss: 1.7899 - val_accuracy: 0.6069\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4161 - accuracy: 0.7902 - val_loss: 1.7467 - val_accuracy: 0.6138\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4053 - accuracy: 0.7785 - val_loss: 1.6108 - val_accuracy: 0.5816\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4150 - accuracy: 0.7703 - val_loss: 1.8797 - val_accuracy: 0.5678\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4035 - accuracy: 0.7931 - val_loss: 2.0530 - val_accuracy: 0.5977\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4251 - accuracy: 0.7858 - val_loss: 1.9707 - val_accuracy: 0.5770\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4076 - accuracy: 0.7907 - val_loss: 2.3976 - val_accuracy: 0.6138\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4087 - accuracy: 0.7846 - val_loss: 2.2368 - val_accuracy: 0.5862\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3987 - accuracy: 0.7988 - val_loss: 2.1216 - val_accuracy: 0.5770\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.3922 - accuracy: 0.7882 - val_loss: 1.9396 - val_accuracy: 0.5563\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3876 - accuracy: 0.7984 - val_loss: 2.2143 - val_accuracy: 0.5862\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3995 - accuracy: 0.7793 - val_loss: 2.3361 - val_accuracy: 0.5816\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3809 - accuracy: 0.7793 - val_loss: 2.3087 - val_accuracy: 0.5931\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.3845 - accuracy: 0.7927 - val_loss: 2.1467 - val_accuracy: 0.6138\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3810 - accuracy: 0.7809 - val_loss: 2.6593 - val_accuracy: 0.5632\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3780 - accuracy: 0.7963 - val_loss: 2.1417 - val_accuracy: 0.5908\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.3856 - accuracy: 0.7947 - val_loss: 2.3058 - val_accuracy: 0.6115\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3785 - accuracy: 0.7972 - val_loss: 2.5627 - val_accuracy: 0.5678\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3678 - accuracy: 0.7963 - val_loss: 2.5428 - val_accuracy: 0.5793\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.3692 - accuracy: 0.7907 - val_loss: 2.4371 - val_accuracy: 0.5701\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.3705 - accuracy: 0.7951 - val_loss: 2.3959 - val_accuracy: 0.5954\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3849 - accuracy: 0.7955 - val_loss: 2.4926 - val_accuracy: 0.5862\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3615 - accuracy: 0.7988 - val_loss: 2.4786 - val_accuracy: 0.6115\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3783 - accuracy: 0.7996 - val_loss: 2.5484 - val_accuracy: 0.6069\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3587 - accuracy: 0.7923 - val_loss: 2.7168 - val_accuracy: 0.5816\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3748 - accuracy: 0.8077 - val_loss: 2.6730 - val_accuracy: 0.5977\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3648 - accuracy: 0.8041 - val_loss: 2.8496 - val_accuracy: 0.5724\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.3590 - accuracy: 0.8041 - val_loss: 2.7205 - val_accuracy: 0.5724\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3525 - accuracy: 0.8037 - val_loss: 3.2030 - val_accuracy: 0.5701\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3714 - accuracy: 0.8167 - val_loss: 3.0682 - val_accuracy: 0.5632\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.3487 - accuracy: 0.8077 - val_loss: 3.2131 - val_accuracy: 0.5655\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3526 - accuracy: 0.8093 - val_loss: 3.2583 - val_accuracy: 0.6069\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3578 - accuracy: 0.8102 - val_loss: 2.8340 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3620 - accuracy: 0.7976 - val_loss: 3.0564 - val_accuracy: 0.5563\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3544 - accuracy: 0.8085 - val_loss: 3.0647 - val_accuracy: 0.6115\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3613 - accuracy: 0.8081 - val_loss: 3.2517 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3466 - accuracy: 0.7931 - val_loss: 3.2794 - val_accuracy: 0.5701\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.3514 - accuracy: 0.8028 - val_loss: 2.9705 - val_accuracy: 0.5678\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3652 - accuracy: 0.8081 - val_loss: 3.1781 - val_accuracy: 0.5655\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.3595 - accuracy: 0.8118 - val_loss: 3.3622 - val_accuracy: 0.5540\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3521 - accuracy: 0.8033 - val_loss: 3.0242 - val_accuracy: 0.5747\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3371 - accuracy: 0.8134 - val_loss: 3.0123 - val_accuracy: 0.6138\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3367 - accuracy: 0.8077 - val_loss: 2.9100 - val_accuracy: 0.5770\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.3454 - accuracy: 0.8061 - val_loss: 3.0111 - val_accuracy: 0.5793\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3403 - accuracy: 0.8081 - val_loss: 2.8822 - val_accuracy: 0.5563\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3368 - accuracy: 0.8150 - val_loss: 3.5914 - val_accuracy: 0.5678\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.3389 - accuracy: 0.8081 - val_loss: 3.4970 - val_accuracy: 0.5655\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3466 - accuracy: 0.8118 - val_loss: 3.5836 - val_accuracy: 0.6161\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3336 - accuracy: 0.8093 - val_loss: 3.4414 - val_accuracy: 0.5747\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.3371 - accuracy: 0.8224 - val_loss: 3.3338 - val_accuracy: 0.5586\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.3316 - accuracy: 0.8061 - val_loss: 3.4187 - val_accuracy: 0.6092\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.3441 - accuracy: 0.8057 - val_loss: 3.3721 - val_accuracy: 0.5471\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.3392 - accuracy: 0.8114 - val_loss: 3.6739 - val_accuracy: 0.5793\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.3250 - accuracy: 0.8049 - val_loss: 3.2896 - val_accuracy: 0.5839\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3379 - accuracy: 0.8053 - val_loss: 3.4934 - val_accuracy: 0.5908\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.3275 - accuracy: 0.8122 - val_loss: 3.8374 - val_accuracy: 0.6138\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3295 - accuracy: 0.8118 - val_loss: 3.7903 - val_accuracy: 0.5724\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3316 - accuracy: 0.8122 - val_loss: 3.8453 - val_accuracy: 0.5839\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.3133 - accuracy: 0.8130 - val_loss: 4.3235 - val_accuracy: 0.6092\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3374 - accuracy: 0.8089 - val_loss: 4.1484 - val_accuracy: 0.5839\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3258 - accuracy: 0.8159 - val_loss: 3.8632 - val_accuracy: 0.5747\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3192 - accuracy: 0.8089 - val_loss: 4.4182 - val_accuracy: 0.5724\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3350 - accuracy: 0.8069 - val_loss: 4.0621 - val_accuracy: 0.5678\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3367 - accuracy: 0.8053 - val_loss: 4.3468 - val_accuracy: 0.5701\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.3205 - accuracy: 0.8248 - val_loss: 4.5512 - val_accuracy: 0.5678\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3290 - accuracy: 0.8102 - val_loss: 4.4577 - val_accuracy: 0.5609\n",
      "2895/2895 [==============================] - 0s 32us/sample - loss: 0.9253 - accuracy: 0.7855\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 185us/sample - loss: 25.4342 - accuracy: 0.5301 - val_loss: 1.6224 - val_accuracy: 0.5103\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.9175 - accuracy: 0.5049 - val_loss: 1.0596 - val_accuracy: 0.4644\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.9381 - accuracy: 0.5122 - val_loss: 0.9052 - val_accuracy: 0.4598\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8406 - accuracy: 0.5020 - val_loss: 0.9872 - val_accuracy: 0.5425\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.8310 - accuracy: 0.5037 - val_loss: 0.7163 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.7992 - accuracy: 0.5154 - val_loss: 1.1021 - val_accuracy: 0.4598\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8218 - accuracy: 0.4992 - val_loss: 1.0573 - val_accuracy: 0.4598\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.8083 - accuracy: 0.5065 - val_loss: 0.6910 - val_accuracy: 0.5425\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.8179 - accuracy: 0.5098 - val_loss: 0.7264 - val_accuracy: 0.5425\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.8159 - accuracy: 0.5146 - val_loss: 0.7568 - val_accuracy: 0.4598\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.8108 - accuracy: 0.5114 - val_loss: 0.7191 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8111 - accuracy: 0.5089 - val_loss: 0.7593 - val_accuracy: 0.4598\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 113us/sample - loss: 0.8007 - accuracy: 0.5220 - val_loss: 0.7359 - val_accuracy: 0.5425\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.7951 - accuracy: 0.5211 - val_loss: 0.6997 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.8199 - accuracy: 0.5024 - val_loss: 0.7338 - val_accuracy: 0.4598\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.7866 - accuracy: 0.5138 - val_loss: 0.7579 - val_accuracy: 0.4598\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.8132 - accuracy: 0.5154 - val_loss: 0.7200 - val_accuracy: 0.5425\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.8170 - accuracy: 0.5041 - val_loss: 0.8584 - val_accuracy: 0.5425\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.8103 - accuracy: 0.5098 - val_loss: 0.9004 - val_accuracy: 0.4598\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8113 - accuracy: 0.5065 - val_loss: 0.6953 - val_accuracy: 0.4575\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8030 - accuracy: 0.5211 - val_loss: 0.8838 - val_accuracy: 0.4598\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.8054 - accuracy: 0.5211 - val_loss: 0.7588 - val_accuracy: 0.5425\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7955 - accuracy: 0.5236 - val_loss: 0.7923 - val_accuracy: 0.5425\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.8241 - accuracy: 0.5106 - val_loss: 0.8775 - val_accuracy: 0.5425\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.8252 - accuracy: 0.4967 - val_loss: 0.7513 - val_accuracy: 0.5425\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8174 - accuracy: 0.5065 - val_loss: 0.7665 - val_accuracy: 0.4598\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8162 - accuracy: 0.5000 - val_loss: 0.9194 - val_accuracy: 0.4598\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.8023 - accuracy: 0.5114 - val_loss: 1.1853 - val_accuracy: 0.5425\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.8104 - accuracy: 0.5098 - val_loss: 0.7097 - val_accuracy: 0.4575\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.8132 - accuracy: 0.5073 - val_loss: 1.0097 - val_accuracy: 0.4598\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.8107 - accuracy: 0.5220 - val_loss: 0.7295 - val_accuracy: 0.5425\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7968 - accuracy: 0.5301 - val_loss: 0.7382 - val_accuracy: 0.4598\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8065 - accuracy: 0.5187 - val_loss: 0.9453 - val_accuracy: 0.4598\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8132 - accuracy: 0.5065 - val_loss: 0.9524 - val_accuracy: 0.4598\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 121us/sample - loss: 0.8306 - accuracy: 0.4943 - val_loss: 0.7395 - val_accuracy: 0.5425\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8035 - accuracy: 0.5187 - val_loss: 0.7122 - val_accuracy: 0.5425\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.8082 - accuracy: 0.5049 - val_loss: 0.7181 - val_accuracy: 0.4598\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7932 - accuracy: 0.5260 - val_loss: 0.8255 - val_accuracy: 0.5425\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.8041 - accuracy: 0.5081 - val_loss: 0.9800 - val_accuracy: 0.5425\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.8265 - accuracy: 0.5008 - val_loss: 0.7994 - val_accuracy: 0.5425\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.8105 - accuracy: 0.5146 - val_loss: 0.9940 - val_accuracy: 0.4598\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 121us/sample - loss: 0.8138 - accuracy: 0.4927 - val_loss: 0.7522 - val_accuracy: 0.5425\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.8278 - accuracy: 0.4878 - val_loss: 0.9243 - val_accuracy: 0.5425\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.7933 - accuracy: 0.5260 - val_loss: 0.7096 - val_accuracy: 0.5425\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.8242 - accuracy: 0.4911 - val_loss: 0.6890 - val_accuracy: 0.5425\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.7939 - accuracy: 0.5244 - val_loss: 0.6889 - val_accuracy: 0.5425\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.8251 - accuracy: 0.5089 - val_loss: 0.9634 - val_accuracy: 0.4598\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.8088 - accuracy: 0.5049 - val_loss: 0.7440 - val_accuracy: 0.5425\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.8246 - accuracy: 0.4976 - val_loss: 0.7815 - val_accuracy: 0.5425\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 117us/sample - loss: 0.8318 - accuracy: 0.4984 - val_loss: 0.9469 - val_accuracy: 0.5425\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.8205 - accuracy: 0.4870 - val_loss: 0.9085 - val_accuracy: 0.5425\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.8093 - accuracy: 0.5106 - val_loss: 0.8351 - val_accuracy: 0.5425\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.8180 - accuracy: 0.5033 - val_loss: 0.8561 - val_accuracy: 0.5425\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.8044 - accuracy: 0.5122 - val_loss: 0.6906 - val_accuracy: 0.5425\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.8281 - accuracy: 0.4967 - val_loss: 0.8038 - val_accuracy: 0.5425\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.8044 - accuracy: 0.4992 - val_loss: 0.8857 - val_accuracy: 0.4598\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.8218 - accuracy: 0.5073 - val_loss: 1.2430 - val_accuracy: 0.5425\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.8216 - accuracy: 0.4984 - val_loss: 0.7293 - val_accuracy: 0.4598\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7934 - accuracy: 0.5138 - val_loss: 0.7528 - val_accuracy: 0.4598\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8253 - accuracy: 0.4959 - val_loss: 0.6984 - val_accuracy: 0.4575\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8047 - accuracy: 0.5065 - val_loss: 0.6891 - val_accuracy: 0.5425\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.8072 - accuracy: 0.5301 - val_loss: 0.7123 - val_accuracy: 0.4575\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.8185 - accuracy: 0.4976 - val_loss: 0.6889 - val_accuracy: 0.5425\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8053 - accuracy: 0.5114 - val_loss: 0.6948 - val_accuracy: 0.5425\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.8095 - accuracy: 0.5130 - val_loss: 0.9804 - val_accuracy: 0.4598\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.8224 - accuracy: 0.4902 - val_loss: 0.7952 - val_accuracy: 0.5425\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.8057 - accuracy: 0.5195 - val_loss: 0.7580 - val_accuracy: 0.5425\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8190 - accuracy: 0.4959 - val_loss: 0.6888 - val_accuracy: 0.5425\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8274 - accuracy: 0.4959 - val_loss: 0.6992 - val_accuracy: 0.5425\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.8246 - accuracy: 0.4927 - val_loss: 0.8730 - val_accuracy: 0.4598\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8229 - accuracy: 0.4886 - val_loss: 0.8021 - val_accuracy: 0.4598\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.8228 - accuracy: 0.4967 - val_loss: 0.7231 - val_accuracy: 0.5425\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.8034 - accuracy: 0.5073 - val_loss: 1.3752 - val_accuracy: 0.4575\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8166 - accuracy: 0.5130 - val_loss: 0.7869 - val_accuracy: 0.4598\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.8162 - accuracy: 0.5073 - val_loss: 1.1078 - val_accuracy: 0.4598\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.8187 - accuracy: 0.5138 - val_loss: 0.6920 - val_accuracy: 0.5425\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.8295 - accuracy: 0.4886 - val_loss: 0.7234 - val_accuracy: 0.4598\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.8005 - accuracy: 0.5163 - val_loss: 0.7114 - val_accuracy: 0.5425\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8095 - accuracy: 0.5146 - val_loss: 0.6975 - val_accuracy: 0.5425\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.8296 - accuracy: 0.4992 - val_loss: 0.6912 - val_accuracy: 0.5425\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.8306 - accuracy: 0.4911 - val_loss: 0.7200 - val_accuracy: 0.5425\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8096 - accuracy: 0.5041 - val_loss: 0.7217 - val_accuracy: 0.4598\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.8088 - accuracy: 0.5138 - val_loss: 0.6890 - val_accuracy: 0.5425\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.8022 - accuracy: 0.5203 - val_loss: 0.8429 - val_accuracy: 0.5425\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.8135 - accuracy: 0.5073 - val_loss: 1.2330 - val_accuracy: 0.4575\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.8108 - accuracy: 0.5138 - val_loss: 0.9896 - val_accuracy: 0.4598\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.8214 - accuracy: 0.4967 - val_loss: 0.7166 - val_accuracy: 0.4598\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.8151 - accuracy: 0.4992 - val_loss: 0.7140 - val_accuracy: 0.4575\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.8141 - accuracy: 0.5163 - val_loss: 1.1174 - val_accuracy: 0.4598\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8118 - accuracy: 0.4976 - val_loss: 0.6927 - val_accuracy: 0.4575\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.8066 - accuracy: 0.5065 - val_loss: 0.8491 - val_accuracy: 0.4598\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.8277 - accuracy: 0.4935 - val_loss: 0.7141 - val_accuracy: 0.4575\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.8175 - accuracy: 0.5073 - val_loss: 0.8700 - val_accuracy: 0.5425\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8043 - accuracy: 0.5122 - val_loss: 1.1151 - val_accuracy: 0.5425\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.8290 - accuracy: 0.4854 - val_loss: 0.8535 - val_accuracy: 0.4598\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.8218 - accuracy: 0.5016 - val_loss: 0.6964 - val_accuracy: 0.4575\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.8188 - accuracy: 0.5122 - val_loss: 0.7597 - val_accuracy: 0.4598\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.8142 - accuracy: 0.5081 - val_loss: 1.0823 - val_accuracy: 0.4598\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7953 - accuracy: 0.5301 - val_loss: 1.0404 - val_accuracy: 0.5425\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.8048 - accuracy: 0.5122 - val_loss: 0.8281 - val_accuracy: 0.5425\n",
      "2895/2895 [==============================] - 0s 29us/sample - loss: 0.8231 - accuracy: 0.5465\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 140us/sample - loss: 3.6281 - accuracy: 0.0024 - val_loss: 3.6140 - val_accuracy: 0.0115\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 3.6158 - accuracy: 0.0028 - val_loss: 3.6035 - val_accuracy: 0.0138\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 3.6064 - accuracy: 0.0033 - val_loss: 3.5948 - val_accuracy: 0.0161\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 3.5983 - accuracy: 0.0041 - val_loss: 3.5872 - val_accuracy: 0.0161\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.5911 - accuracy: 0.0045 - val_loss: 3.5803 - val_accuracy: 0.0161\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.5845 - accuracy: 0.0053 - val_loss: 3.5739 - val_accuracy: 0.0161\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 115us/sample - loss: 3.5784 - accuracy: 0.0053 - val_loss: 3.5679 - val_accuracy: 0.0161\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 3.5726 - accuracy: 0.0053 - val_loss: 3.5623 - val_accuracy: 0.0184\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 3.5671 - accuracy: 0.0065 - val_loss: 3.5569 - val_accuracy: 0.0184\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.5619 - accuracy: 0.0065 - val_loss: 3.5518 - val_accuracy: 0.0184\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5569 - accuracy: 0.0069 - val_loss: 3.5468 - val_accuracy: 0.0184\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.5521 - accuracy: 0.0073 - val_loss: 3.5421 - val_accuracy: 0.0207\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 3.5475 - accuracy: 0.0085 - val_loss: 3.5375 - val_accuracy: 0.0230\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.5430 - accuracy: 0.0098 - val_loss: 3.5331 - val_accuracy: 0.0230\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 3.5386 - accuracy: 0.0106 - val_loss: 3.5288 - val_accuracy: 0.0230\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.5344 - accuracy: 0.0122 - val_loss: 3.5246 - val_accuracy: 0.0230\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.5303 - accuracy: 0.0126 - val_loss: 3.5205 - val_accuracy: 0.0230\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.5262 - accuracy: 0.0130 - val_loss: 3.5165 - val_accuracy: 0.0230\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 3.5223 - accuracy: 0.0138 - val_loss: 3.5126 - val_accuracy: 0.0230\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.5185 - accuracy: 0.0154 - val_loss: 3.5088 - val_accuracy: 0.0230\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.5147 - accuracy: 0.0159 - val_loss: 3.5050 - val_accuracy: 0.0230\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 3.5110 - accuracy: 0.0167 - val_loss: 3.5013 - val_accuracy: 0.0230\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.5074 - accuracy: 0.0179 - val_loss: 3.4977 - val_accuracy: 0.0299\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.5038 - accuracy: 0.0183 - val_loss: 3.4942 - val_accuracy: 0.0299\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.5003 - accuracy: 0.0187 - val_loss: 3.4907 - val_accuracy: 0.0322\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.4969 - accuracy: 0.0195 - val_loss: 3.4873 - val_accuracy: 0.0322\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 3.4935 - accuracy: 0.0211 - val_loss: 3.4839 - val_accuracy: 0.0322\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 3.4902 - accuracy: 0.0228 - val_loss: 3.4806 - val_accuracy: 0.0322\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.4869 - accuracy: 0.0228 - val_loss: 3.4773 - val_accuracy: 0.0345\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.4837 - accuracy: 0.0232 - val_loss: 3.4741 - val_accuracy: 0.0368\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4805 - accuracy: 0.0240 - val_loss: 3.4709 - val_accuracy: 0.0437\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.4774 - accuracy: 0.0260 - val_loss: 3.4678 - val_accuracy: 0.0437\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4743 - accuracy: 0.0272 - val_loss: 3.4647 - val_accuracy: 0.0460\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4712 - accuracy: 0.0280 - val_loss: 3.4616 - val_accuracy: 0.0483\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 3.4682 - accuracy: 0.0305 - val_loss: 3.4586 - val_accuracy: 0.0483\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.4652 - accuracy: 0.0317 - val_loss: 3.4556 - val_accuracy: 0.0506\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.4622 - accuracy: 0.0325 - val_loss: 3.4526 - val_accuracy: 0.0529\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 3.4593 - accuracy: 0.0346 - val_loss: 3.4497 - val_accuracy: 0.0552\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4564 - accuracy: 0.0350 - val_loss: 3.4468 - val_accuracy: 0.0552\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 3.4535 - accuracy: 0.0354 - val_loss: 3.4440 - val_accuracy: 0.0552\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4507 - accuracy: 0.0358 - val_loss: 3.4411 - val_accuracy: 0.0552\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.4479 - accuracy: 0.0374 - val_loss: 3.4383 - val_accuracy: 0.0552\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 3.4451 - accuracy: 0.0402 - val_loss: 3.4355 - val_accuracy: 0.0552\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 3.4424 - accuracy: 0.0427 - val_loss: 3.4328 - val_accuracy: 0.0598\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.4396 - accuracy: 0.0431 - val_loss: 3.4301 - val_accuracy: 0.0621\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.4369 - accuracy: 0.0447 - val_loss: 3.4274 - val_accuracy: 0.0621\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 3.4343 - accuracy: 0.0476 - val_loss: 3.4247 - val_accuracy: 0.0690\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.4316 - accuracy: 0.0492 - val_loss: 3.4220 - val_accuracy: 0.0759\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4290 - accuracy: 0.0504 - val_loss: 3.4194 - val_accuracy: 0.0759\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 3.4264 - accuracy: 0.0528 - val_loss: 3.4168 - val_accuracy: 0.0805\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.4238 - accuracy: 0.0537 - val_loss: 3.4142 - val_accuracy: 0.0805\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.4212 - accuracy: 0.0569 - val_loss: 3.4116 - val_accuracy: 0.0828\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.4187 - accuracy: 0.0577 - val_loss: 3.4091 - val_accuracy: 0.0828\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.4161 - accuracy: 0.0593 - val_loss: 3.4065 - val_accuracy: 0.0828\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 3.4136 - accuracy: 0.0622 - val_loss: 3.4040 - val_accuracy: 0.0874\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4112 - accuracy: 0.0638 - val_loss: 3.4015 - val_accuracy: 0.0943\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.4087 - accuracy: 0.0659 - val_loss: 3.3990 - val_accuracy: 0.0943\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.4062 - accuracy: 0.0691 - val_loss: 3.3966 - val_accuracy: 0.0943\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.4038 - accuracy: 0.0703 - val_loss: 3.3941 - val_accuracy: 0.0989\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.4014 - accuracy: 0.0728 - val_loss: 3.3917 - val_accuracy: 0.0989\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.3990 - accuracy: 0.0756 - val_loss: 3.3893 - val_accuracy: 0.1034\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 3.3966 - accuracy: 0.0772 - val_loss: 3.3869 - val_accuracy: 0.1057\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.3942 - accuracy: 0.0817 - val_loss: 3.3845 - val_accuracy: 0.1080\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.3919 - accuracy: 0.0833 - val_loss: 3.3822 - val_accuracy: 0.1103\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.3895 - accuracy: 0.0846 - val_loss: 3.3798 - val_accuracy: 0.1103\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.3872 - accuracy: 0.0858 - val_loss: 3.3775 - val_accuracy: 0.1103\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.3849 - accuracy: 0.0878 - val_loss: 3.3752 - val_accuracy: 0.1103\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 3.3826 - accuracy: 0.0902 - val_loss: 3.3729 - val_accuracy: 0.1149\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.3803 - accuracy: 0.0919 - val_loss: 3.3706 - val_accuracy: 0.1195\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.3780 - accuracy: 0.0939 - val_loss: 3.3683 - val_accuracy: 0.1241\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 113us/sample - loss: 3.3758 - accuracy: 0.0951 - val_loss: 3.3660 - val_accuracy: 0.1264\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 3.3735 - accuracy: 0.0984 - val_loss: 3.3638 - val_accuracy: 0.1264\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 3.3713 - accuracy: 0.1000 - val_loss: 3.3615 - val_accuracy: 0.1264\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 3.3691 - accuracy: 0.1020 - val_loss: 3.3593 - val_accuracy: 0.1356\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 3.3669 - accuracy: 0.1049 - val_loss: 3.3571 - val_accuracy: 0.1402\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.3647 - accuracy: 0.1081 - val_loss: 3.3549 - val_accuracy: 0.1402\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.3625 - accuracy: 0.1089 - val_loss: 3.3527 - val_accuracy: 0.1471\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 3.3603 - accuracy: 0.1122 - val_loss: 3.3505 - val_accuracy: 0.1494\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.3582 - accuracy: 0.1159 - val_loss: 3.3483 - val_accuracy: 0.1517\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.3560 - accuracy: 0.1211 - val_loss: 3.3461 - val_accuracy: 0.1563\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 3.3539 - accuracy: 0.1244 - val_loss: 3.3440 - val_accuracy: 0.1609\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 3.3517 - accuracy: 0.1276 - val_loss: 3.3419 - val_accuracy: 0.1609\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.3496 - accuracy: 0.1301 - val_loss: 3.3397 - val_accuracy: 0.1609\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 3.3475 - accuracy: 0.1325 - val_loss: 3.3376 - val_accuracy: 0.1655\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.3454 - accuracy: 0.1341 - val_loss: 3.3355 - val_accuracy: 0.1678\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 115us/sample - loss: 3.3433 - accuracy: 0.1390 - val_loss: 3.3334 - val_accuracy: 0.1747\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 3.3413 - accuracy: 0.1415 - val_loss: 3.3313 - val_accuracy: 0.1770\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.3392 - accuracy: 0.1472 - val_loss: 3.3292 - val_accuracy: 0.1770\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 3.3371 - accuracy: 0.1508 - val_loss: 3.3272 - val_accuracy: 0.1816\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 3.3351 - accuracy: 0.1541 - val_loss: 3.3251 - val_accuracy: 0.1839\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 3.3330 - accuracy: 0.1557 - val_loss: 3.3230 - val_accuracy: 0.1862\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 3.3310 - accuracy: 0.1598 - val_loss: 3.3210 - val_accuracy: 0.1954\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.3290 - accuracy: 0.1638 - val_loss: 3.3190 - val_accuracy: 0.2000\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.3270 - accuracy: 0.1671 - val_loss: 3.3169 - val_accuracy: 0.2023\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.3249 - accuracy: 0.1720 - val_loss: 3.3149 - val_accuracy: 0.2046\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.3229 - accuracy: 0.1744 - val_loss: 3.3129 - val_accuracy: 0.2046\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 3.3210 - accuracy: 0.1768 - val_loss: 3.3109 - val_accuracy: 0.2092\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.3190 - accuracy: 0.1817 - val_loss: 3.3089 - val_accuracy: 0.2092\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.3170 - accuracy: 0.1850 - val_loss: 3.3069 - val_accuracy: 0.2115\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 3.3150 - accuracy: 0.1878 - val_loss: 3.3049 - val_accuracy: 0.2138\n",
      "2895/2895 [==============================] - 0s 31us/sample - loss: 3.3127 - accuracy: 0.1927\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 181us/sample - loss: 3.3364 - accuracy: 0.2171 - val_loss: 3.2603 - val_accuracy: 0.3034\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 3.2074 - accuracy: 0.3557 - val_loss: 3.1493 - val_accuracy: 0.3954\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.1074 - accuracy: 0.4187 - val_loss: 3.0561 - val_accuracy: 0.4322\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 3.0204 - accuracy: 0.4455 - val_loss: 2.9729 - val_accuracy: 0.4529\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 2.9415 - accuracy: 0.4663 - val_loss: 2.8963 - val_accuracy: 0.4575\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.8683 - accuracy: 0.4756 - val_loss: 2.8246 - val_accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 2.7993 - accuracy: 0.4793 - val_loss: 2.7567 - val_accuracy: 0.4644\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 2.7336 - accuracy: 0.4809 - val_loss: 2.6918 - val_accuracy: 0.4690\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 2.6707 - accuracy: 0.4829 - val_loss: 2.6296 - val_accuracy: 0.4667\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 2.6103 - accuracy: 0.4841 - val_loss: 2.5698 - val_accuracy: 0.4690\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 2.5521 - accuracy: 0.4817 - val_loss: 2.5120 - val_accuracy: 0.4713\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 2.4960 - accuracy: 0.4841 - val_loss: 2.4563 - val_accuracy: 0.4713\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 2.4417 - accuracy: 0.4841 - val_loss: 2.4024 - val_accuracy: 0.4690\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 2.3892 - accuracy: 0.4850 - val_loss: 2.3502 - val_accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.3384 - accuracy: 0.4850 - val_loss: 2.2998 - val_accuracy: 0.4621\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 2.2893 - accuracy: 0.4858 - val_loss: 2.2512 - val_accuracy: 0.4667\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 2.2418 - accuracy: 0.4846 - val_loss: 2.2041 - val_accuracy: 0.4667\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 2.1959 - accuracy: 0.4874 - val_loss: 2.1586 - val_accuracy: 0.4736\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 2.1515 - accuracy: 0.4886 - val_loss: 2.1147 - val_accuracy: 0.4897\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 2.1085 - accuracy: 0.4898 - val_loss: 2.0722 - val_accuracy: 0.4943\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 2.0670 - accuracy: 0.4931 - val_loss: 2.0312 - val_accuracy: 0.4874\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 2.0268 - accuracy: 0.4911 - val_loss: 1.9916 - val_accuracy: 0.4874\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 1.9880 - accuracy: 0.4955 - val_loss: 1.9533 - val_accuracy: 0.4966\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.9505 - accuracy: 0.5004 - val_loss: 1.9164 - val_accuracy: 0.4966\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.9143 - accuracy: 0.5041 - val_loss: 1.8807 - val_accuracy: 0.4966\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 1.8793 - accuracy: 0.5057 - val_loss: 1.8463 - val_accuracy: 0.4943\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.8455 - accuracy: 0.5081 - val_loss: 1.8131 - val_accuracy: 0.4920\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 1.8128 - accuracy: 0.5089 - val_loss: 1.7810 - val_accuracy: 0.5011\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 1.7812 - accuracy: 0.5142 - val_loss: 1.7501 - val_accuracy: 0.5103\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 1.7507 - accuracy: 0.5203 - val_loss: 1.7201 - val_accuracy: 0.5126\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 1.7211 - accuracy: 0.5280 - val_loss: 1.6912 - val_accuracy: 0.5080\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 1.6926 - accuracy: 0.5333 - val_loss: 1.6633 - val_accuracy: 0.5103\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 129us/sample - loss: 1.6650 - accuracy: 0.5333 - val_loss: 1.6364 - val_accuracy: 0.5195\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 1.6384 - accuracy: 0.5337 - val_loss: 1.6103 - val_accuracy: 0.5241\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 1.6126 - accuracy: 0.5362 - val_loss: 1.5852 - val_accuracy: 0.5195\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.5877 - accuracy: 0.5423 - val_loss: 1.5609 - val_accuracy: 0.5310\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 1.5636 - accuracy: 0.5492 - val_loss: 1.5374 - val_accuracy: 0.5356\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.5402 - accuracy: 0.5533 - val_loss: 1.5147 - val_accuracy: 0.5402\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.5177 - accuracy: 0.5602 - val_loss: 1.4928 - val_accuracy: 0.5494\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 1.4958 - accuracy: 0.5638 - val_loss: 1.4716 - val_accuracy: 0.5494\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.4747 - accuracy: 0.5646 - val_loss: 1.4511 - val_accuracy: 0.5517\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 1.4543 - accuracy: 0.5654 - val_loss: 1.4312 - val_accuracy: 0.5609\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 1.4345 - accuracy: 0.5683 - val_loss: 1.4120 - val_accuracy: 0.5586\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.4153 - accuracy: 0.5695 - val_loss: 1.3934 - val_accuracy: 0.5655\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 1.3967 - accuracy: 0.5715 - val_loss: 1.3754 - val_accuracy: 0.5678\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 1.3788 - accuracy: 0.5703 - val_loss: 1.3580 - val_accuracy: 0.5724\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.3613 - accuracy: 0.5728 - val_loss: 1.3412 - val_accuracy: 0.5724\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 1.3445 - accuracy: 0.5720 - val_loss: 1.3248 - val_accuracy: 0.5701\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 1.3281 - accuracy: 0.5699 - val_loss: 1.3090 - val_accuracy: 0.5632\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 1.3123 - accuracy: 0.5720 - val_loss: 1.2937 - val_accuracy: 0.5655\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.2969 - accuracy: 0.5736 - val_loss: 1.2789 - val_accuracy: 0.5609\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.2820 - accuracy: 0.5752 - val_loss: 1.2645 - val_accuracy: 0.5609\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 1.2676 - accuracy: 0.5752 - val_loss: 1.2506 - val_accuracy: 0.5678\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 1.2535 - accuracy: 0.5776 - val_loss: 1.2371 - val_accuracy: 0.5724\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 1.2399 - accuracy: 0.5801 - val_loss: 1.2240 - val_accuracy: 0.5724\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 1.2267 - accuracy: 0.5825 - val_loss: 1.2113 - val_accuracy: 0.5747\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 1.2139 - accuracy: 0.5846 - val_loss: 1.1990 - val_accuracy: 0.5724\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 1.2015 - accuracy: 0.5841 - val_loss: 1.1870 - val_accuracy: 0.5701\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 1.1894 - accuracy: 0.5850 - val_loss: 1.1754 - val_accuracy: 0.5701\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.1777 - accuracy: 0.5846 - val_loss: 1.1642 - val_accuracy: 0.5747\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.1664 - accuracy: 0.5866 - val_loss: 1.1533 - val_accuracy: 0.5724\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 122us/sample - loss: 1.1553 - accuracy: 0.5894 - val_loss: 1.1427 - val_accuracy: 0.5747\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 1.1446 - accuracy: 0.5898 - val_loss: 1.1324 - val_accuracy: 0.5724\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 1.1341 - accuracy: 0.5882 - val_loss: 1.1224 - val_accuracy: 0.5770\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 1.1240 - accuracy: 0.5882 - val_loss: 1.1127 - val_accuracy: 0.5770\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 1.1142 - accuracy: 0.5923 - val_loss: 1.1033 - val_accuracy: 0.5770\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 1.1046 - accuracy: 0.5935 - val_loss: 1.0941 - val_accuracy: 0.5770\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 131us/sample - loss: 1.0953 - accuracy: 0.5943 - val_loss: 1.0852 - val_accuracy: 0.5839\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.0862 - accuracy: 0.5967 - val_loss: 1.0765 - val_accuracy: 0.5839\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 1.0774 - accuracy: 0.5976 - val_loss: 1.0681 - val_accuracy: 0.5885\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 1.0688 - accuracy: 0.5976 - val_loss: 1.0599 - val_accuracy: 0.5885\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.0605 - accuracy: 0.5996 - val_loss: 1.0520 - val_accuracy: 0.5931\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 1.0524 - accuracy: 0.6012 - val_loss: 1.0442 - val_accuracy: 0.5954\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.0445 - accuracy: 0.6024 - val_loss: 1.0367 - val_accuracy: 0.5954\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 1.0368 - accuracy: 0.6037 - val_loss: 1.0293 - val_accuracy: 0.5954\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 1.0294 - accuracy: 0.6041 - val_loss: 1.0222 - val_accuracy: 0.5931\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 1.0221 - accuracy: 0.6037 - val_loss: 1.0153 - val_accuracy: 0.5931\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 1.0150 - accuracy: 0.6045 - val_loss: 1.0085 - val_accuracy: 0.5954\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 1.0081 - accuracy: 0.6045 - val_loss: 1.0019 - val_accuracy: 0.5977\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.0014 - accuracy: 0.6061 - val_loss: 0.9955 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.9948 - accuracy: 0.6061 - val_loss: 0.9892 - val_accuracy: 0.6023\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 114us/sample - loss: 0.9884 - accuracy: 0.6057 - val_loss: 0.9831 - val_accuracy: 0.6023\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.9822 - accuracy: 0.6069 - val_loss: 0.9772 - val_accuracy: 0.6023\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 0.9761 - accuracy: 0.6077 - val_loss: 0.9714 - val_accuracy: 0.6023\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.9702 - accuracy: 0.6077 - val_loss: 0.9658 - val_accuracy: 0.6023\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.9644 - accuracy: 0.6077 - val_loss: 0.9602 - val_accuracy: 0.6023\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.9588 - accuracy: 0.6073 - val_loss: 0.9549 - val_accuracy: 0.6023\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.9533 - accuracy: 0.6085 - val_loss: 0.9496 - val_accuracy: 0.6023\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 131us/sample - loss: 0.9480 - accuracy: 0.6102 - val_loss: 0.9445 - val_accuracy: 0.6046\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.9427 - accuracy: 0.6102 - val_loss: 0.9396 - val_accuracy: 0.6092\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.9376 - accuracy: 0.6106 - val_loss: 0.9347 - val_accuracy: 0.6092\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.9327 - accuracy: 0.6110 - val_loss: 0.9299 - val_accuracy: 0.6161\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.9278 - accuracy: 0.6122 - val_loss: 0.9253 - val_accuracy: 0.6161\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.9230 - accuracy: 0.6126 - val_loss: 0.9208 - val_accuracy: 0.6161\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 120us/sample - loss: 0.9184 - accuracy: 0.6114 - val_loss: 0.9164 - val_accuracy: 0.6161\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.9139 - accuracy: 0.6122 - val_loss: 0.9121 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.9094 - accuracy: 0.6126 - val_loss: 0.9078 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.9051 - accuracy: 0.6134 - val_loss: 0.9037 - val_accuracy: 0.6184\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.9009 - accuracy: 0.6118 - val_loss: 0.8997 - val_accuracy: 0.6207\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 120us/sample - loss: 0.8968 - accuracy: 0.6146 - val_loss: 0.8958 - val_accuracy: 0.6230\n",
      "2895/2895 [==============================] - 0s 46us/sample - loss: 0.8948 - accuracy: 0.6155\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 153us/sample - loss: 2.8498 - accuracy: 0.3919 - val_loss: 2.0995 - val_accuracy: 0.5149\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 1.6422 - accuracy: 0.5549 - val_loss: 1.2778 - val_accuracy: 0.5379\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 1.1052 - accuracy: 0.5679 - val_loss: 0.9694 - val_accuracy: 0.5655\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.8932 - accuracy: 0.5915 - val_loss: 0.8420 - val_accuracy: 0.5747\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.7969 - accuracy: 0.6134 - val_loss: 0.7788 - val_accuracy: 0.5885\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.7447 - accuracy: 0.6276 - val_loss: 0.7429 - val_accuracy: 0.6046\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.7128 - accuracy: 0.6467 - val_loss: 0.7190 - val_accuracy: 0.6161\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6906 - accuracy: 0.6512 - val_loss: 0.7025 - val_accuracy: 0.6207\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.6736 - accuracy: 0.6569 - val_loss: 0.6901 - val_accuracy: 0.6437\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6610 - accuracy: 0.6557 - val_loss: 0.6796 - val_accuracy: 0.6276\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6510 - accuracy: 0.6687 - val_loss: 0.6721 - val_accuracy: 0.6391\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6428 - accuracy: 0.6691 - val_loss: 0.6650 - val_accuracy: 0.6345\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.6354 - accuracy: 0.6728 - val_loss: 0.6595 - val_accuracy: 0.6276\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.6289 - accuracy: 0.6732 - val_loss: 0.6546 - val_accuracy: 0.6391\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.6231 - accuracy: 0.6768 - val_loss: 0.6513 - val_accuracy: 0.6460\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6189 - accuracy: 0.6748 - val_loss: 0.6472 - val_accuracy: 0.6460\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6144 - accuracy: 0.6821 - val_loss: 0.6438 - val_accuracy: 0.6437\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.6109 - accuracy: 0.6829 - val_loss: 0.6406 - val_accuracy: 0.6529\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6077 - accuracy: 0.6813 - val_loss: 0.6381 - val_accuracy: 0.6529\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6045 - accuracy: 0.6862 - val_loss: 0.6359 - val_accuracy: 0.6506\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.6017 - accuracy: 0.6837 - val_loss: 0.6338 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5993 - accuracy: 0.6915 - val_loss: 0.6325 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5968 - accuracy: 0.6894 - val_loss: 0.6305 - val_accuracy: 0.6690\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5947 - accuracy: 0.6923 - val_loss: 0.6288 - val_accuracy: 0.6690\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.5926 - accuracy: 0.6894 - val_loss: 0.6274 - val_accuracy: 0.6621\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5910 - accuracy: 0.6902 - val_loss: 0.6263 - val_accuracy: 0.6690\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5895 - accuracy: 0.6919 - val_loss: 0.6249 - val_accuracy: 0.6621\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5880 - accuracy: 0.6963 - val_loss: 0.6240 - val_accuracy: 0.6644\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5866 - accuracy: 0.6943 - val_loss: 0.6235 - val_accuracy: 0.6644\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.5855 - accuracy: 0.6943 - val_loss: 0.6226 - val_accuracy: 0.6621\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5843 - accuracy: 0.6976 - val_loss: 0.6219 - val_accuracy: 0.6621\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5831 - accuracy: 0.6967 - val_loss: 0.6211 - val_accuracy: 0.6575\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5819 - accuracy: 0.6951 - val_loss: 0.6204 - val_accuracy: 0.6621\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5809 - accuracy: 0.6959 - val_loss: 0.6199 - val_accuracy: 0.6552\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5801 - accuracy: 0.6976 - val_loss: 0.6196 - val_accuracy: 0.6506\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5791 - accuracy: 0.6984 - val_loss: 0.6190 - val_accuracy: 0.6529\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5785 - accuracy: 0.6996 - val_loss: 0.6191 - val_accuracy: 0.6598\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5779 - accuracy: 0.6963 - val_loss: 0.6183 - val_accuracy: 0.6552\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5770 - accuracy: 0.6984 - val_loss: 0.6182 - val_accuracy: 0.6575\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5764 - accuracy: 0.7024 - val_loss: 0.6178 - val_accuracy: 0.6552\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5759 - accuracy: 0.6976 - val_loss: 0.6174 - val_accuracy: 0.6552\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5749 - accuracy: 0.6976 - val_loss: 0.6171 - val_accuracy: 0.6483\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5747 - accuracy: 0.7004 - val_loss: 0.6171 - val_accuracy: 0.6598\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5740 - accuracy: 0.6992 - val_loss: 0.6168 - val_accuracy: 0.6575\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5734 - accuracy: 0.6988 - val_loss: 0.6167 - val_accuracy: 0.6552\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 138us/sample - loss: 0.5728 - accuracy: 0.7000 - val_loss: 0.6169 - val_accuracy: 0.6575\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5723 - accuracy: 0.6992 - val_loss: 0.6164 - val_accuracy: 0.6529\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5718 - accuracy: 0.6992 - val_loss: 0.6163 - val_accuracy: 0.6552\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.5709 - accuracy: 0.7041 - val_loss: 0.6165 - val_accuracy: 0.6644\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5710 - accuracy: 0.6976 - val_loss: 0.6162 - val_accuracy: 0.6529\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5703 - accuracy: 0.7061 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5701 - accuracy: 0.7020 - val_loss: 0.6158 - val_accuracy: 0.6506\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5697 - accuracy: 0.7020 - val_loss: 0.6159 - val_accuracy: 0.6552\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 129us/sample - loss: 0.5690 - accuracy: 0.7053 - val_loss: 0.6159 - val_accuracy: 0.6575\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5687 - accuracy: 0.7008 - val_loss: 0.6160 - val_accuracy: 0.6552\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5684 - accuracy: 0.7016 - val_loss: 0.6160 - val_accuracy: 0.6552\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.5683 - accuracy: 0.7065 - val_loss: 0.6157 - val_accuracy: 0.6529\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5677 - accuracy: 0.7093 - val_loss: 0.6154 - val_accuracy: 0.6460\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5674 - accuracy: 0.7041 - val_loss: 0.6156 - val_accuracy: 0.6460\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.5667 - accuracy: 0.7069 - val_loss: 0.6152 - val_accuracy: 0.6483\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5667 - accuracy: 0.7049 - val_loss: 0.6152 - val_accuracy: 0.6529\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5664 - accuracy: 0.7085 - val_loss: 0.6157 - val_accuracy: 0.6575\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5660 - accuracy: 0.7049 - val_loss: 0.6153 - val_accuracy: 0.6529\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5658 - accuracy: 0.7114 - val_loss: 0.6157 - val_accuracy: 0.6575\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5653 - accuracy: 0.7102 - val_loss: 0.6157 - val_accuracy: 0.6644\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5651 - accuracy: 0.7089 - val_loss: 0.6155 - val_accuracy: 0.6621\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5647 - accuracy: 0.7077 - val_loss: 0.6157 - val_accuracy: 0.6552\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5643 - accuracy: 0.7085 - val_loss: 0.6154 - val_accuracy: 0.6552\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5641 - accuracy: 0.7126 - val_loss: 0.6159 - val_accuracy: 0.6690\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5638 - accuracy: 0.7069 - val_loss: 0.6152 - val_accuracy: 0.6552\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.5638 - accuracy: 0.7122 - val_loss: 0.6155 - val_accuracy: 0.6644\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5634 - accuracy: 0.7118 - val_loss: 0.6156 - val_accuracy: 0.6713\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5632 - accuracy: 0.7098 - val_loss: 0.6154 - val_accuracy: 0.6575\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5629 - accuracy: 0.7089 - val_loss: 0.6156 - val_accuracy: 0.6621\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 126us/sample - loss: 0.5627 - accuracy: 0.7126 - val_loss: 0.6159 - val_accuracy: 0.6690\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5622 - accuracy: 0.7093 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 0.5620 - accuracy: 0.7093 - val_loss: 0.6154 - val_accuracy: 0.6598\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5618 - accuracy: 0.7085 - val_loss: 0.6155 - val_accuracy: 0.6690\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5616 - accuracy: 0.7130 - val_loss: 0.6156 - val_accuracy: 0.6644\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5613 - accuracy: 0.7130 - val_loss: 0.6154 - val_accuracy: 0.6598\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5611 - accuracy: 0.7098 - val_loss: 0.6154 - val_accuracy: 0.6644\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5608 - accuracy: 0.7154 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5605 - accuracy: 0.7102 - val_loss: 0.6155 - val_accuracy: 0.6644\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5603 - accuracy: 0.7146 - val_loss: 0.6159 - val_accuracy: 0.6690\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5602 - accuracy: 0.7130 - val_loss: 0.6156 - val_accuracy: 0.6644\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5599 - accuracy: 0.7118 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5596 - accuracy: 0.7130 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5595 - accuracy: 0.7138 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5592 - accuracy: 0.7122 - val_loss: 0.6155 - val_accuracy: 0.6644\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5590 - accuracy: 0.7146 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5589 - accuracy: 0.7154 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5585 - accuracy: 0.7167 - val_loss: 0.6165 - val_accuracy: 0.6713\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5582 - accuracy: 0.7142 - val_loss: 0.6167 - val_accuracy: 0.6690\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5582 - accuracy: 0.7106 - val_loss: 0.6159 - val_accuracy: 0.6644\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5581 - accuracy: 0.7146 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5577 - accuracy: 0.7134 - val_loss: 0.6161 - val_accuracy: 0.6690\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5575 - accuracy: 0.7154 - val_loss: 0.6164 - val_accuracy: 0.6690\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5574 - accuracy: 0.7134 - val_loss: 0.6159 - val_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5571 - accuracy: 0.7142 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5569 - accuracy: 0.7146 - val_loss: 0.6159 - val_accuracy: 0.6644\n",
      "2895/2895 [==============================] - 0s 74us/sample - loss: 0.5647 - accuracy: 0.7095\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 120us/sample - loss: 0.9117 - accuracy: 0.5813 - val_loss: 0.6431 - val_accuracy: 0.6391\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.6240 - accuracy: 0.6500 - val_loss: 0.6223 - val_accuracy: 0.6483\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6089 - accuracy: 0.6732 - val_loss: 0.6189 - val_accuracy: 0.6736\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5940 - accuracy: 0.6841 - val_loss: 0.6144 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5814 - accuracy: 0.6984 - val_loss: 0.6556 - val_accuracy: 0.6621\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 124us/sample - loss: 0.5853 - accuracy: 0.6923 - val_loss: 0.6080 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5813 - accuracy: 0.6951 - val_loss: 0.6050 - val_accuracy: 0.6598\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 134us/sample - loss: 0.5789 - accuracy: 0.6935 - val_loss: 0.6094 - val_accuracy: 0.6759\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5731 - accuracy: 0.7053 - val_loss: 0.6078 - val_accuracy: 0.6644\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5720 - accuracy: 0.7028 - val_loss: 0.6088 - val_accuracy: 0.6690\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.5653 - accuracy: 0.7045 - val_loss: 0.6148 - val_accuracy: 0.6690\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5646 - accuracy: 0.7093 - val_loss: 0.6128 - val_accuracy: 0.6851\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5604 - accuracy: 0.7118 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5605 - accuracy: 0.7122 - val_loss: 0.6121 - val_accuracy: 0.6644\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5585 - accuracy: 0.7093 - val_loss: 0.6222 - val_accuracy: 0.6575\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 120us/sample - loss: 0.5509 - accuracy: 0.7179 - val_loss: 0.6175 - val_accuracy: 0.6621\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5528 - accuracy: 0.7110 - val_loss: 0.6157 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5451 - accuracy: 0.7240 - val_loss: 0.6279 - val_accuracy: 0.6598\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5460 - accuracy: 0.7207 - val_loss: 0.6188 - val_accuracy: 0.6690\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5389 - accuracy: 0.7150 - val_loss: 0.6249 - val_accuracy: 0.6828\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5431 - accuracy: 0.7224 - val_loss: 0.6197 - val_accuracy: 0.6598\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5375 - accuracy: 0.7280 - val_loss: 0.6205 - val_accuracy: 0.6782\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5348 - accuracy: 0.7289 - val_loss: 0.6216 - val_accuracy: 0.6552\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5301 - accuracy: 0.7350 - val_loss: 0.6195 - val_accuracy: 0.6644\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5260 - accuracy: 0.7370 - val_loss: 0.6259 - val_accuracy: 0.6851\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.5229 - accuracy: 0.7358 - val_loss: 0.6242 - val_accuracy: 0.6943\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5186 - accuracy: 0.7431 - val_loss: 0.6262 - val_accuracy: 0.6874\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.5158 - accuracy: 0.7439 - val_loss: 0.6296 - val_accuracy: 0.6690\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5132 - accuracy: 0.7451 - val_loss: 0.6244 - val_accuracy: 0.6805\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5084 - accuracy: 0.7419 - val_loss: 0.6324 - val_accuracy: 0.6897\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.5078 - accuracy: 0.7443 - val_loss: 0.6269 - val_accuracy: 0.6759\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5044 - accuracy: 0.7496 - val_loss: 0.6310 - val_accuracy: 0.6759\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 124us/sample - loss: 0.4991 - accuracy: 0.7496 - val_loss: 0.6307 - val_accuracy: 0.6713\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4954 - accuracy: 0.7557 - val_loss: 0.6381 - val_accuracy: 0.6644\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4925 - accuracy: 0.7646 - val_loss: 0.6553 - val_accuracy: 0.6345\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4901 - accuracy: 0.7569 - val_loss: 0.6566 - val_accuracy: 0.6299\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4864 - accuracy: 0.7585 - val_loss: 0.6361 - val_accuracy: 0.6874\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4818 - accuracy: 0.7622 - val_loss: 0.6397 - val_accuracy: 0.6897\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.4816 - accuracy: 0.7642 - val_loss: 0.6597 - val_accuracy: 0.6299\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4735 - accuracy: 0.7728 - val_loss: 0.6493 - val_accuracy: 0.6690\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.4707 - accuracy: 0.7772 - val_loss: 0.6425 - val_accuracy: 0.6713\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4673 - accuracy: 0.7724 - val_loss: 0.6524 - val_accuracy: 0.6736\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4628 - accuracy: 0.7817 - val_loss: 0.6461 - val_accuracy: 0.6782\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4589 - accuracy: 0.7821 - val_loss: 0.6777 - val_accuracy: 0.6253\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4557 - accuracy: 0.7789 - val_loss: 0.6576 - val_accuracy: 0.6713\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4515 - accuracy: 0.7886 - val_loss: 0.6637 - val_accuracy: 0.6552\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4484 - accuracy: 0.7894 - val_loss: 0.6617 - val_accuracy: 0.6575\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4441 - accuracy: 0.7943 - val_loss: 0.6610 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4395 - accuracy: 0.7955 - val_loss: 0.6595 - val_accuracy: 0.6690\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4355 - accuracy: 0.7980 - val_loss: 0.6683 - val_accuracy: 0.6690\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4351 - accuracy: 0.8053 - val_loss: 0.6684 - val_accuracy: 0.6713\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4319 - accuracy: 0.8020 - val_loss: 0.6716 - val_accuracy: 0.6713\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4239 - accuracy: 0.8089 - val_loss: 0.6722 - val_accuracy: 0.6736\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4224 - accuracy: 0.8069 - val_loss: 0.6776 - val_accuracy: 0.6805\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4209 - accuracy: 0.8106 - val_loss: 0.6912 - val_accuracy: 0.6598\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4172 - accuracy: 0.8081 - val_loss: 0.6864 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4136 - accuracy: 0.8146 - val_loss: 0.6959 - val_accuracy: 0.6506\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4079 - accuracy: 0.8163 - val_loss: 0.7046 - val_accuracy: 0.6506\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4082 - accuracy: 0.8167 - val_loss: 0.6909 - val_accuracy: 0.6690\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4054 - accuracy: 0.8126 - val_loss: 0.6935 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.3988 - accuracy: 0.8240 - val_loss: 0.7032 - val_accuracy: 0.6529\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3976 - accuracy: 0.8260 - val_loss: 0.6990 - val_accuracy: 0.6644\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.3935 - accuracy: 0.8268 - val_loss: 0.7064 - val_accuracy: 0.6598\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.3900 - accuracy: 0.8362 - val_loss: 0.7080 - val_accuracy: 0.6575\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3919 - accuracy: 0.8248 - val_loss: 0.7101 - val_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.3879 - accuracy: 0.8248 - val_loss: 0.7172 - val_accuracy: 0.6598\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3819 - accuracy: 0.8313 - val_loss: 0.7374 - val_accuracy: 0.6437\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3789 - accuracy: 0.8317 - val_loss: 0.7215 - val_accuracy: 0.6483\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3749 - accuracy: 0.8386 - val_loss: 0.7463 - val_accuracy: 0.6345\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3748 - accuracy: 0.8402 - val_loss: 0.7424 - val_accuracy: 0.6529\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3705 - accuracy: 0.8386 - val_loss: 0.7427 - val_accuracy: 0.6529\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3687 - accuracy: 0.8443 - val_loss: 0.7292 - val_accuracy: 0.6598\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.3688 - accuracy: 0.8411 - val_loss: 0.7377 - val_accuracy: 0.6391\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3626 - accuracy: 0.8411 - val_loss: 0.7602 - val_accuracy: 0.6299\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3567 - accuracy: 0.8472 - val_loss: 0.7499 - val_accuracy: 0.6414\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3577 - accuracy: 0.8439 - val_loss: 0.7656 - val_accuracy: 0.6460\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3568 - accuracy: 0.8472 - val_loss: 0.7512 - val_accuracy: 0.6575\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3533 - accuracy: 0.8545 - val_loss: 0.7653 - val_accuracy: 0.6391\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.3512 - accuracy: 0.8492 - val_loss: 0.7591 - val_accuracy: 0.6575\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3480 - accuracy: 0.8533 - val_loss: 0.7667 - val_accuracy: 0.6483\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3464 - accuracy: 0.8557 - val_loss: 0.7640 - val_accuracy: 0.6460\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.3458 - accuracy: 0.8516 - val_loss: 0.7688 - val_accuracy: 0.6483\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3415 - accuracy: 0.8573 - val_loss: 0.7684 - val_accuracy: 0.6506\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.3396 - accuracy: 0.8606 - val_loss: 0.7820 - val_accuracy: 0.6368\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3376 - accuracy: 0.8593 - val_loss: 0.7797 - val_accuracy: 0.6437\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3357 - accuracy: 0.8602 - val_loss: 0.7815 - val_accuracy: 0.6460\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3338 - accuracy: 0.8573 - val_loss: 0.7902 - val_accuracy: 0.6437\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3325 - accuracy: 0.8585 - val_loss: 0.7954 - val_accuracy: 0.6414\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3295 - accuracy: 0.8610 - val_loss: 0.8081 - val_accuracy: 0.6368\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.3290 - accuracy: 0.8593 - val_loss: 0.7946 - val_accuracy: 0.6437\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3256 - accuracy: 0.8646 - val_loss: 0.8090 - val_accuracy: 0.6322\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3241 - accuracy: 0.8687 - val_loss: 0.8106 - val_accuracy: 0.6575\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.3230 - accuracy: 0.8683 - val_loss: 0.8057 - val_accuracy: 0.6345\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3216 - accuracy: 0.8646 - val_loss: 0.8054 - val_accuracy: 0.6414\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 133us/sample - loss: 0.3154 - accuracy: 0.8707 - val_loss: 0.8170 - val_accuracy: 0.6414\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3148 - accuracy: 0.8744 - val_loss: 0.8367 - val_accuracy: 0.6230\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3121 - accuracy: 0.8740 - val_loss: 0.8263 - val_accuracy: 0.6345\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.3119 - accuracy: 0.8776 - val_loss: 0.8161 - val_accuracy: 0.6414\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3101 - accuracy: 0.8707 - val_loss: 0.8202 - val_accuracy: 0.6345\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3091 - accuracy: 0.8748 - val_loss: 0.8222 - val_accuracy: 0.6437\n",
      "2895/2895 [==============================] - 0s 72us/sample - loss: 0.3672 - accuracy: 0.8549\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 124us/sample - loss: 1.0300 - accuracy: 0.5687 - val_loss: 0.7550 - val_accuracy: 0.5954\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.6383 - accuracy: 0.6569 - val_loss: 0.6268 - val_accuracy: 0.6460\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.6177 - accuracy: 0.6626 - val_loss: 0.6113 - val_accuracy: 0.6644\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6065 - accuracy: 0.6772 - val_loss: 0.6195 - val_accuracy: 0.6483\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.6066 - accuracy: 0.6760 - val_loss: 0.6136 - val_accuracy: 0.6598\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5938 - accuracy: 0.6801 - val_loss: 0.6152 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5902 - accuracy: 0.6890 - val_loss: 0.6186 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5857 - accuracy: 0.6874 - val_loss: 0.6222 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5903 - accuracy: 0.6858 - val_loss: 0.6436 - val_accuracy: 0.6598\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5796 - accuracy: 0.6902 - val_loss: 0.6242 - val_accuracy: 0.6621\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5782 - accuracy: 0.6874 - val_loss: 0.6405 - val_accuracy: 0.6552\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5696 - accuracy: 0.6972 - val_loss: 0.6456 - val_accuracy: 0.6575\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5735 - accuracy: 0.7037 - val_loss: 0.6822 - val_accuracy: 0.6644\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5611 - accuracy: 0.7106 - val_loss: 0.6420 - val_accuracy: 0.6460\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5576 - accuracy: 0.7020 - val_loss: 0.6380 - val_accuracy: 0.6690\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5584 - accuracy: 0.7028 - val_loss: 0.6563 - val_accuracy: 0.6736\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5488 - accuracy: 0.7106 - val_loss: 0.6633 - val_accuracy: 0.6529\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5498 - accuracy: 0.7089 - val_loss: 0.6616 - val_accuracy: 0.6621\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5384 - accuracy: 0.7187 - val_loss: 0.6817 - val_accuracy: 0.6460\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5350 - accuracy: 0.7252 - val_loss: 0.6669 - val_accuracy: 0.6506\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5257 - accuracy: 0.7268 - val_loss: 0.6960 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5185 - accuracy: 0.7199 - val_loss: 0.7134 - val_accuracy: 0.6552\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5213 - accuracy: 0.7337 - val_loss: 0.7096 - val_accuracy: 0.6368\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5082 - accuracy: 0.7402 - val_loss: 0.7811 - val_accuracy: 0.6276\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5020 - accuracy: 0.7390 - val_loss: 0.7399 - val_accuracy: 0.6276\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5028 - accuracy: 0.7386 - val_loss: 0.7349 - val_accuracy: 0.6460\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.4943 - accuracy: 0.7541 - val_loss: 0.7472 - val_accuracy: 0.6391\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4946 - accuracy: 0.7500 - val_loss: 0.7422 - val_accuracy: 0.6391\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.4848 - accuracy: 0.7484 - val_loss: 0.7918 - val_accuracy: 0.6299\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4766 - accuracy: 0.7618 - val_loss: 0.8316 - val_accuracy: 0.6023\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4714 - accuracy: 0.7545 - val_loss: 0.7852 - val_accuracy: 0.6391\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4676 - accuracy: 0.7659 - val_loss: 0.8210 - val_accuracy: 0.6460\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4626 - accuracy: 0.7752 - val_loss: 0.8161 - val_accuracy: 0.6253\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4533 - accuracy: 0.7793 - val_loss: 0.8061 - val_accuracy: 0.6276\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4597 - accuracy: 0.7675 - val_loss: 0.8395 - val_accuracy: 0.6161\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4570 - accuracy: 0.7740 - val_loss: 0.8563 - val_accuracy: 0.6161\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4404 - accuracy: 0.7793 - val_loss: 0.8557 - val_accuracy: 0.6207\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4371 - accuracy: 0.7854 - val_loss: 0.8637 - val_accuracy: 0.6276\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4334 - accuracy: 0.7789 - val_loss: 0.8969 - val_accuracy: 0.6345\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.4352 - accuracy: 0.7862 - val_loss: 0.9014 - val_accuracy: 0.6138\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4238 - accuracy: 0.7919 - val_loss: 0.8913 - val_accuracy: 0.6161\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4234 - accuracy: 0.7927 - val_loss: 0.9076 - val_accuracy: 0.6575\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.4170 - accuracy: 0.7919 - val_loss: 0.9496 - val_accuracy: 0.6345\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.4134 - accuracy: 0.8045 - val_loss: 0.9848 - val_accuracy: 0.6253\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4033 - accuracy: 0.8000 - val_loss: 0.9820 - val_accuracy: 0.6253\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.4034 - accuracy: 0.8065 - val_loss: 1.0085 - val_accuracy: 0.6345\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3949 - accuracy: 0.8085 - val_loss: 0.9489 - val_accuracy: 0.6322\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 121us/sample - loss: 0.3943 - accuracy: 0.8069 - val_loss: 1.0173 - val_accuracy: 0.6230\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3862 - accuracy: 0.8061 - val_loss: 1.0418 - val_accuracy: 0.6322\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3873 - accuracy: 0.8171 - val_loss: 1.0719 - val_accuracy: 0.5908\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3804 - accuracy: 0.8118 - val_loss: 1.0511 - val_accuracy: 0.6161\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3795 - accuracy: 0.8232 - val_loss: 1.0560 - val_accuracy: 0.6299\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3619 - accuracy: 0.8215 - val_loss: 1.0950 - val_accuracy: 0.6253\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3675 - accuracy: 0.8220 - val_loss: 1.1153 - val_accuracy: 0.6184\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3611 - accuracy: 0.8232 - val_loss: 1.0537 - val_accuracy: 0.6138\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.3636 - accuracy: 0.8272 - val_loss: 1.1593 - val_accuracy: 0.6276\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 0.3527 - accuracy: 0.8305 - val_loss: 1.1574 - val_accuracy: 0.6138\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3477 - accuracy: 0.8366 - val_loss: 1.2035 - val_accuracy: 0.6345\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 119us/sample - loss: 0.3438 - accuracy: 0.8435 - val_loss: 1.2175 - val_accuracy: 0.6207\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3435 - accuracy: 0.8370 - val_loss: 1.2378 - val_accuracy: 0.6207\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3376 - accuracy: 0.8431 - val_loss: 1.2623 - val_accuracy: 0.6092\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3345 - accuracy: 0.8447 - val_loss: 1.2782 - val_accuracy: 0.6483\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.3309 - accuracy: 0.8382 - val_loss: 1.2583 - val_accuracy: 0.6299\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3278 - accuracy: 0.8463 - val_loss: 1.2951 - val_accuracy: 0.6207\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.3265 - accuracy: 0.8496 - val_loss: 1.2948 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.3204 - accuracy: 0.8549 - val_loss: 1.3170 - val_accuracy: 0.6161\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3242 - accuracy: 0.8447 - val_loss: 1.3221 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3205 - accuracy: 0.8476 - val_loss: 1.3410 - val_accuracy: 0.6207\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.3057 - accuracy: 0.8569 - val_loss: 1.4354 - val_accuracy: 0.6230\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3127 - accuracy: 0.8528 - val_loss: 1.4195 - val_accuracy: 0.5908\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3078 - accuracy: 0.8598 - val_loss: 1.3982 - val_accuracy: 0.6023\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3009 - accuracy: 0.8602 - val_loss: 1.4265 - val_accuracy: 0.6046\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3076 - accuracy: 0.8569 - val_loss: 1.4468 - val_accuracy: 0.6138\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3013 - accuracy: 0.8573 - val_loss: 1.4637 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.2991 - accuracy: 0.8630 - val_loss: 1.4362 - val_accuracy: 0.6115\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.2991 - accuracy: 0.8667 - val_loss: 1.4749 - val_accuracy: 0.6207\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.2903 - accuracy: 0.8630 - val_loss: 1.4956 - val_accuracy: 0.6276\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.2895 - accuracy: 0.8711 - val_loss: 1.5035 - val_accuracy: 0.5977\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.2806 - accuracy: 0.8768 - val_loss: 1.5374 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.2766 - accuracy: 0.8768 - val_loss: 1.5619 - val_accuracy: 0.6161\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.2777 - accuracy: 0.8752 - val_loss: 1.5912 - val_accuracy: 0.6207\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.2836 - accuracy: 0.8760 - val_loss: 1.6345 - val_accuracy: 0.6138\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.2739 - accuracy: 0.8805 - val_loss: 1.6250 - val_accuracy: 0.6207\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2778 - accuracy: 0.8776 - val_loss: 1.5925 - val_accuracy: 0.5977\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2737 - accuracy: 0.8760 - val_loss: 1.7067 - val_accuracy: 0.5954\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.2659 - accuracy: 0.8801 - val_loss: 1.6774 - val_accuracy: 0.6207\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.2676 - accuracy: 0.8780 - val_loss: 1.7312 - val_accuracy: 0.6069\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.2575 - accuracy: 0.8841 - val_loss: 1.7284 - val_accuracy: 0.5908\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2631 - accuracy: 0.8809 - val_loss: 1.7681 - val_accuracy: 0.6207\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.2586 - accuracy: 0.8850 - val_loss: 1.8431 - val_accuracy: 0.6161\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.2569 - accuracy: 0.8829 - val_loss: 1.7844 - val_accuracy: 0.6115\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.2568 - accuracy: 0.8862 - val_loss: 1.8188 - val_accuracy: 0.6115\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2503 - accuracy: 0.8902 - val_loss: 1.8677 - val_accuracy: 0.6092\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.2470 - accuracy: 0.8939 - val_loss: 1.8278 - val_accuracy: 0.6161\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2441 - accuracy: 0.8931 - val_loss: 1.8580 - val_accuracy: 0.6046\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.2511 - accuracy: 0.8866 - val_loss: 1.8538 - val_accuracy: 0.6023\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.2413 - accuracy: 0.8935 - val_loss: 1.8804 - val_accuracy: 0.5977\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.2445 - accuracy: 0.8935 - val_loss: 1.9184 - val_accuracy: 0.5954\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.2405 - accuracy: 0.8959 - val_loss: 1.9884 - val_accuracy: 0.6046\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.2460 - accuracy: 0.8915 - val_loss: 1.9750 - val_accuracy: 0.6115\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.4751 - accuracy: 0.8618\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 184us/sample - loss: 3.4943 - accuracy: 0.0415 - val_loss: 3.4183 - val_accuracy: 0.0851\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.3783 - accuracy: 0.1122 - val_loss: 3.3045 - val_accuracy: 0.1931\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.2671 - accuracy: 0.2305 - val_loss: 3.1921 - val_accuracy: 0.3310\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 3.1581 - accuracy: 0.3691 - val_loss: 3.0823 - val_accuracy: 0.4575\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 3.0495 - accuracy: 0.4715 - val_loss: 2.9706 - val_accuracy: 0.5172\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.9389 - accuracy: 0.5240 - val_loss: 2.8590 - val_accuracy: 0.5402\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 2.8290 - accuracy: 0.5350 - val_loss: 2.7468 - val_accuracy: 0.5425\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 2.7197 - accuracy: 0.5415 - val_loss: 2.6353 - val_accuracy: 0.5448\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 2.6079 - accuracy: 0.5443 - val_loss: 2.5196 - val_accuracy: 0.5471\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 2.4929 - accuracy: 0.5476 - val_loss: 2.4027 - val_accuracy: 0.5471\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 2.3788 - accuracy: 0.5480 - val_loss: 2.2884 - val_accuracy: 0.5471\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 2.2661 - accuracy: 0.5496 - val_loss: 2.1741 - val_accuracy: 0.5471\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.1533 - accuracy: 0.5488 - val_loss: 2.0613 - val_accuracy: 0.5448\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 2.0417 - accuracy: 0.5484 - val_loss: 1.9504 - val_accuracy: 0.5494\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 1.9332 - accuracy: 0.5484 - val_loss: 1.8445 - val_accuracy: 0.5494\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 1.8292 - accuracy: 0.5488 - val_loss: 1.7439 - val_accuracy: 0.5494\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 1.7307 - accuracy: 0.5512 - val_loss: 1.6496 - val_accuracy: 0.5494\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 1.6376 - accuracy: 0.5524 - val_loss: 1.5604 - val_accuracy: 0.5494\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.5491 - accuracy: 0.5524 - val_loss: 1.4762 - val_accuracy: 0.5517\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 1.4662 - accuracy: 0.5516 - val_loss: 1.3988 - val_accuracy: 0.5540\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.3895 - accuracy: 0.5533 - val_loss: 1.3267 - val_accuracy: 0.5494\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 1.3179 - accuracy: 0.5533 - val_loss: 1.2605 - val_accuracy: 0.5494\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 1.2521 - accuracy: 0.5541 - val_loss: 1.2002 - val_accuracy: 0.5471\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 1.1925 - accuracy: 0.5569 - val_loss: 1.1455 - val_accuracy: 0.5494\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 1.1376 - accuracy: 0.5561 - val_loss: 1.0950 - val_accuracy: 0.5517\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 165us/sample - loss: 1.0875 - accuracy: 0.5573 - val_loss: 1.0497 - val_accuracy: 0.5540\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 111us/sample - loss: 1.0425 - accuracy: 0.5561 - val_loss: 1.0093 - val_accuracy: 0.5609\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 1.0018 - accuracy: 0.5581 - val_loss: 0.9718 - val_accuracy: 0.5563\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.9643 - accuracy: 0.5630 - val_loss: 0.9380 - val_accuracy: 0.5655\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.9300 - accuracy: 0.5659 - val_loss: 0.9067 - val_accuracy: 0.5724\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.8995 - accuracy: 0.5691 - val_loss: 0.8799 - val_accuracy: 0.5701\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.8723 - accuracy: 0.5724 - val_loss: 0.8555 - val_accuracy: 0.5747\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.8477 - accuracy: 0.5768 - val_loss: 0.8336 - val_accuracy: 0.5793\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.8258 - accuracy: 0.5821 - val_loss: 0.8141 - val_accuracy: 0.5862\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.8062 - accuracy: 0.5866 - val_loss: 0.7967 - val_accuracy: 0.5862\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7885 - accuracy: 0.5939 - val_loss: 0.7811 - val_accuracy: 0.5816\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.7730 - accuracy: 0.5915 - val_loss: 0.7675 - val_accuracy: 0.5839\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.7590 - accuracy: 0.5931 - val_loss: 0.7554 - val_accuracy: 0.5839\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7467 - accuracy: 0.5972 - val_loss: 0.7446 - val_accuracy: 0.5839\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7357 - accuracy: 0.6028 - val_loss: 0.7350 - val_accuracy: 0.5839\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.7256 - accuracy: 0.6077 - val_loss: 0.7263 - val_accuracy: 0.5862\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7166 - accuracy: 0.6098 - val_loss: 0.7186 - val_accuracy: 0.5977\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.7086 - accuracy: 0.6130 - val_loss: 0.7117 - val_accuracy: 0.6069\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.7013 - accuracy: 0.6179 - val_loss: 0.7054 - val_accuracy: 0.6092\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.6948 - accuracy: 0.6195 - val_loss: 0.6996 - val_accuracy: 0.6138\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.6888 - accuracy: 0.6228 - val_loss: 0.6944 - val_accuracy: 0.6184\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.6834 - accuracy: 0.6260 - val_loss: 0.6898 - val_accuracy: 0.6184\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.6784 - accuracy: 0.6268 - val_loss: 0.6856 - val_accuracy: 0.6161\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.6738 - accuracy: 0.6285 - val_loss: 0.6817 - val_accuracy: 0.6161\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6695 - accuracy: 0.6354 - val_loss: 0.6781 - val_accuracy: 0.6138\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.6656 - accuracy: 0.6354 - val_loss: 0.6747 - val_accuracy: 0.6230\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.6621 - accuracy: 0.6382 - val_loss: 0.6716 - val_accuracy: 0.6253\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.6585 - accuracy: 0.6394 - val_loss: 0.6687 - val_accuracy: 0.6276\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.6555 - accuracy: 0.6423 - val_loss: 0.6660 - val_accuracy: 0.6299\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 28us/sample - loss: 0.6524 - accuracy: 0.6419 - val_loss: 0.6635 - val_accuracy: 0.6299\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.6495 - accuracy: 0.6439 - val_loss: 0.6611 - val_accuracy: 0.6299\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.6470 - accuracy: 0.6439 - val_loss: 0.6590 - val_accuracy: 0.6276\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.6445 - accuracy: 0.6480 - val_loss: 0.6568 - val_accuracy: 0.6276\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.6421 - accuracy: 0.6533 - val_loss: 0.6549 - val_accuracy: 0.6230\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.6400 - accuracy: 0.6541 - val_loss: 0.6530 - val_accuracy: 0.6253\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.6378 - accuracy: 0.6516 - val_loss: 0.6514 - val_accuracy: 0.6230\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6358 - accuracy: 0.6557 - val_loss: 0.6496 - val_accuracy: 0.6253\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.6339 - accuracy: 0.6569 - val_loss: 0.6480 - val_accuracy: 0.6322\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6321 - accuracy: 0.6581 - val_loss: 0.6464 - val_accuracy: 0.6322\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.6302 - accuracy: 0.6614 - val_loss: 0.6449 - val_accuracy: 0.6322\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6285 - accuracy: 0.6630 - val_loss: 0.6436 - val_accuracy: 0.6322\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6270 - accuracy: 0.6659 - val_loss: 0.6423 - val_accuracy: 0.6368\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.6254 - accuracy: 0.6654 - val_loss: 0.6410 - val_accuracy: 0.6391\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.6239 - accuracy: 0.6695 - val_loss: 0.6398 - val_accuracy: 0.6414\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6225 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6391\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6210 - accuracy: 0.6699 - val_loss: 0.6373 - val_accuracy: 0.6437\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.6196 - accuracy: 0.6715 - val_loss: 0.6363 - val_accuracy: 0.6437\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6184 - accuracy: 0.6728 - val_loss: 0.6352 - val_accuracy: 0.6460\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.6171 - accuracy: 0.6760 - val_loss: 0.6341 - val_accuracy: 0.6460\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6159 - accuracy: 0.6752 - val_loss: 0.6332 - val_accuracy: 0.6460\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.6146 - accuracy: 0.6768 - val_loss: 0.6323 - val_accuracy: 0.6506\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.6136 - accuracy: 0.6785 - val_loss: 0.6314 - val_accuracy: 0.6483\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.6125 - accuracy: 0.6813 - val_loss: 0.6305 - val_accuracy: 0.6483\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.6114 - accuracy: 0.6789 - val_loss: 0.6296 - val_accuracy: 0.6437\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.6104 - accuracy: 0.6821 - val_loss: 0.6288 - val_accuracy: 0.6437\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.6093 - accuracy: 0.6833 - val_loss: 0.6281 - val_accuracy: 0.6414\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.6085 - accuracy: 0.6821 - val_loss: 0.6272 - val_accuracy: 0.6414\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.6075 - accuracy: 0.6813 - val_loss: 0.6265 - val_accuracy: 0.6437\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6065 - accuracy: 0.6809 - val_loss: 0.6257 - val_accuracy: 0.6437\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.6057 - accuracy: 0.6821 - val_loss: 0.6251 - val_accuracy: 0.6460\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6048 - accuracy: 0.6829 - val_loss: 0.6244 - val_accuracy: 0.6437\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6039 - accuracy: 0.6825 - val_loss: 0.6238 - val_accuracy: 0.6437\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.6032 - accuracy: 0.6813 - val_loss: 0.6232 - val_accuracy: 0.6437\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6023 - accuracy: 0.6829 - val_loss: 0.6225 - val_accuracy: 0.6437\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.6015 - accuracy: 0.6825 - val_loss: 0.6219 - val_accuracy: 0.6437\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.6008 - accuracy: 0.6862 - val_loss: 0.6213 - val_accuracy: 0.6460\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.6001 - accuracy: 0.6858 - val_loss: 0.6207 - val_accuracy: 0.6483\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5993 - accuracy: 0.6862 - val_loss: 0.6203 - val_accuracy: 0.6437\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5986 - accuracy: 0.6866 - val_loss: 0.6198 - val_accuracy: 0.6437\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5979 - accuracy: 0.6878 - val_loss: 0.6192 - val_accuracy: 0.6483\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5972 - accuracy: 0.6890 - val_loss: 0.6187 - val_accuracy: 0.6483\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5966 - accuracy: 0.6898 - val_loss: 0.6182 - val_accuracy: 0.6483\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5959 - accuracy: 0.6874 - val_loss: 0.6178 - val_accuracy: 0.6460\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5953 - accuracy: 0.6874 - val_loss: 0.6174 - val_accuracy: 0.6414\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5948 - accuracy: 0.6882 - val_loss: 0.6169 - val_accuracy: 0.6414\n",
      "2895/2895 [==============================] - 0s 16us/sample - loss: 0.5975 - accuracy: 0.6812\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 111us/sample - loss: 2.9615 - accuracy: 0.3752 - val_loss: 2.3711 - val_accuracy: 0.4989\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 1.8265 - accuracy: 0.5520 - val_loss: 1.3402 - val_accuracy: 0.5517\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 1.0906 - accuracy: 0.5793 - val_loss: 0.9155 - val_accuracy: 0.5793\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.8298 - accuracy: 0.6045 - val_loss: 0.7793 - val_accuracy: 0.5862\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7384 - accuracy: 0.6175 - val_loss: 0.7241 - val_accuracy: 0.6115\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.6946 - accuracy: 0.6358 - val_loss: 0.6936 - val_accuracy: 0.6299\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.6682 - accuracy: 0.6541 - val_loss: 0.6740 - val_accuracy: 0.6391\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.6495 - accuracy: 0.6671 - val_loss: 0.6597 - val_accuracy: 0.6506\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.6352 - accuracy: 0.6744 - val_loss: 0.6485 - val_accuracy: 0.6483\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6237 - accuracy: 0.6854 - val_loss: 0.6397 - val_accuracy: 0.6552\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.6143 - accuracy: 0.6841 - val_loss: 0.6340 - val_accuracy: 0.6690\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6069 - accuracy: 0.6915 - val_loss: 0.6270 - val_accuracy: 0.6713\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.6001 - accuracy: 0.6915 - val_loss: 0.6226 - val_accuracy: 0.6690\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5944 - accuracy: 0.6947 - val_loss: 0.6191 - val_accuracy: 0.6736\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5899 - accuracy: 0.6996 - val_loss: 0.6170 - val_accuracy: 0.6713\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5861 - accuracy: 0.7016 - val_loss: 0.6143 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5840 - accuracy: 0.7045 - val_loss: 0.6141 - val_accuracy: 0.6621\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5805 - accuracy: 0.7028 - val_loss: 0.6109 - val_accuracy: 0.6598\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5780 - accuracy: 0.7085 - val_loss: 0.6114 - val_accuracy: 0.6598\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5765 - accuracy: 0.7057 - val_loss: 0.6096 - val_accuracy: 0.6690\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5749 - accuracy: 0.7073 - val_loss: 0.6097 - val_accuracy: 0.6575\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5736 - accuracy: 0.7118 - val_loss: 0.6084 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5717 - accuracy: 0.7085 - val_loss: 0.6086 - val_accuracy: 0.6621\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5708 - accuracy: 0.7098 - val_loss: 0.6085 - val_accuracy: 0.6598\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5691 - accuracy: 0.7102 - val_loss: 0.6081 - val_accuracy: 0.6598\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5686 - accuracy: 0.7126 - val_loss: 0.6084 - val_accuracy: 0.6598\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5678 - accuracy: 0.7093 - val_loss: 0.6074 - val_accuracy: 0.6575\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5681 - accuracy: 0.7093 - val_loss: 0.6083 - val_accuracy: 0.6598\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5655 - accuracy: 0.7098 - val_loss: 0.6075 - val_accuracy: 0.6598\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5645 - accuracy: 0.7122 - val_loss: 0.6080 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5630 - accuracy: 0.7122 - val_loss: 0.6084 - val_accuracy: 0.6598\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5625 - accuracy: 0.7114 - val_loss: 0.6074 - val_accuracy: 0.6575\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5611 - accuracy: 0.7118 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5610 - accuracy: 0.7118 - val_loss: 0.6081 - val_accuracy: 0.6575\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.5600 - accuracy: 0.7122 - val_loss: 0.6079 - val_accuracy: 0.6575\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5590 - accuracy: 0.7146 - val_loss: 0.6080 - val_accuracy: 0.6552\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5584 - accuracy: 0.7159 - val_loss: 0.6098 - val_accuracy: 0.6690\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5575 - accuracy: 0.7138 - val_loss: 0.6088 - val_accuracy: 0.6598\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5572 - accuracy: 0.7150 - val_loss: 0.6097 - val_accuracy: 0.6598\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5561 - accuracy: 0.7171 - val_loss: 0.6104 - val_accuracy: 0.6736\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5550 - accuracy: 0.7146 - val_loss: 0.6086 - val_accuracy: 0.6552\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5544 - accuracy: 0.7146 - val_loss: 0.6092 - val_accuracy: 0.6529\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5537 - accuracy: 0.7150 - val_loss: 0.6111 - val_accuracy: 0.6736\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5527 - accuracy: 0.7150 - val_loss: 0.6095 - val_accuracy: 0.6575\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5519 - accuracy: 0.7146 - val_loss: 0.6096 - val_accuracy: 0.6575\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 111us/sample - loss: 0.5514 - accuracy: 0.7175 - val_loss: 0.6101 - val_accuracy: 0.6644\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5514 - accuracy: 0.7142 - val_loss: 0.6097 - val_accuracy: 0.6621\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5499 - accuracy: 0.7171 - val_loss: 0.6106 - val_accuracy: 0.6690\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5493 - accuracy: 0.7134 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5482 - accuracy: 0.7220 - val_loss: 0.6115 - val_accuracy: 0.6736\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5477 - accuracy: 0.7150 - val_loss: 0.6110 - val_accuracy: 0.6575\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5466 - accuracy: 0.7203 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5463 - accuracy: 0.7183 - val_loss: 0.6110 - val_accuracy: 0.6598\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5460 - accuracy: 0.7203 - val_loss: 0.6109 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5449 - accuracy: 0.7215 - val_loss: 0.6116 - val_accuracy: 0.6644\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5440 - accuracy: 0.7183 - val_loss: 0.6109 - val_accuracy: 0.6598\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5435 - accuracy: 0.7224 - val_loss: 0.6113 - val_accuracy: 0.6575\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5431 - accuracy: 0.7232 - val_loss: 0.6116 - val_accuracy: 0.6621\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5413 - accuracy: 0.7203 - val_loss: 0.6118 - val_accuracy: 0.6621\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5410 - accuracy: 0.7195 - val_loss: 0.6122 - val_accuracy: 0.6598\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5400 - accuracy: 0.7220 - val_loss: 0.6131 - val_accuracy: 0.6690\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5393 - accuracy: 0.7244 - val_loss: 0.6146 - val_accuracy: 0.6736\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5381 - accuracy: 0.7244 - val_loss: 0.6145 - val_accuracy: 0.6690\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5383 - accuracy: 0.7203 - val_loss: 0.6171 - val_accuracy: 0.6759\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5365 - accuracy: 0.7248 - val_loss: 0.6141 - val_accuracy: 0.6575\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5352 - accuracy: 0.7285 - val_loss: 0.6141 - val_accuracy: 0.6575\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5351 - accuracy: 0.7240 - val_loss: 0.6142 - val_accuracy: 0.6713\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5342 - accuracy: 0.7272 - val_loss: 0.6150 - val_accuracy: 0.6736\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5336 - accuracy: 0.7313 - val_loss: 0.6149 - val_accuracy: 0.6736\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 28us/sample - loss: 0.5330 - accuracy: 0.7276 - val_loss: 0.6147 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5317 - accuracy: 0.7264 - val_loss: 0.6156 - val_accuracy: 0.6690\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5311 - accuracy: 0.7293 - val_loss: 0.6154 - val_accuracy: 0.6713\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5303 - accuracy: 0.7313 - val_loss: 0.6155 - val_accuracy: 0.6644\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5296 - accuracy: 0.7276 - val_loss: 0.6156 - val_accuracy: 0.6736\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5295 - accuracy: 0.7289 - val_loss: 0.6171 - val_accuracy: 0.6713\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5283 - accuracy: 0.7313 - val_loss: 0.6169 - val_accuracy: 0.6575\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5272 - accuracy: 0.7313 - val_loss: 0.6169 - val_accuracy: 0.6621\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5271 - accuracy: 0.7317 - val_loss: 0.6167 - val_accuracy: 0.6575\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5259 - accuracy: 0.7346 - val_loss: 0.6178 - val_accuracy: 0.6690\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5240 - accuracy: 0.7350 - val_loss: 0.6173 - val_accuracy: 0.6598\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5241 - accuracy: 0.7382 - val_loss: 0.6176 - val_accuracy: 0.6598\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5228 - accuracy: 0.7378 - val_loss: 0.6193 - val_accuracy: 0.6690\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5221 - accuracy: 0.7350 - val_loss: 0.6186 - val_accuracy: 0.6690\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5213 - accuracy: 0.7382 - val_loss: 0.6200 - val_accuracy: 0.6644\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5211 - accuracy: 0.7358 - val_loss: 0.6197 - val_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5202 - accuracy: 0.7341 - val_loss: 0.6196 - val_accuracy: 0.6644\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5188 - accuracy: 0.7378 - val_loss: 0.6197 - val_accuracy: 0.6621\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5183 - accuracy: 0.7386 - val_loss: 0.6208 - val_accuracy: 0.6483\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5169 - accuracy: 0.7382 - val_loss: 0.6212 - val_accuracy: 0.6690\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5162 - accuracy: 0.7382 - val_loss: 0.6222 - val_accuracy: 0.6506\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.6216 - val_accuracy: 0.6621\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5152 - accuracy: 0.7407 - val_loss: 0.6212 - val_accuracy: 0.6621\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5135 - accuracy: 0.7451 - val_loss: 0.6230 - val_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5141 - accuracy: 0.7411 - val_loss: 0.6222 - val_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5124 - accuracy: 0.7411 - val_loss: 0.6230 - val_accuracy: 0.6621\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5122 - accuracy: 0.7411 - val_loss: 0.6229 - val_accuracy: 0.6598\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5113 - accuracy: 0.7447 - val_loss: 0.6231 - val_accuracy: 0.6552\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5102 - accuracy: 0.7480 - val_loss: 0.6239 - val_accuracy: 0.6644\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5090 - accuracy: 0.7431 - val_loss: 0.6238 - val_accuracy: 0.6460\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5084 - accuracy: 0.7439 - val_loss: 0.6243 - val_accuracy: 0.6575\n",
      "2895/2895 [==============================] - 0s 20us/sample - loss: 0.5230 - accuracy: 0.7351\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 117us/sample - loss: 1.0094 - accuracy: 0.5898 - val_loss: 0.6848 - val_accuracy: 0.6322\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6108 - accuracy: 0.6663 - val_loss: 0.6302 - val_accuracy: 0.6529\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.5874 - accuracy: 0.6825 - val_loss: 0.6235 - val_accuracy: 0.6414\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5786 - accuracy: 0.6992 - val_loss: 0.6142 - val_accuracy: 0.6621\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5755 - accuracy: 0.6959 - val_loss: 0.6228 - val_accuracy: 0.6368\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5701 - accuracy: 0.6898 - val_loss: 0.6192 - val_accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5647 - accuracy: 0.6992 - val_loss: 0.6192 - val_accuracy: 0.6713\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5592 - accuracy: 0.7049 - val_loss: 0.6218 - val_accuracy: 0.6529\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5527 - accuracy: 0.7102 - val_loss: 0.6254 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 132us/sample - loss: 0.5454 - accuracy: 0.7175 - val_loss: 0.6328 - val_accuracy: 0.6414\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5459 - accuracy: 0.7232 - val_loss: 0.6363 - val_accuracy: 0.6598\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.5354 - accuracy: 0.7232 - val_loss: 0.6385 - val_accuracy: 0.6690\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5304 - accuracy: 0.7313 - val_loss: 0.6537 - val_accuracy: 0.6529\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5239 - accuracy: 0.7362 - val_loss: 0.6365 - val_accuracy: 0.6621\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 120us/sample - loss: 0.5178 - accuracy: 0.7346 - val_loss: 0.6376 - val_accuracy: 0.6598\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5069 - accuracy: 0.7407 - val_loss: 0.6787 - val_accuracy: 0.6138\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.5104 - accuracy: 0.7419 - val_loss: 0.6727 - val_accuracy: 0.6483\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4894 - accuracy: 0.7533 - val_loss: 0.6624 - val_accuracy: 0.6414\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4898 - accuracy: 0.7593 - val_loss: 0.6705 - val_accuracy: 0.6414\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.4796 - accuracy: 0.7577 - val_loss: 0.6744 - val_accuracy: 0.6414\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4761 - accuracy: 0.7602 - val_loss: 0.6717 - val_accuracy: 0.6276\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.4669 - accuracy: 0.7695 - val_loss: 0.6794 - val_accuracy: 0.6322\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.6859 - val_accuracy: 0.6483\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.4520 - accuracy: 0.7837 - val_loss: 0.6887 - val_accuracy: 0.6368\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.4500 - accuracy: 0.7854 - val_loss: 0.6933 - val_accuracy: 0.6506\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4456 - accuracy: 0.7902 - val_loss: 0.7037 - val_accuracy: 0.6299\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.4412 - accuracy: 0.7915 - val_loss: 0.7094 - val_accuracy: 0.6552\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4384 - accuracy: 0.7955 - val_loss: 0.7202 - val_accuracy: 0.6414\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4344 - accuracy: 0.8004 - val_loss: 0.7191 - val_accuracy: 0.6552\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4210 - accuracy: 0.8020 - val_loss: 0.7256 - val_accuracy: 0.6437\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.4176 - accuracy: 0.8077 - val_loss: 0.7656 - val_accuracy: 0.6115\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.4187 - accuracy: 0.8020 - val_loss: 0.7546 - val_accuracy: 0.6276\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.7503 - val_accuracy: 0.6414\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.4054 - accuracy: 0.8150 - val_loss: 0.7579 - val_accuracy: 0.6345\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3983 - accuracy: 0.8191 - val_loss: 0.7611 - val_accuracy: 0.6437\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3966 - accuracy: 0.8154 - val_loss: 0.7795 - val_accuracy: 0.6276\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3898 - accuracy: 0.8325 - val_loss: 0.7661 - val_accuracy: 0.6483\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.3856 - accuracy: 0.8236 - val_loss: 0.7837 - val_accuracy: 0.6253\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3806 - accuracy: 0.8244 - val_loss: 0.7913 - val_accuracy: 0.6276\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3774 - accuracy: 0.8337 - val_loss: 0.7880 - val_accuracy: 0.6460\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.3697 - accuracy: 0.8366 - val_loss: 0.8127 - val_accuracy: 0.6207\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3655 - accuracy: 0.8407 - val_loss: 0.8097 - val_accuracy: 0.6506\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3622 - accuracy: 0.8411 - val_loss: 0.8019 - val_accuracy: 0.6437\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3614 - accuracy: 0.8370 - val_loss: 0.8409 - val_accuracy: 0.6299\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3587 - accuracy: 0.8407 - val_loss: 0.8243 - val_accuracy: 0.6460\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3553 - accuracy: 0.8488 - val_loss: 0.8256 - val_accuracy: 0.6414\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3480 - accuracy: 0.8512 - val_loss: 0.8259 - val_accuracy: 0.6276\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.3458 - accuracy: 0.8500 - val_loss: 0.8429 - val_accuracy: 0.6483\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3389 - accuracy: 0.8451 - val_loss: 0.8983 - val_accuracy: 0.6207\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3494 - accuracy: 0.8443 - val_loss: 0.8529 - val_accuracy: 0.6437\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3338 - accuracy: 0.8569 - val_loss: 0.8550 - val_accuracy: 0.6437\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3341 - accuracy: 0.8467 - val_loss: 0.8747 - val_accuracy: 0.6368\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3344 - accuracy: 0.8630 - val_loss: 0.9035 - val_accuracy: 0.6322\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3207 - accuracy: 0.8602 - val_loss: 0.8820 - val_accuracy: 0.6276\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.3193 - accuracy: 0.8634 - val_loss: 0.9206 - val_accuracy: 0.6207\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.3150 - accuracy: 0.8691 - val_loss: 0.8896 - val_accuracy: 0.6368\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.3158 - accuracy: 0.8711 - val_loss: 0.9048 - val_accuracy: 0.6345\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3090 - accuracy: 0.8650 - val_loss: 0.9131 - val_accuracy: 0.6230\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.3065 - accuracy: 0.8707 - val_loss: 0.9247 - val_accuracy: 0.6276\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.3007 - accuracy: 0.8715 - val_loss: 0.9234 - val_accuracy: 0.6391\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.2982 - accuracy: 0.8695 - val_loss: 0.9619 - val_accuracy: 0.6207\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.2924 - accuracy: 0.8902 - val_loss: 0.9556 - val_accuracy: 0.6092\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.2955 - accuracy: 0.8809 - val_loss: 0.9554 - val_accuracy: 0.6230\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.2861 - accuracy: 0.8854 - val_loss: 0.9439 - val_accuracy: 0.6345\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.2960 - accuracy: 0.8764 - val_loss: 0.9812 - val_accuracy: 0.6230\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.2793 - accuracy: 0.8837 - val_loss: 0.9692 - val_accuracy: 0.6345\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.2778 - accuracy: 0.8813 - val_loss: 1.0021 - val_accuracy: 0.6207\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.2753 - accuracy: 0.8943 - val_loss: 1.0044 - val_accuracy: 0.6207\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2715 - accuracy: 0.8902 - val_loss: 0.9758 - val_accuracy: 0.6230\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.2703 - accuracy: 0.8825 - val_loss: 0.9988 - val_accuracy: 0.6345\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2606 - accuracy: 0.9012 - val_loss: 1.0120 - val_accuracy: 0.6161\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.2588 - accuracy: 0.8951 - val_loss: 1.0347 - val_accuracy: 0.6207\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.2674 - accuracy: 0.8894 - val_loss: 1.0114 - val_accuracy: 0.6207\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.2558 - accuracy: 0.8984 - val_loss: 1.0540 - val_accuracy: 0.6092\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.2512 - accuracy: 0.9028 - val_loss: 1.0513 - val_accuracy: 0.6230\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.2489 - accuracy: 0.9081 - val_loss: 1.0390 - val_accuracy: 0.6322\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.2438 - accuracy: 0.9073 - val_loss: 1.0712 - val_accuracy: 0.6161\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.2569 - accuracy: 0.8972 - val_loss: 1.0753 - val_accuracy: 0.6253\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.2492 - accuracy: 0.9020 - val_loss: 1.0957 - val_accuracy: 0.6207\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.2369 - accuracy: 0.9122 - val_loss: 1.0781 - val_accuracy: 0.6092\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.2381 - accuracy: 0.9081 - val_loss: 1.1133 - val_accuracy: 0.6322\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.2346 - accuracy: 0.9102 - val_loss: 1.0910 - val_accuracy: 0.6276\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.2377 - accuracy: 0.9110 - val_loss: 1.1295 - val_accuracy: 0.5977\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.2433 - accuracy: 0.8980 - val_loss: 1.1197 - val_accuracy: 0.6046\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2259 - accuracy: 0.9138 - val_loss: 1.1332 - val_accuracy: 0.6322\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2216 - accuracy: 0.9154 - val_loss: 1.1529 - val_accuracy: 0.6207\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.2256 - accuracy: 0.9142 - val_loss: 1.1361 - val_accuracy: 0.6299\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2280 - accuracy: 0.9150 - val_loss: 1.1486 - val_accuracy: 0.6276\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.2141 - accuracy: 0.9264 - val_loss: 1.1741 - val_accuracy: 0.6207\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.2188 - accuracy: 0.9211 - val_loss: 1.1653 - val_accuracy: 0.6069\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.2142 - accuracy: 0.9187 - val_loss: 1.1781 - val_accuracy: 0.6207\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.2272 - accuracy: 0.9130 - val_loss: 1.1714 - val_accuracy: 0.6161\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.2133 - accuracy: 0.9224 - val_loss: 1.2224 - val_accuracy: 0.6092\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.2053 - accuracy: 0.9313 - val_loss: 1.1918 - val_accuracy: 0.6207\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.2049 - accuracy: 0.9236 - val_loss: 1.2092 - val_accuracy: 0.6161\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.2090 - accuracy: 0.9232 - val_loss: 1.2052 - val_accuracy: 0.6207\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.2075 - accuracy: 0.9272 - val_loss: 1.2384 - val_accuracy: 0.5885\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.2046 - accuracy: 0.9289 - val_loss: 1.2177 - val_accuracy: 0.6207\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1976 - accuracy: 0.9305 - val_loss: 1.2884 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.1960 - accuracy: 0.9272 - val_loss: 1.2524 - val_accuracy: 0.6069\n",
      "2895/2895 [==============================] - 0s 32us/sample - loss: 0.3323 - accuracy: 0.8957\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 168us/sample - loss: 0.7391 - accuracy: 0.5980 - val_loss: 0.6416 - val_accuracy: 0.6552\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.6062 - accuracy: 0.6785 - val_loss: 0.6471 - val_accuracy: 0.6621\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5912 - accuracy: 0.6801 - val_loss: 0.6356 - val_accuracy: 0.6529\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5774 - accuracy: 0.6959 - val_loss: 0.6911 - val_accuracy: 0.6529\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5636 - accuracy: 0.7098 - val_loss: 0.6594 - val_accuracy: 0.6529\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5470 - accuracy: 0.7187 - val_loss: 0.6988 - val_accuracy: 0.6460\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5442 - accuracy: 0.7236 - val_loss: 0.7394 - val_accuracy: 0.6391\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5170 - accuracy: 0.7459 - val_loss: 0.7031 - val_accuracy: 0.6276\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5162 - accuracy: 0.7459 - val_loss: 0.7468 - val_accuracy: 0.6368\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.4946 - accuracy: 0.7455 - val_loss: 0.7741 - val_accuracy: 0.6299\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4772 - accuracy: 0.7675 - val_loss: 0.8277 - val_accuracy: 0.6368\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.4839 - accuracy: 0.7667 - val_loss: 0.8554 - val_accuracy: 0.6276\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.8532 - val_accuracy: 0.6299\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4451 - accuracy: 0.7939 - val_loss: 0.8368 - val_accuracy: 0.6299\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4245 - accuracy: 0.7984 - val_loss: 0.9020 - val_accuracy: 0.6207\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.4229 - accuracy: 0.8061 - val_loss: 0.9371 - val_accuracy: 0.5908\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.4136 - accuracy: 0.7976 - val_loss: 0.9613 - val_accuracy: 0.5862\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.4017 - accuracy: 0.8146 - val_loss: 1.0424 - val_accuracy: 0.6414\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3898 - accuracy: 0.8195 - val_loss: 1.0236 - val_accuracy: 0.6253\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.3900 - accuracy: 0.8195 - val_loss: 1.0401 - val_accuracy: 0.5885\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.3554 - accuracy: 0.8415 - val_loss: 1.0816 - val_accuracy: 0.6115\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3758 - accuracy: 0.8276 - val_loss: 1.1357 - val_accuracy: 0.5977\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.3631 - accuracy: 0.8305 - val_loss: 1.1133 - val_accuracy: 0.6092\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.3388 - accuracy: 0.8496 - val_loss: 1.1942 - val_accuracy: 0.6230\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3282 - accuracy: 0.8553 - val_loss: 1.1814 - val_accuracy: 0.6322\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.3315 - accuracy: 0.8496 - val_loss: 1.2564 - val_accuracy: 0.6069\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3164 - accuracy: 0.8573 - val_loss: 1.3463 - val_accuracy: 0.6092\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.3279 - accuracy: 0.8553 - val_loss: 1.3540 - val_accuracy: 0.6161\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3346 - accuracy: 0.8533 - val_loss: 1.4260 - val_accuracy: 0.5885\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.2879 - accuracy: 0.8772 - val_loss: 1.3887 - val_accuracy: 0.5770\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.2934 - accuracy: 0.8687 - val_loss: 1.4880 - val_accuracy: 0.5793\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.2843 - accuracy: 0.8707 - val_loss: 1.4916 - val_accuracy: 0.6138\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.2844 - accuracy: 0.8720 - val_loss: 1.4690 - val_accuracy: 0.6299\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.2753 - accuracy: 0.8691 - val_loss: 1.5605 - val_accuracy: 0.6092\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.2630 - accuracy: 0.8907 - val_loss: 1.5683 - val_accuracy: 0.6069\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.2424 - accuracy: 0.8939 - val_loss: 1.6098 - val_accuracy: 0.5931\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 123us/sample - loss: 0.2610 - accuracy: 0.8841 - val_loss: 1.6269 - val_accuracy: 0.6184\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.2322 - accuracy: 0.9041 - val_loss: 1.6764 - val_accuracy: 0.6046\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.2383 - accuracy: 0.8943 - val_loss: 1.8125 - val_accuracy: 0.5977\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.2338 - accuracy: 0.9004 - val_loss: 1.6904 - val_accuracy: 0.6092\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.2347 - accuracy: 0.9004 - val_loss: 1.8526 - val_accuracy: 0.6092\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.2191 - accuracy: 0.9114 - val_loss: 1.8569 - val_accuracy: 0.6069\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.2153 - accuracy: 0.9130 - val_loss: 2.0197 - val_accuracy: 0.5678\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.2101 - accuracy: 0.9130 - val_loss: 1.9078 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1914 - accuracy: 0.9207 - val_loss: 1.9807 - val_accuracy: 0.5977\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.2159 - accuracy: 0.9077 - val_loss: 2.0648 - val_accuracy: 0.6046\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.2010 - accuracy: 0.9126 - val_loss: 2.0107 - val_accuracy: 0.5954\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.2004 - accuracy: 0.9175 - val_loss: 2.0199 - val_accuracy: 0.6046\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1795 - accuracy: 0.9248 - val_loss: 2.0221 - val_accuracy: 0.6230\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 0.2062 - accuracy: 0.9171 - val_loss: 2.0551 - val_accuracy: 0.6023\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.1773 - accuracy: 0.9280 - val_loss: 2.0894 - val_accuracy: 0.6046\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.1816 - accuracy: 0.9232 - val_loss: 2.0480 - val_accuracy: 0.6069\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.1839 - accuracy: 0.9252 - val_loss: 2.2651 - val_accuracy: 0.5839\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.1748 - accuracy: 0.9293 - val_loss: 2.2338 - val_accuracy: 0.5977\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.1669 - accuracy: 0.9313 - val_loss: 2.2550 - val_accuracy: 0.5839\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.1893 - accuracy: 0.9207 - val_loss: 2.2677 - val_accuracy: 0.6046\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.1678 - accuracy: 0.9358 - val_loss: 2.2920 - val_accuracy: 0.5977\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.1642 - accuracy: 0.9309 - val_loss: 2.2208 - val_accuracy: 0.5954\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1633 - accuracy: 0.9317 - val_loss: 2.2325 - val_accuracy: 0.6069\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.1511 - accuracy: 0.9378 - val_loss: 2.4458 - val_accuracy: 0.6092\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.1426 - accuracy: 0.9443 - val_loss: 2.4256 - val_accuracy: 0.6138\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.1606 - accuracy: 0.9374 - val_loss: 2.4793 - val_accuracy: 0.5839\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.1462 - accuracy: 0.9423 - val_loss: 2.4644 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.1507 - accuracy: 0.9419 - val_loss: 2.4431 - val_accuracy: 0.5885\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.1284 - accuracy: 0.9435 - val_loss: 2.4768 - val_accuracy: 0.6138\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.1244 - accuracy: 0.9472 - val_loss: 2.5921 - val_accuracy: 0.6184\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.1358 - accuracy: 0.9415 - val_loss: 2.6139 - val_accuracy: 0.5954\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.1598 - accuracy: 0.9386 - val_loss: 2.5016 - val_accuracy: 0.6115\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.1318 - accuracy: 0.9512 - val_loss: 2.5426 - val_accuracy: 0.6138\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1138 - accuracy: 0.9545 - val_loss: 2.5739 - val_accuracy: 0.5977\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1411 - accuracy: 0.9415 - val_loss: 2.7066 - val_accuracy: 0.5908\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.1248 - accuracy: 0.9459 - val_loss: 2.6688 - val_accuracy: 0.5862\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.1438 - accuracy: 0.9431 - val_loss: 2.6702 - val_accuracy: 0.5885\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.1323 - accuracy: 0.9472 - val_loss: 2.8937 - val_accuracy: 0.5770\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.1242 - accuracy: 0.9455 - val_loss: 2.8232 - val_accuracy: 0.5885\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1329 - accuracy: 0.9472 - val_loss: 2.8696 - val_accuracy: 0.6023\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.1445 - accuracy: 0.9439 - val_loss: 2.8034 - val_accuracy: 0.6115\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.1325 - accuracy: 0.9492 - val_loss: 2.7587 - val_accuracy: 0.6069\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.1219 - accuracy: 0.9504 - val_loss: 2.7968 - val_accuracy: 0.5747\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.1045 - accuracy: 0.9606 - val_loss: 2.8155 - val_accuracy: 0.6069\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.1073 - accuracy: 0.9537 - val_loss: 2.9180 - val_accuracy: 0.6161\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.1370 - accuracy: 0.9476 - val_loss: 2.9164 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.1121 - accuracy: 0.9577 - val_loss: 3.2313 - val_accuracy: 0.5862\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.1258 - accuracy: 0.9512 - val_loss: 2.8950 - val_accuracy: 0.5977\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.1149 - accuracy: 0.9553 - val_loss: 3.0456 - val_accuracy: 0.5862\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.0997 - accuracy: 0.9598 - val_loss: 2.8978 - val_accuracy: 0.5954\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.1067 - accuracy: 0.9561 - val_loss: 3.0031 - val_accuracy: 0.5862\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1031 - accuracy: 0.9606 - val_loss: 3.1672 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.1353 - accuracy: 0.9451 - val_loss: 3.0663 - val_accuracy: 0.5977\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.1170 - accuracy: 0.9533 - val_loss: 3.1396 - val_accuracy: 0.5839\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.0892 - accuracy: 0.9654 - val_loss: 3.2433 - val_accuracy: 0.5793\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.0991 - accuracy: 0.9598 - val_loss: 3.0938 - val_accuracy: 0.5931\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.1103 - accuracy: 0.9585 - val_loss: 3.0769 - val_accuracy: 0.5977\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.1033 - accuracy: 0.9553 - val_loss: 3.1823 - val_accuracy: 0.5862\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.0997 - accuracy: 0.9610 - val_loss: 3.1129 - val_accuracy: 0.5954\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.0960 - accuracy: 0.9610 - val_loss: 3.0260 - val_accuracy: 0.6115\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.1045 - accuracy: 0.9545 - val_loss: 3.0575 - val_accuracy: 0.6230\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.1260 - accuracy: 0.9524 - val_loss: 3.3509 - val_accuracy: 0.5908\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.1002 - accuracy: 0.9618 - val_loss: 3.1914 - val_accuracy: 0.6023\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.1180 - accuracy: 0.9537 - val_loss: 3.2165 - val_accuracy: 0.6000\n",
      "2895/2895 [==============================] - 0s 50us/sample - loss: 0.5392 - accuracy: 0.9178\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 118us/sample - loss: 3.7979 - accuracy: 0.5463 - val_loss: 0.7080 - val_accuracy: 0.5471\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.6580 - accuracy: 0.6248 - val_loss: 0.6628 - val_accuracy: 0.6322\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.6207 - accuracy: 0.6581 - val_loss: 0.6748 - val_accuracy: 0.6207\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6047 - accuracy: 0.6732 - val_loss: 0.7199 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.5977 - accuracy: 0.6683 - val_loss: 0.7078 - val_accuracy: 0.6437\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5847 - accuracy: 0.6850 - val_loss: 0.7879 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.5830 - accuracy: 0.6837 - val_loss: 0.7385 - val_accuracy: 0.6322\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5693 - accuracy: 0.6967 - val_loss: 0.7260 - val_accuracy: 0.6529\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 28us/sample - loss: 0.5702 - accuracy: 0.6972 - val_loss: 0.7139 - val_accuracy: 0.6253\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5574 - accuracy: 0.7118 - val_loss: 0.8356 - val_accuracy: 0.6207\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.5604 - accuracy: 0.7041 - val_loss: 0.8606 - val_accuracy: 0.5862\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.9375 - val_accuracy: 0.6368\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5436 - accuracy: 0.7069 - val_loss: 0.8617 - val_accuracy: 0.6184\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5509 - accuracy: 0.7037 - val_loss: 0.8955 - val_accuracy: 0.5885\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5273 - accuracy: 0.7167 - val_loss: 0.9418 - val_accuracy: 0.5862\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.5268 - accuracy: 0.7187 - val_loss: 0.9561 - val_accuracy: 0.5770\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5320 - accuracy: 0.6996 - val_loss: 0.9604 - val_accuracy: 0.6046\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5152 - accuracy: 0.7199 - val_loss: 1.0755 - val_accuracy: 0.6046\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5025 - accuracy: 0.7276 - val_loss: 1.0472 - val_accuracy: 0.5770\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5549 - accuracy: 0.7069 - val_loss: 1.0599 - val_accuracy: 0.5632\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5072 - accuracy: 0.7236 - val_loss: 1.1914 - val_accuracy: 0.6207\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.4810 - accuracy: 0.7370 - val_loss: 1.2197 - val_accuracy: 0.6069\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5113 - accuracy: 0.7163 - val_loss: 1.0560 - val_accuracy: 0.6230\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5411 - accuracy: 0.7187 - val_loss: 1.1173 - val_accuracy: 0.6276\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4976 - accuracy: 0.7207 - val_loss: 1.1573 - val_accuracy: 0.5977\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5161 - accuracy: 0.7264 - val_loss: 1.1658 - val_accuracy: 0.5839\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4877 - accuracy: 0.7276 - val_loss: 1.2273 - val_accuracy: 0.5609\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4907 - accuracy: 0.7211 - val_loss: 1.4316 - val_accuracy: 0.5701\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5275 - accuracy: 0.7057 - val_loss: 1.2240 - val_accuracy: 0.6322\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.4772 - accuracy: 0.7207 - val_loss: 1.3358 - val_accuracy: 0.6069\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.4969 - accuracy: 0.7179 - val_loss: 1.2629 - val_accuracy: 0.6253\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4852 - accuracy: 0.7211 - val_loss: 1.3815 - val_accuracy: 0.6046\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4584 - accuracy: 0.7293 - val_loss: 1.5483 - val_accuracy: 0.6299\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.4639 - accuracy: 0.7313 - val_loss: 1.7065 - val_accuracy: 0.5977\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4359 - accuracy: 0.7439 - val_loss: 1.6985 - val_accuracy: 0.6207\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4261 - accuracy: 0.7630 - val_loss: 1.8511 - val_accuracy: 0.5747\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4763 - accuracy: 0.7346 - val_loss: 1.5619 - val_accuracy: 0.5586\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.4783 - accuracy: 0.7370 - val_loss: 1.9086 - val_accuracy: 0.6115\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.4623 - accuracy: 0.7150 - val_loss: 1.6541 - val_accuracy: 0.5724\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4486 - accuracy: 0.7244 - val_loss: 1.7299 - val_accuracy: 0.5540\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4205 - accuracy: 0.7398 - val_loss: 1.7650 - val_accuracy: 0.5931\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.4078 - accuracy: 0.7545 - val_loss: 2.1700 - val_accuracy: 0.6023\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4054 - accuracy: 0.7431 - val_loss: 2.1720 - val_accuracy: 0.5724\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.4191 - accuracy: 0.7402 - val_loss: 2.2872 - val_accuracy: 0.5862\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.4192 - accuracy: 0.7439 - val_loss: 2.1461 - val_accuracy: 0.6161\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4336 - accuracy: 0.7541 - val_loss: 1.6120 - val_accuracy: 0.6184\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4306 - accuracy: 0.7346 - val_loss: 2.0430 - val_accuracy: 0.6276\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4057 - accuracy: 0.7569 - val_loss: 2.2601 - val_accuracy: 0.6069\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4180 - accuracy: 0.7435 - val_loss: 1.9396 - val_accuracy: 0.6184\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4297 - accuracy: 0.7354 - val_loss: 2.5069 - val_accuracy: 0.5862\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.4077 - accuracy: 0.7431 - val_loss: 2.1116 - val_accuracy: 0.6230\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.4261 - accuracy: 0.7285 - val_loss: 2.2770 - val_accuracy: 0.5862\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.3785 - accuracy: 0.7626 - val_loss: 2.5201 - val_accuracy: 0.5977\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3957 - accuracy: 0.7476 - val_loss: 2.5350 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3899 - accuracy: 0.7423 - val_loss: 2.2873 - val_accuracy: 0.6207\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.3992 - accuracy: 0.7512 - val_loss: 2.0751 - val_accuracy: 0.6322\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.4021 - accuracy: 0.7496 - val_loss: 2.6360 - val_accuracy: 0.6230\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.3930 - accuracy: 0.7553 - val_loss: 3.0859 - val_accuracy: 0.5931\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.4294 - accuracy: 0.7431 - val_loss: 2.1596 - val_accuracy: 0.6207\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.4287 - accuracy: 0.7378 - val_loss: 2.2739 - val_accuracy: 0.5908\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3685 - accuracy: 0.7736 - val_loss: 2.4505 - val_accuracy: 0.5839\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.3817 - accuracy: 0.7573 - val_loss: 2.7922 - val_accuracy: 0.6023\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.3798 - accuracy: 0.7667 - val_loss: 2.7185 - val_accuracy: 0.6138\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.3956 - accuracy: 0.7528 - val_loss: 2.5923 - val_accuracy: 0.5770\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.4186 - accuracy: 0.7390 - val_loss: 2.4363 - val_accuracy: 0.6069\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 28us/sample - loss: 0.3906 - accuracy: 0.7602 - val_loss: 2.7166 - val_accuracy: 0.5931\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3590 - accuracy: 0.7537 - val_loss: 2.5260 - val_accuracy: 0.6023\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.4022 - accuracy: 0.7463 - val_loss: 2.9066 - val_accuracy: 0.6115\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3701 - accuracy: 0.7654 - val_loss: 3.1774 - val_accuracy: 0.6207\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 28us/sample - loss: 0.3805 - accuracy: 0.7732 - val_loss: 2.9192 - val_accuracy: 0.6161\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.3689 - accuracy: 0.7549 - val_loss: 3.0505 - val_accuracy: 0.6115\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.3768 - accuracy: 0.7634 - val_loss: 3.5030 - val_accuracy: 0.6161\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3827 - accuracy: 0.7740 - val_loss: 3.0607 - val_accuracy: 0.6161\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 30us/sample - loss: 0.3881 - accuracy: 0.7736 - val_loss: 2.6381 - val_accuracy: 0.5747\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 29us/sample - loss: 0.3907 - accuracy: 0.7573 - val_loss: 2.7396 - val_accuracy: 0.5747\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3796 - accuracy: 0.7573 - val_loss: 2.7035 - val_accuracy: 0.6138\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.3528 - accuracy: 0.7715 - val_loss: 3.3033 - val_accuracy: 0.6069\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3673 - accuracy: 0.7715 - val_loss: 2.6686 - val_accuracy: 0.5908\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3729 - accuracy: 0.7589 - val_loss: 3.2240 - val_accuracy: 0.6276\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3763 - accuracy: 0.7720 - val_loss: 2.8315 - val_accuracy: 0.6253\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3679 - accuracy: 0.7695 - val_loss: 3.4558 - val_accuracy: 0.5793\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.3703 - accuracy: 0.7618 - val_loss: 3.0124 - val_accuracy: 0.6230\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3670 - accuracy: 0.7626 - val_loss: 3.1835 - val_accuracy: 0.6276\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3722 - accuracy: 0.7626 - val_loss: 3.0425 - val_accuracy: 0.5885\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.3577 - accuracy: 0.7650 - val_loss: 3.4157 - val_accuracy: 0.6069\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3451 - accuracy: 0.7752 - val_loss: 3.3539 - val_accuracy: 0.6276\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.3508 - accuracy: 0.7854 - val_loss: 3.1873 - val_accuracy: 0.6046\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.3791 - accuracy: 0.7764 - val_loss: 3.3417 - val_accuracy: 0.6253\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.3501 - accuracy: 0.7850 - val_loss: 3.4684 - val_accuracy: 0.6115\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3213 - accuracy: 0.7793 - val_loss: 4.1815 - val_accuracy: 0.6138\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.3667 - accuracy: 0.7598 - val_loss: 3.6108 - val_accuracy: 0.5885\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.3507 - accuracy: 0.7569 - val_loss: 3.6238 - val_accuracy: 0.6299\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3694 - accuracy: 0.7683 - val_loss: 3.8308 - val_accuracy: 0.5885\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3610 - accuracy: 0.7752 - val_loss: 4.3706 - val_accuracy: 0.6069\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3592 - accuracy: 0.7858 - val_loss: 3.3191 - val_accuracy: 0.6391\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3397 - accuracy: 0.7809 - val_loss: 3.9199 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.3324 - accuracy: 0.7817 - val_loss: 4.0586 - val_accuracy: 0.5724\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3359 - accuracy: 0.7862 - val_loss: 4.0096 - val_accuracy: 0.6138\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3356 - accuracy: 0.7732 - val_loss: 3.8447 - val_accuracy: 0.6161\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3375 - accuracy: 0.7854 - val_loss: 4.5039 - val_accuracy: 0.6345\n",
      "2895/2895 [==============================] - 0s 26us/sample - loss: 0.9619 - accuracy: 0.7637\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 245us/sample - loss: 3.4203 - accuracy: 0.1768 - val_loss: 3.3235 - val_accuracy: 0.2391\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.2322 - accuracy: 0.2789 - val_loss: 3.1277 - val_accuracy: 0.3563\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 3.0325 - accuracy: 0.4289 - val_loss: 2.9178 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 2.8171 - accuracy: 0.5293 - val_loss: 2.6911 - val_accuracy: 0.5149\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 2.5848 - accuracy: 0.5520 - val_loss: 2.4487 - val_accuracy: 0.5287\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 2.3408 - accuracy: 0.5589 - val_loss: 2.1998 - val_accuracy: 0.5287\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 2.0959 - accuracy: 0.5630 - val_loss: 1.9580 - val_accuracy: 0.5379\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 1.8636 - accuracy: 0.5675 - val_loss: 1.7362 - val_accuracy: 0.5402\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 1.6540 - accuracy: 0.5744 - val_loss: 1.5421 - val_accuracy: 0.5425\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 1.4728 - accuracy: 0.5768 - val_loss: 1.3787 - val_accuracy: 0.5517\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 1.3210 - accuracy: 0.5801 - val_loss: 1.2440 - val_accuracy: 0.5517\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 1.1959 - accuracy: 0.5927 - val_loss: 1.1347 - val_accuracy: 0.5586\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 1.0941 - accuracy: 0.6077 - val_loss: 1.0467 - val_accuracy: 0.5816\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 1.0120 - accuracy: 0.6102 - val_loss: 0.9762 - val_accuracy: 0.5839\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.9461 - accuracy: 0.6154 - val_loss: 0.9198 - val_accuracy: 0.5977\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.8929 - accuracy: 0.6252 - val_loss: 0.8745 - val_accuracy: 0.5954\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.8501 - accuracy: 0.6317 - val_loss: 0.8380 - val_accuracy: 0.6069\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.8153 - accuracy: 0.6382 - val_loss: 0.8084 - val_accuracy: 0.6115\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.7869 - accuracy: 0.6447 - val_loss: 0.7841 - val_accuracy: 0.6161\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.7633 - accuracy: 0.6488 - val_loss: 0.7641 - val_accuracy: 0.6138\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7436 - accuracy: 0.6573 - val_loss: 0.7472 - val_accuracy: 0.6092\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.7269 - accuracy: 0.6638 - val_loss: 0.7330 - val_accuracy: 0.6092\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.7126 - accuracy: 0.6650 - val_loss: 0.7208 - val_accuracy: 0.6184\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.7003 - accuracy: 0.6695 - val_loss: 0.7103 - val_accuracy: 0.6184\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.6895 - accuracy: 0.6703 - val_loss: 0.7011 - val_accuracy: 0.6276\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6798 - accuracy: 0.6797 - val_loss: 0.6930 - val_accuracy: 0.6322\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6714 - accuracy: 0.6797 - val_loss: 0.6859 - val_accuracy: 0.6299\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6638 - accuracy: 0.6862 - val_loss: 0.6795 - val_accuracy: 0.6322\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.6569 - accuracy: 0.6829 - val_loss: 0.6738 - val_accuracy: 0.6414\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.6507 - accuracy: 0.6858 - val_loss: 0.6687 - val_accuracy: 0.6437\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6450 - accuracy: 0.6878 - val_loss: 0.6639 - val_accuracy: 0.6437\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.6397 - accuracy: 0.6898 - val_loss: 0.6597 - val_accuracy: 0.6460\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.6348 - accuracy: 0.6927 - val_loss: 0.6558 - val_accuracy: 0.6506\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 0.6304 - accuracy: 0.6939 - val_loss: 0.6523 - val_accuracy: 0.6506\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.6262 - accuracy: 0.6951 - val_loss: 0.6489 - val_accuracy: 0.6552\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.6224 - accuracy: 0.6959 - val_loss: 0.6460 - val_accuracy: 0.6575\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.6189 - accuracy: 0.6947 - val_loss: 0.6432 - val_accuracy: 0.6621\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6154 - accuracy: 0.6959 - val_loss: 0.6406 - val_accuracy: 0.6598\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6122 - accuracy: 0.6976 - val_loss: 0.6382 - val_accuracy: 0.6552\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6093 - accuracy: 0.6959 - val_loss: 0.6361 - val_accuracy: 0.6621\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.6065 - accuracy: 0.6951 - val_loss: 0.6341 - val_accuracy: 0.6575\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6038 - accuracy: 0.7016 - val_loss: 0.6322 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.6015 - accuracy: 0.6972 - val_loss: 0.6305 - val_accuracy: 0.6621\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5992 - accuracy: 0.6984 - val_loss: 0.6288 - val_accuracy: 0.6529\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5971 - accuracy: 0.7020 - val_loss: 0.6275 - val_accuracy: 0.6644\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5951 - accuracy: 0.7020 - val_loss: 0.6260 - val_accuracy: 0.6621\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5931 - accuracy: 0.6992 - val_loss: 0.6248 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5913 - accuracy: 0.7053 - val_loss: 0.6236 - val_accuracy: 0.6713\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5897 - accuracy: 0.7049 - val_loss: 0.6224 - val_accuracy: 0.6713\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5880 - accuracy: 0.7037 - val_loss: 0.6216 - val_accuracy: 0.6736\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5865 - accuracy: 0.7037 - val_loss: 0.6208 - val_accuracy: 0.6782\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5851 - accuracy: 0.7073 - val_loss: 0.6199 - val_accuracy: 0.6805\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5839 - accuracy: 0.7065 - val_loss: 0.6191 - val_accuracy: 0.6805\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5825 - accuracy: 0.7093 - val_loss: 0.6183 - val_accuracy: 0.6759\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.5812 - accuracy: 0.7069 - val_loss: 0.6178 - val_accuracy: 0.6805\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5803 - accuracy: 0.7045 - val_loss: 0.6171 - val_accuracy: 0.6736\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5791 - accuracy: 0.7081 - val_loss: 0.6166 - val_accuracy: 0.6736\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5781 - accuracy: 0.7073 - val_loss: 0.6162 - val_accuracy: 0.6690\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5771 - accuracy: 0.7077 - val_loss: 0.6156 - val_accuracy: 0.6713\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5762 - accuracy: 0.7077 - val_loss: 0.6154 - val_accuracy: 0.6759\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5753 - accuracy: 0.7065 - val_loss: 0.6151 - val_accuracy: 0.6759\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5744 - accuracy: 0.7093 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5737 - accuracy: 0.7085 - val_loss: 0.6143 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5729 - accuracy: 0.7073 - val_loss: 0.6143 - val_accuracy: 0.6782\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5721 - accuracy: 0.7081 - val_loss: 0.6141 - val_accuracy: 0.6759\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5716 - accuracy: 0.7085 - val_loss: 0.6137 - val_accuracy: 0.6713\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5708 - accuracy: 0.7098 - val_loss: 0.6136 - val_accuracy: 0.6713\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5701 - accuracy: 0.7134 - val_loss: 0.6133 - val_accuracy: 0.6690\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5696 - accuracy: 0.7093 - val_loss: 0.6132 - val_accuracy: 0.6690\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5690 - accuracy: 0.7081 - val_loss: 0.6132 - val_accuracy: 0.6690\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5684 - accuracy: 0.7114 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5679 - accuracy: 0.7122 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5674 - accuracy: 0.7118 - val_loss: 0.6128 - val_accuracy: 0.6690\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5670 - accuracy: 0.7110 - val_loss: 0.6128 - val_accuracy: 0.6690\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5663 - accuracy: 0.7134 - val_loss: 0.6127 - val_accuracy: 0.6644\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5659 - accuracy: 0.7102 - val_loss: 0.6126 - val_accuracy: 0.6621\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5653 - accuracy: 0.7142 - val_loss: 0.6127 - val_accuracy: 0.6644\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5649 - accuracy: 0.7122 - val_loss: 0.6126 - val_accuracy: 0.6598\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5646 - accuracy: 0.7126 - val_loss: 0.6126 - val_accuracy: 0.6598\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5641 - accuracy: 0.7118 - val_loss: 0.6125 - val_accuracy: 0.6529\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5635 - accuracy: 0.7126 - val_loss: 0.6126 - val_accuracy: 0.6575\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5633 - accuracy: 0.7118 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5630 - accuracy: 0.7114 - val_loss: 0.6125 - val_accuracy: 0.6598\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5625 - accuracy: 0.7114 - val_loss: 0.6128 - val_accuracy: 0.6598\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5622 - accuracy: 0.7118 - val_loss: 0.6128 - val_accuracy: 0.6644\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.5618 - accuracy: 0.7167 - val_loss: 0.6128 - val_accuracy: 0.6575\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5614 - accuracy: 0.7114 - val_loss: 0.6128 - val_accuracy: 0.6575\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5612 - accuracy: 0.7122 - val_loss: 0.6129 - val_accuracy: 0.6598\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5608 - accuracy: 0.7098 - val_loss: 0.6128 - val_accuracy: 0.6529\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.5603 - accuracy: 0.7150 - val_loss: 0.6128 - val_accuracy: 0.6506\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5601 - accuracy: 0.7150 - val_loss: 0.6131 - val_accuracy: 0.6598\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5596 - accuracy: 0.7110 - val_loss: 0.6130 - val_accuracy: 0.6552\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.5593 - accuracy: 0.7134 - val_loss: 0.6132 - val_accuracy: 0.6598\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5589 - accuracy: 0.7142 - val_loss: 0.6134 - val_accuracy: 0.6598\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5588 - accuracy: 0.7142 - val_loss: 0.6133 - val_accuracy: 0.6506\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5584 - accuracy: 0.7114 - val_loss: 0.6133 - val_accuracy: 0.6552\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5581 - accuracy: 0.7138 - val_loss: 0.6133 - val_accuracy: 0.6575\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5578 - accuracy: 0.7171 - val_loss: 0.6135 - val_accuracy: 0.6598\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5575 - accuracy: 0.7138 - val_loss: 0.6135 - val_accuracy: 0.6598\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5571 - accuracy: 0.7134 - val_loss: 0.6138 - val_accuracy: 0.6598\n",
      "2895/2895 [==============================] - 0s 54us/sample - loss: 0.5647 - accuracy: 0.7060\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 184us/sample - loss: 2.7336 - accuracy: 0.3935 - val_loss: 1.6307 - val_accuracy: 0.5471\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 1.0945 - accuracy: 0.5809 - val_loss: 0.8106 - val_accuracy: 0.5770\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.7237 - accuracy: 0.6244 - val_loss: 0.6902 - val_accuracy: 0.6184\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 0.6499 - accuracy: 0.6683 - val_loss: 0.6475 - val_accuracy: 0.6437\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.6168 - accuracy: 0.6907 - val_loss: 0.6276 - val_accuracy: 0.6506\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5978 - accuracy: 0.7008 - val_loss: 0.6189 - val_accuracy: 0.6736\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5882 - accuracy: 0.6992 - val_loss: 0.6105 - val_accuracy: 0.6552\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5798 - accuracy: 0.6947 - val_loss: 0.6129 - val_accuracy: 0.6644\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5771 - accuracy: 0.7024 - val_loss: 0.6054 - val_accuracy: 0.6690\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 37us/sample - loss: 0.5722 - accuracy: 0.7089 - val_loss: 0.6065 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5687 - accuracy: 0.7000 - val_loss: 0.6066 - val_accuracy: 0.6483\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5663 - accuracy: 0.7065 - val_loss: 0.6063 - val_accuracy: 0.6644\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5633 - accuracy: 0.7057 - val_loss: 0.6122 - val_accuracy: 0.6805\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5610 - accuracy: 0.7106 - val_loss: 0.6079 - val_accuracy: 0.6598\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5585 - accuracy: 0.7122 - val_loss: 0.6078 - val_accuracy: 0.6575\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5564 - accuracy: 0.7114 - val_loss: 0.6122 - val_accuracy: 0.6713\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5531 - accuracy: 0.7163 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5513 - accuracy: 0.7154 - val_loss: 0.6093 - val_accuracy: 0.6621\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5485 - accuracy: 0.7142 - val_loss: 0.6089 - val_accuracy: 0.6621\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 0.5455 - accuracy: 0.7236 - val_loss: 0.6120 - val_accuracy: 0.6759\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5437 - accuracy: 0.7232 - val_loss: 0.6136 - val_accuracy: 0.6759\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5406 - accuracy: 0.7236 - val_loss: 0.6168 - val_accuracy: 0.6805\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5374 - accuracy: 0.7256 - val_loss: 0.6152 - val_accuracy: 0.6598\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5349 - accuracy: 0.7256 - val_loss: 0.6171 - val_accuracy: 0.6529\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5306 - accuracy: 0.7276 - val_loss: 0.6187 - val_accuracy: 0.6690\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5285 - accuracy: 0.7329 - val_loss: 0.6157 - val_accuracy: 0.6644\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5245 - accuracy: 0.7386 - val_loss: 0.6155 - val_accuracy: 0.6621\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5203 - accuracy: 0.7423 - val_loss: 0.6252 - val_accuracy: 0.6897\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5187 - accuracy: 0.7402 - val_loss: 0.6182 - val_accuracy: 0.6690\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.5143 - accuracy: 0.7394 - val_loss: 0.6275 - val_accuracy: 0.6782\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5109 - accuracy: 0.7435 - val_loss: 0.6231 - val_accuracy: 0.6552\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5071 - accuracy: 0.7451 - val_loss: 0.6271 - val_accuracy: 0.6506\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 138us/sample - loss: 0.5035 - accuracy: 0.7516 - val_loss: 0.6265 - val_accuracy: 0.6598\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4995 - accuracy: 0.7512 - val_loss: 0.6280 - val_accuracy: 0.6690\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4957 - accuracy: 0.7516 - val_loss: 0.6336 - val_accuracy: 0.6690\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4917 - accuracy: 0.7626 - val_loss: 0.6340 - val_accuracy: 0.6690\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4889 - accuracy: 0.7553 - val_loss: 0.6346 - val_accuracy: 0.6690\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.4847 - accuracy: 0.7638 - val_loss: 0.6358 - val_accuracy: 0.6644\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.4806 - accuracy: 0.7679 - val_loss: 0.6497 - val_accuracy: 0.6460\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.4788 - accuracy: 0.7610 - val_loss: 0.6430 - val_accuracy: 0.6575\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4743 - accuracy: 0.7687 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4707 - accuracy: 0.7772 - val_loss: 0.6455 - val_accuracy: 0.6644\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4674 - accuracy: 0.7736 - val_loss: 0.6471 - val_accuracy: 0.6598\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4635 - accuracy: 0.7797 - val_loss: 0.6490 - val_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.4595 - accuracy: 0.7805 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.6584 - val_accuracy: 0.6598\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4543 - accuracy: 0.7805 - val_loss: 0.6600 - val_accuracy: 0.6552\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4510 - accuracy: 0.7886 - val_loss: 0.6606 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4485 - accuracy: 0.7837 - val_loss: 0.6619 - val_accuracy: 0.6552\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4454 - accuracy: 0.7854 - val_loss: 0.6649 - val_accuracy: 0.6575\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4425 - accuracy: 0.7894 - val_loss: 0.6695 - val_accuracy: 0.6483\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4397 - accuracy: 0.7862 - val_loss: 0.6672 - val_accuracy: 0.6506\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.4365 - accuracy: 0.7931 - val_loss: 0.6731 - val_accuracy: 0.6529\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4331 - accuracy: 0.7963 - val_loss: 0.6768 - val_accuracy: 0.6391\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4307 - accuracy: 0.7967 - val_loss: 0.6828 - val_accuracy: 0.6460\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.4279 - accuracy: 0.8073 - val_loss: 0.6821 - val_accuracy: 0.6460\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4255 - accuracy: 0.8012 - val_loss: 0.6843 - val_accuracy: 0.6437\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.4228 - accuracy: 0.8004 - val_loss: 0.6842 - val_accuracy: 0.6552\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.4196 - accuracy: 0.8057 - val_loss: 0.6865 - val_accuracy: 0.6598\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4180 - accuracy: 0.8024 - val_loss: 0.6905 - val_accuracy: 0.6598\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4148 - accuracy: 0.8098 - val_loss: 0.6971 - val_accuracy: 0.6368\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.4118 - accuracy: 0.8110 - val_loss: 0.7007 - val_accuracy: 0.6414\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.4105 - accuracy: 0.8089 - val_loss: 0.6967 - val_accuracy: 0.6621\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4066 - accuracy: 0.8081 - val_loss: 0.7016 - val_accuracy: 0.6575\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.7058 - val_accuracy: 0.6483\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.4027 - accuracy: 0.8187 - val_loss: 0.7113 - val_accuracy: 0.6460\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.3996 - accuracy: 0.8110 - val_loss: 0.7122 - val_accuracy: 0.6483\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3971 - accuracy: 0.8114 - val_loss: 0.7159 - val_accuracy: 0.6437\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.3953 - accuracy: 0.8150 - val_loss: 0.7215 - val_accuracy: 0.6391\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.3936 - accuracy: 0.8199 - val_loss: 0.7187 - val_accuracy: 0.6575\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.3912 - accuracy: 0.8215 - val_loss: 0.7200 - val_accuracy: 0.6460\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.3889 - accuracy: 0.8268 - val_loss: 0.7218 - val_accuracy: 0.6506\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.3868 - accuracy: 0.8244 - val_loss: 0.7274 - val_accuracy: 0.6437\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3848 - accuracy: 0.8240 - val_loss: 0.7265 - val_accuracy: 0.6529\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.3816 - accuracy: 0.8313 - val_loss: 0.7325 - val_accuracy: 0.6391\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3803 - accuracy: 0.8289 - val_loss: 0.7335 - val_accuracy: 0.6460\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3771 - accuracy: 0.8309 - val_loss: 0.7424 - val_accuracy: 0.6322\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3767 - accuracy: 0.8321 - val_loss: 0.7382 - val_accuracy: 0.6391\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.3742 - accuracy: 0.8346 - val_loss: 0.7422 - val_accuracy: 0.6345\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3730 - accuracy: 0.8358 - val_loss: 0.7471 - val_accuracy: 0.6414\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3705 - accuracy: 0.8285 - val_loss: 0.7502 - val_accuracy: 0.6460\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3684 - accuracy: 0.8451 - val_loss: 0.7577 - val_accuracy: 0.6299\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.3663 - accuracy: 0.8427 - val_loss: 0.7501 - val_accuracy: 0.6460\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.3637 - accuracy: 0.8402 - val_loss: 0.7556 - val_accuracy: 0.6552\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3625 - accuracy: 0.8370 - val_loss: 0.7550 - val_accuracy: 0.6391\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.3596 - accuracy: 0.8394 - val_loss: 0.7626 - val_accuracy: 0.6391\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.3577 - accuracy: 0.8463 - val_loss: 0.7623 - val_accuracy: 0.6391\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.3566 - accuracy: 0.8439 - val_loss: 0.7681 - val_accuracy: 0.6414\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3561 - accuracy: 0.8443 - val_loss: 0.7690 - val_accuracy: 0.6460\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.3529 - accuracy: 0.8480 - val_loss: 0.7722 - val_accuracy: 0.6506\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3506 - accuracy: 0.8488 - val_loss: 0.7773 - val_accuracy: 0.6322\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3499 - accuracy: 0.8484 - val_loss: 0.7737 - val_accuracy: 0.6345\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3460 - accuracy: 0.8480 - val_loss: 0.7788 - val_accuracy: 0.6460\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3435 - accuracy: 0.8549 - val_loss: 0.7815 - val_accuracy: 0.6437\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3431 - accuracy: 0.8565 - val_loss: 0.7863 - val_accuracy: 0.6322\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.3411 - accuracy: 0.8561 - val_loss: 0.7867 - val_accuracy: 0.6437\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3408 - accuracy: 0.8545 - val_loss: 0.7878 - val_accuracy: 0.6345\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.3377 - accuracy: 0.8618 - val_loss: 0.7942 - val_accuracy: 0.6437\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.3365 - accuracy: 0.8549 - val_loss: 0.7913 - val_accuracy: 0.6391\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.3342 - accuracy: 0.8618 - val_loss: 0.7966 - val_accuracy: 0.6345\n",
      "2895/2895 [==============================] - 0s 62us/sample - loss: 0.3913 - accuracy: 0.8415\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 217us/sample - loss: 0.9214 - accuracy: 0.6049 - val_loss: 0.6088 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.6045 - accuracy: 0.6785 - val_loss: 0.6090 - val_accuracy: 0.6759\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5918 - accuracy: 0.6772 - val_loss: 0.6485 - val_accuracy: 0.6529\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5766 - accuracy: 0.6833 - val_loss: 0.6242 - val_accuracy: 0.6598\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5667 - accuracy: 0.6963 - val_loss: 0.6311 - val_accuracy: 0.6483\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5551 - accuracy: 0.7093 - val_loss: 0.6559 - val_accuracy: 0.6391\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5408 - accuracy: 0.7211 - val_loss: 0.6489 - val_accuracy: 0.6575\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5300 - accuracy: 0.7321 - val_loss: 0.6582 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5118 - accuracy: 0.7378 - val_loss: 0.6777 - val_accuracy: 0.6575\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4998 - accuracy: 0.7508 - val_loss: 0.6868 - val_accuracy: 0.6391\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.4891 - accuracy: 0.7610 - val_loss: 0.7190 - val_accuracy: 0.6184\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.4774 - accuracy: 0.7577 - val_loss: 0.7220 - val_accuracy: 0.6230\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4587 - accuracy: 0.7748 - val_loss: 0.7904 - val_accuracy: 0.6207\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4526 - accuracy: 0.7756 - val_loss: 0.7658 - val_accuracy: 0.6529\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4452 - accuracy: 0.7813 - val_loss: 0.7809 - val_accuracy: 0.6414\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.4282 - accuracy: 0.7935 - val_loss: 0.8331 - val_accuracy: 0.6092\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.4209 - accuracy: 0.7939 - val_loss: 0.8602 - val_accuracy: 0.6092\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4065 - accuracy: 0.8057 - val_loss: 0.8964 - val_accuracy: 0.6437\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.4004 - accuracy: 0.8122 - val_loss: 0.9098 - val_accuracy: 0.6092\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.3949 - accuracy: 0.8150 - val_loss: 0.9391 - val_accuracy: 0.6138\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.3818 - accuracy: 0.8122 - val_loss: 0.9485 - val_accuracy: 0.6023\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.3761 - accuracy: 0.8228 - val_loss: 0.9571 - val_accuracy: 0.6207\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.3707 - accuracy: 0.8220 - val_loss: 0.9918 - val_accuracy: 0.5747\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.3647 - accuracy: 0.8256 - val_loss: 0.9980 - val_accuracy: 0.6115\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3481 - accuracy: 0.8358 - val_loss: 1.0272 - val_accuracy: 0.6391\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.3436 - accuracy: 0.8447 - val_loss: 1.0525 - val_accuracy: 0.5954\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3444 - accuracy: 0.8431 - val_loss: 1.1567 - val_accuracy: 0.6138\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.3367 - accuracy: 0.8427 - val_loss: 1.0945 - val_accuracy: 0.6276\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3244 - accuracy: 0.8496 - val_loss: 1.1281 - val_accuracy: 0.6023\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3285 - accuracy: 0.8553 - val_loss: 1.1260 - val_accuracy: 0.6230\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.3145 - accuracy: 0.8537 - val_loss: 1.1788 - val_accuracy: 0.6046\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.3152 - accuracy: 0.8593 - val_loss: 1.2311 - val_accuracy: 0.6115\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.3052 - accuracy: 0.8630 - val_loss: 1.2201 - val_accuracy: 0.6184\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.2971 - accuracy: 0.8671 - val_loss: 1.2074 - val_accuracy: 0.6345\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.2917 - accuracy: 0.8663 - val_loss: 1.2641 - val_accuracy: 0.6046\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.2852 - accuracy: 0.8695 - val_loss: 1.3031 - val_accuracy: 0.6253\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.2835 - accuracy: 0.8699 - val_loss: 1.3269 - val_accuracy: 0.6069\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.2821 - accuracy: 0.8789 - val_loss: 1.3343 - val_accuracy: 0.5908\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.2700 - accuracy: 0.8805 - val_loss: 1.3680 - val_accuracy: 0.6230\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 0.2712 - accuracy: 0.8785 - val_loss: 1.3558 - val_accuracy: 0.6299\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.2650 - accuracy: 0.8878 - val_loss: 1.3754 - val_accuracy: 0.6368\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.2592 - accuracy: 0.8841 - val_loss: 1.3935 - val_accuracy: 0.6345\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.2538 - accuracy: 0.8841 - val_loss: 1.4578 - val_accuracy: 0.6184\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.2560 - accuracy: 0.8923 - val_loss: 1.4168 - val_accuracy: 0.6092\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.2453 - accuracy: 0.8947 - val_loss: 1.5016 - val_accuracy: 0.6276\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.2335 - accuracy: 0.8963 - val_loss: 1.5194 - val_accuracy: 0.6092\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.2289 - accuracy: 0.8996 - val_loss: 1.5209 - val_accuracy: 0.6207\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.2263 - accuracy: 0.8996 - val_loss: 1.5299 - val_accuracy: 0.6299\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.2252 - accuracy: 0.9000 - val_loss: 1.5860 - val_accuracy: 0.6161\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.2181 - accuracy: 0.9118 - val_loss: 1.6147 - val_accuracy: 0.6230\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.2167 - accuracy: 0.9069 - val_loss: 1.6214 - val_accuracy: 0.6207\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.2124 - accuracy: 0.9089 - val_loss: 1.6339 - val_accuracy: 0.6299\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.2090 - accuracy: 0.9114 - val_loss: 1.6481 - val_accuracy: 0.6368\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.2171 - accuracy: 0.9077 - val_loss: 1.6745 - val_accuracy: 0.6230\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.2007 - accuracy: 0.9179 - val_loss: 1.7173 - val_accuracy: 0.6253\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.2007 - accuracy: 0.9130 - val_loss: 1.7224 - val_accuracy: 0.6207\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.1936 - accuracy: 0.9199 - val_loss: 1.7017 - val_accuracy: 0.6414\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.1904 - accuracy: 0.9220 - val_loss: 1.7398 - val_accuracy: 0.6276\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.1944 - accuracy: 0.9154 - val_loss: 1.7399 - val_accuracy: 0.6230\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.1821 - accuracy: 0.9264 - val_loss: 1.7860 - val_accuracy: 0.6138\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.1866 - accuracy: 0.9256 - val_loss: 1.8524 - val_accuracy: 0.5862\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.1760 - accuracy: 0.9317 - val_loss: 1.8656 - val_accuracy: 0.6046\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.1758 - accuracy: 0.9321 - val_loss: 1.8261 - val_accuracy: 0.6046\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.1655 - accuracy: 0.9309 - val_loss: 1.9786 - val_accuracy: 0.5977\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.1744 - accuracy: 0.9268 - val_loss: 1.9369 - val_accuracy: 0.5977\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1709 - accuracy: 0.9276 - val_loss: 1.9384 - val_accuracy: 0.6023\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.1664 - accuracy: 0.9325 - val_loss: 1.9189 - val_accuracy: 0.6069\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.1644 - accuracy: 0.9293 - val_loss: 1.9756 - val_accuracy: 0.6322\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.1709 - accuracy: 0.9297 - val_loss: 2.0313 - val_accuracy: 0.5908\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.1699 - accuracy: 0.9309 - val_loss: 2.0335 - val_accuracy: 0.6092\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.1472 - accuracy: 0.9419 - val_loss: 2.0858 - val_accuracy: 0.6069\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.1555 - accuracy: 0.9358 - val_loss: 2.0374 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.1494 - accuracy: 0.9419 - val_loss: 2.0608 - val_accuracy: 0.5954\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.1469 - accuracy: 0.9427 - val_loss: 2.0594 - val_accuracy: 0.6276\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.1486 - accuracy: 0.9402 - val_loss: 2.1792 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.1404 - accuracy: 0.9402 - val_loss: 2.1647 - val_accuracy: 0.6184\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.1483 - accuracy: 0.9423 - val_loss: 2.1537 - val_accuracy: 0.6138\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.1516 - accuracy: 0.9386 - val_loss: 2.1970 - val_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 108us/sample - loss: 0.1414 - accuracy: 0.9427 - val_loss: 2.2288 - val_accuracy: 0.5931\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.1364 - accuracy: 0.9451 - val_loss: 2.1937 - val_accuracy: 0.6092\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.1446 - accuracy: 0.9390 - val_loss: 2.2494 - val_accuracy: 0.5931\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.1416 - accuracy: 0.9407 - val_loss: 2.3160 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.1403 - accuracy: 0.9427 - val_loss: 2.3467 - val_accuracy: 0.6046\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.1280 - accuracy: 0.9512 - val_loss: 2.2823 - val_accuracy: 0.5839\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.1368 - accuracy: 0.9459 - val_loss: 2.2975 - val_accuracy: 0.6046\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.1344 - accuracy: 0.9455 - val_loss: 2.3571 - val_accuracy: 0.6069\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.1330 - accuracy: 0.9431 - val_loss: 2.3635 - val_accuracy: 0.6092\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.1345 - accuracy: 0.9459 - val_loss: 2.3571 - val_accuracy: 0.6092\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.1376 - accuracy: 0.9451 - val_loss: 2.4109 - val_accuracy: 0.5954\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.1283 - accuracy: 0.9467 - val_loss: 2.4667 - val_accuracy: 0.6092\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.1315 - accuracy: 0.9496 - val_loss: 2.3609 - val_accuracy: 0.6092\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.1212 - accuracy: 0.9549 - val_loss: 2.4756 - val_accuracy: 0.5977\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.1202 - accuracy: 0.9533 - val_loss: 2.4335 - val_accuracy: 0.5885\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.1236 - accuracy: 0.9496 - val_loss: 2.4702 - val_accuracy: 0.5862\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.1211 - accuracy: 0.9553 - val_loss: 2.5086 - val_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.1203 - accuracy: 0.9565 - val_loss: 2.5374 - val_accuracy: 0.5954\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.1203 - accuracy: 0.9516 - val_loss: 2.5247 - val_accuracy: 0.5977\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.1165 - accuracy: 0.9565 - val_loss: 2.5255 - val_accuracy: 0.6069\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.1115 - accuracy: 0.9610 - val_loss: 2.6175 - val_accuracy: 0.5747\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.1117 - accuracy: 0.9589 - val_loss: 2.5868 - val_accuracy: 0.5954\n",
      "2895/2895 [==============================] - 0s 25us/sample - loss: 0.4596 - accuracy: 0.9116\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 189us/sample - loss: 0.7971 - accuracy: 0.5935 - val_loss: 0.7821 - val_accuracy: 0.5977\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.6894 - accuracy: 0.6411 - val_loss: 0.7361 - val_accuracy: 0.6069\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.6576 - accuracy: 0.6659 - val_loss: 0.7280 - val_accuracy: 0.5885\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6396 - accuracy: 0.6593 - val_loss: 0.7801 - val_accuracy: 0.5678\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.6240 - accuracy: 0.6748 - val_loss: 0.7147 - val_accuracy: 0.6092\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5992 - accuracy: 0.6915 - val_loss: 0.7405 - val_accuracy: 0.5954\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.6097 - accuracy: 0.6874 - val_loss: 0.7687 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 34us/sample - loss: 0.5727 - accuracy: 0.7016 - val_loss: 0.7595 - val_accuracy: 0.6092\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5735 - accuracy: 0.7150 - val_loss: 0.7633 - val_accuracy: 0.6276\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.5540 - accuracy: 0.7093 - val_loss: 0.7809 - val_accuracy: 0.6161\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.5445 - accuracy: 0.7244 - val_loss: 0.8790 - val_accuracy: 0.6345\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5346 - accuracy: 0.7305 - val_loss: 0.7707 - val_accuracy: 0.6184\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5166 - accuracy: 0.7398 - val_loss: 0.8590 - val_accuracy: 0.6253\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 35us/sample - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.8673 - val_accuracy: 0.6345\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5133 - accuracy: 0.7484 - val_loss: 0.9573 - val_accuracy: 0.6138\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4970 - accuracy: 0.7492 - val_loss: 0.9779 - val_accuracy: 0.6253\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.4869 - accuracy: 0.7553 - val_loss: 0.8774 - val_accuracy: 0.5839\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.4783 - accuracy: 0.7435 - val_loss: 1.0175 - val_accuracy: 0.6345\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4697 - accuracy: 0.7533 - val_loss: 1.1203 - val_accuracy: 0.6460\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.4785 - accuracy: 0.7545 - val_loss: 1.0937 - val_accuracy: 0.6253\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.4498 - accuracy: 0.7545 - val_loss: 0.9172 - val_accuracy: 0.5977\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4474 - accuracy: 0.7581 - val_loss: 1.1161 - val_accuracy: 0.6322\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4560 - accuracy: 0.7699 - val_loss: 1.0303 - val_accuracy: 0.6207\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.4393 - accuracy: 0.7618 - val_loss: 1.2191 - val_accuracy: 0.6230\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.4275 - accuracy: 0.7715 - val_loss: 1.2512 - val_accuracy: 0.6253\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.4329 - accuracy: 0.7585 - val_loss: 1.3042 - val_accuracy: 0.6322\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4190 - accuracy: 0.7642 - val_loss: 1.4142 - val_accuracy: 0.6023\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.4278 - accuracy: 0.7634 - val_loss: 1.5716 - val_accuracy: 0.6023\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4185 - accuracy: 0.7687 - val_loss: 1.3746 - val_accuracy: 0.6345\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.4094 - accuracy: 0.7785 - val_loss: 1.4594 - val_accuracy: 0.6138\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4147 - accuracy: 0.7715 - val_loss: 1.3381 - val_accuracy: 0.6023\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.4176 - accuracy: 0.7630 - val_loss: 1.5355 - val_accuracy: 0.6345\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4196 - accuracy: 0.7650 - val_loss: 1.5974 - val_accuracy: 0.5908\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4094 - accuracy: 0.7801 - val_loss: 1.6247 - val_accuracy: 0.5954\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.3996 - accuracy: 0.7606 - val_loss: 1.6049 - val_accuracy: 0.5839\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4016 - accuracy: 0.7577 - val_loss: 1.6816 - val_accuracy: 0.6092\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.4052 - accuracy: 0.7728 - val_loss: 1.5273 - val_accuracy: 0.6207\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.3743 - accuracy: 0.7817 - val_loss: 1.8961 - val_accuracy: 0.6138\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.3667 - accuracy: 0.7862 - val_loss: 1.9759 - val_accuracy: 0.5931\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.3900 - accuracy: 0.7772 - val_loss: 1.7177 - val_accuracy: 0.5954\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3705 - accuracy: 0.7768 - val_loss: 2.1820 - val_accuracy: 0.6115\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.3770 - accuracy: 0.7833 - val_loss: 1.7992 - val_accuracy: 0.6069\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3710 - accuracy: 0.7894 - val_loss: 1.8885 - val_accuracy: 0.6437\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3587 - accuracy: 0.7967 - val_loss: 2.1189 - val_accuracy: 0.6184\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3466 - accuracy: 0.7911 - val_loss: 1.9364 - val_accuracy: 0.6138\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3569 - accuracy: 0.7841 - val_loss: 2.1198 - val_accuracy: 0.6207\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.3434 - accuracy: 0.8016 - val_loss: 2.1008 - val_accuracy: 0.6046\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3614 - accuracy: 0.7898 - val_loss: 2.0750 - val_accuracy: 0.6069\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.3362 - accuracy: 0.7870 - val_loss: 2.2311 - val_accuracy: 0.5793\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3668 - accuracy: 0.7984 - val_loss: 1.8732 - val_accuracy: 0.6069\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 124us/sample - loss: 0.3473 - accuracy: 0.7797 - val_loss: 2.1359 - val_accuracy: 0.6092\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3451 - accuracy: 0.8020 - val_loss: 2.4030 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3626 - accuracy: 0.7907 - val_loss: 2.5220 - val_accuracy: 0.6138\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.3588 - accuracy: 0.7862 - val_loss: 2.0806 - val_accuracy: 0.6115\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.3569 - accuracy: 0.7833 - val_loss: 2.3306 - val_accuracy: 0.6276\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3438 - accuracy: 0.7915 - val_loss: 2.6077 - val_accuracy: 0.6230\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.3246 - accuracy: 0.7996 - val_loss: 2.9028 - val_accuracy: 0.5931\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3821 - accuracy: 0.7772 - val_loss: 2.7820 - val_accuracy: 0.6069\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.3542 - accuracy: 0.7874 - val_loss: 2.3619 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3393 - accuracy: 0.8000 - val_loss: 2.5453 - val_accuracy: 0.6138\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.3360 - accuracy: 0.7943 - val_loss: 3.1398 - val_accuracy: 0.6023\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.3470 - accuracy: 0.8024 - val_loss: 2.8626 - val_accuracy: 0.6115\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.3365 - accuracy: 0.7951 - val_loss: 2.4362 - val_accuracy: 0.6230\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.3254 - accuracy: 0.7927 - val_loss: 2.8341 - val_accuracy: 0.6207\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 123us/sample - loss: 0.3124 - accuracy: 0.8037 - val_loss: 2.9472 - val_accuracy: 0.6184\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.3598 - accuracy: 0.7833 - val_loss: 2.6355 - val_accuracy: 0.6161\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.3356 - accuracy: 0.7829 - val_loss: 2.7356 - val_accuracy: 0.6069\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.3245 - accuracy: 0.7951 - val_loss: 3.2606 - val_accuracy: 0.6046\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.3376 - accuracy: 0.7780 - val_loss: 3.1992 - val_accuracy: 0.5885\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.3377 - accuracy: 0.7825 - val_loss: 3.2290 - val_accuracy: 0.6069\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.3355 - accuracy: 0.7902 - val_loss: 3.0671 - val_accuracy: 0.6138\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.3380 - accuracy: 0.7837 - val_loss: 3.3401 - val_accuracy: 0.6253\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.3370 - accuracy: 0.7919 - val_loss: 3.0777 - val_accuracy: 0.5816\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3548 - accuracy: 0.7817 - val_loss: 3.4574 - val_accuracy: 0.5931\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.3759 - accuracy: 0.7862 - val_loss: 2.8732 - val_accuracy: 0.6092\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 0.3892 - accuracy: 0.7602 - val_loss: 3.7684 - val_accuracy: 0.5931\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3744 - accuracy: 0.7695 - val_loss: 3.6456 - val_accuracy: 0.6046\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.3665 - accuracy: 0.7780 - val_loss: 3.2353 - val_accuracy: 0.6115\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.3415 - accuracy: 0.7902 - val_loss: 3.5828 - val_accuracy: 0.5977\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.3469 - accuracy: 0.7732 - val_loss: 3.2681 - val_accuracy: 0.5977\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.3484 - accuracy: 0.7732 - val_loss: 3.2444 - val_accuracy: 0.6023\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3320 - accuracy: 0.7846 - val_loss: 3.5277 - val_accuracy: 0.5885\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.3292 - accuracy: 0.7894 - val_loss: 3.6961 - val_accuracy: 0.5724\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.3624 - accuracy: 0.7671 - val_loss: 3.3962 - val_accuracy: 0.6161\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.3424 - accuracy: 0.7939 - val_loss: 4.2682 - val_accuracy: 0.6092\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.3566 - accuracy: 0.7789 - val_loss: 3.8458 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.3489 - accuracy: 0.7793 - val_loss: 3.3276 - val_accuracy: 0.5701\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.3523 - accuracy: 0.7833 - val_loss: 3.3001 - val_accuracy: 0.6276\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.3296 - accuracy: 0.7898 - val_loss: 3.6484 - val_accuracy: 0.5747\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.3370 - accuracy: 0.7967 - val_loss: 3.6213 - val_accuracy: 0.6230\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 0.3406 - accuracy: 0.8008 - val_loss: 3.7252 - val_accuracy: 0.6069\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.3544 - accuracy: 0.7858 - val_loss: 3.8193 - val_accuracy: 0.6184\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.3449 - accuracy: 0.8008 - val_loss: 3.3431 - val_accuracy: 0.6207\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.3247 - accuracy: 0.7963 - val_loss: 3.8255 - val_accuracy: 0.6046\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 0.3429 - accuracy: 0.7764 - val_loss: 3.3404 - val_accuracy: 0.6207\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.3389 - accuracy: 0.7833 - val_loss: 3.5357 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 110us/sample - loss: 0.3147 - accuracy: 0.7935 - val_loss: 3.9063 - val_accuracy: 0.6023\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.3279 - accuracy: 0.7911 - val_loss: 3.8225 - val_accuracy: 0.6069\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.3127 - accuracy: 0.8028 - val_loss: 3.9054 - val_accuracy: 0.6161\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.3183 - accuracy: 0.7890 - val_loss: 4.2659 - val_accuracy: 0.6253\n",
      "2895/2895 [==============================] - 0s 32us/sample - loss: 0.9182 - accuracy: 0.7623\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 221us/sample - loss: 4.7887 - accuracy: 0.5224 - val_loss: 1.6173 - val_accuracy: 0.4598\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.9835 - accuracy: 0.5382 - val_loss: 1.0095 - val_accuracy: 0.4667\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.8799 - accuracy: 0.4976 - val_loss: 0.7674 - val_accuracy: 0.4621\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.7865 - accuracy: 0.5134 - val_loss: 0.7173 - val_accuracy: 0.5356\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.7085 - accuracy: 0.5394 - val_loss: 0.7246 - val_accuracy: 0.4621\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.7477 - accuracy: 0.5089 - val_loss: 0.7716 - val_accuracy: 0.4552\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.7633 - accuracy: 0.4919 - val_loss: 0.8106 - val_accuracy: 0.4598\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.7533 - accuracy: 0.5122 - val_loss: 0.7567 - val_accuracy: 0.5402\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.7318 - accuracy: 0.5114 - val_loss: 0.8044 - val_accuracy: 0.4575\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7452 - accuracy: 0.5024 - val_loss: 0.7213 - val_accuracy: 0.5402\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 117us/sample - loss: 0.7357 - accuracy: 0.5240 - val_loss: 0.9367 - val_accuracy: 0.5402\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.7586 - accuracy: 0.5081 - val_loss: 0.7321 - val_accuracy: 0.4575\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.7115 - accuracy: 0.5191 - val_loss: 0.7148 - val_accuracy: 0.5402\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.7426 - accuracy: 0.5012 - val_loss: 0.7113 - val_accuracy: 0.5379\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.7350 - accuracy: 0.5187 - val_loss: 0.7148 - val_accuracy: 0.4575\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.7392 - accuracy: 0.4996 - val_loss: 0.7121 - val_accuracy: 0.5402\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7327 - accuracy: 0.5089 - val_loss: 0.7126 - val_accuracy: 0.5402\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.7191 - accuracy: 0.5171 - val_loss: 0.9253 - val_accuracy: 0.4575\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 1.4499 - accuracy: 0.5354 - val_loss: 0.7406 - val_accuracy: 0.5425\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.7247 - accuracy: 0.5163 - val_loss: 0.7366 - val_accuracy: 0.5425\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.7098 - accuracy: 0.5228 - val_loss: 0.6904 - val_accuracy: 0.5402\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.7288 - accuracy: 0.5081 - val_loss: 0.6972 - val_accuracy: 0.5425\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.7359 - accuracy: 0.5065 - val_loss: 0.6941 - val_accuracy: 0.4575\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.7262 - accuracy: 0.5171 - val_loss: 0.7189 - val_accuracy: 0.5425\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.7278 - accuracy: 0.5179 - val_loss: 0.7649 - val_accuracy: 0.4575\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.7276 - accuracy: 0.5008 - val_loss: 0.7090 - val_accuracy: 0.5425\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.7168 - accuracy: 0.5244 - val_loss: 0.7053 - val_accuracy: 0.5425\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.7373 - accuracy: 0.4992 - val_loss: 0.6909 - val_accuracy: 0.5425\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.7276 - accuracy: 0.5041 - val_loss: 0.7392 - val_accuracy: 0.4575\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.7217 - accuracy: 0.5106 - val_loss: 0.7023 - val_accuracy: 0.5425\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.7292 - accuracy: 0.5171 - val_loss: 0.7202 - val_accuracy: 0.4575\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7335 - accuracy: 0.5016 - val_loss: 0.7211 - val_accuracy: 0.5425\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.7117 - accuracy: 0.5236 - val_loss: 0.7783 - val_accuracy: 0.4575\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7340 - accuracy: 0.4992 - val_loss: 0.7552 - val_accuracy: 0.4575\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.7377 - accuracy: 0.5098 - val_loss: 0.7763 - val_accuracy: 0.4575\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.7242 - accuracy: 0.4967 - val_loss: 0.6901 - val_accuracy: 0.5402\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.7196 - accuracy: 0.5171 - val_loss: 0.7963 - val_accuracy: 0.4575\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7359 - accuracy: 0.5041 - val_loss: 0.7036 - val_accuracy: 0.5425\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.7251 - accuracy: 0.4984 - val_loss: 0.7084 - val_accuracy: 0.4575\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7275 - accuracy: 0.5000 - val_loss: 0.6903 - val_accuracy: 0.5425\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.7135 - accuracy: 0.5073 - val_loss: 0.6920 - val_accuracy: 0.5402\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.7125 - accuracy: 0.5203 - val_loss: 0.7091 - val_accuracy: 0.5425\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7137 - accuracy: 0.5211 - val_loss: 0.6897 - val_accuracy: 0.5425\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.7171 - accuracy: 0.5179 - val_loss: 0.7156 - val_accuracy: 0.4575\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7362 - accuracy: 0.5041 - val_loss: 0.6958 - val_accuracy: 0.4575\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.7138 - accuracy: 0.5341 - val_loss: 0.7028 - val_accuracy: 0.5425\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.7039 - accuracy: 0.5268 - val_loss: 0.6909 - val_accuracy: 0.5425\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7235 - accuracy: 0.5122 - val_loss: 0.8648 - val_accuracy: 0.4575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.7272 - accuracy: 0.5049 - val_loss: 0.6909 - val_accuracy: 0.5402\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.7145 - accuracy: 0.5130 - val_loss: 0.7724 - val_accuracy: 0.5425\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7139 - accuracy: 0.5114 - val_loss: 0.6965 - val_accuracy: 0.5425\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.7227 - accuracy: 0.4967 - val_loss: 0.7124 - val_accuracy: 0.4575\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.7228 - accuracy: 0.5081 - val_loss: 0.6918 - val_accuracy: 0.5425\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.7096 - accuracy: 0.5187 - val_loss: 0.7398 - val_accuracy: 0.4575\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.7109 - accuracy: 0.5228 - val_loss: 0.7488 - val_accuracy: 0.5425\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7105 - accuracy: 0.5244 - val_loss: 0.7202 - val_accuracy: 0.4575\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.7228 - accuracy: 0.5146 - val_loss: 0.7142 - val_accuracy: 0.4575\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.7209 - accuracy: 0.5073 - val_loss: 0.7054 - val_accuracy: 0.5425\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7194 - accuracy: 0.5211 - val_loss: 0.6948 - val_accuracy: 0.4575\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.7052 - accuracy: 0.5358 - val_loss: 0.7072 - val_accuracy: 0.5425\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.7130 - accuracy: 0.5187 - val_loss: 0.7093 - val_accuracy: 0.5425\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.7021 - accuracy: 0.5317 - val_loss: 0.7147 - val_accuracy: 0.5425\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.7073 - accuracy: 0.5244 - val_loss: 0.7332 - val_accuracy: 0.5425\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.7184 - accuracy: 0.5122 - val_loss: 0.7242 - val_accuracy: 0.5425\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.7070 - accuracy: 0.5317 - val_loss: 0.7275 - val_accuracy: 0.4575\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.7064 - accuracy: 0.5163 - val_loss: 0.7718 - val_accuracy: 0.4575\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 105us/sample - loss: 0.7187 - accuracy: 0.5130 - val_loss: 0.6898 - val_accuracy: 0.5425\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.7210 - accuracy: 0.5122 - val_loss: 0.7806 - val_accuracy: 0.5425\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.7206 - accuracy: 0.4976 - val_loss: 0.7650 - val_accuracy: 0.4575\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.7129 - accuracy: 0.5195 - val_loss: 0.6999 - val_accuracy: 0.5425\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7167 - accuracy: 0.5033 - val_loss: 0.6933 - val_accuracy: 0.4575\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.7028 - accuracy: 0.5276 - val_loss: 0.8278 - val_accuracy: 0.5425\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7122 - accuracy: 0.5228 - val_loss: 0.6901 - val_accuracy: 0.5425\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.7111 - accuracy: 0.5220 - val_loss: 0.6939 - val_accuracy: 0.5425\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7055 - accuracy: 0.5236 - val_loss: 0.7293 - val_accuracy: 0.4575\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.7109 - accuracy: 0.5106 - val_loss: 0.6976 - val_accuracy: 0.4575\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7062 - accuracy: 0.5244 - val_loss: 0.6897 - val_accuracy: 0.5425\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.7145 - accuracy: 0.5138 - val_loss: 0.6897 - val_accuracy: 0.5425\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7140 - accuracy: 0.5154 - val_loss: 0.7171 - val_accuracy: 0.5425\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.7042 - accuracy: 0.5398 - val_loss: 0.7019 - val_accuracy: 0.5425\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.7132 - accuracy: 0.5138 - val_loss: 0.7052 - val_accuracy: 0.5425\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.7068 - accuracy: 0.5268 - val_loss: 0.6925 - val_accuracy: 0.5425\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.7066 - accuracy: 0.5374 - val_loss: 0.7265 - val_accuracy: 0.4575\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.7139 - accuracy: 0.5089 - val_loss: 0.6910 - val_accuracy: 0.5425\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.7021 - accuracy: 0.5228 - val_loss: 0.7481 - val_accuracy: 0.4575\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.7144 - accuracy: 0.5211 - val_loss: 0.7330 - val_accuracy: 0.5425\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 0.7099 - accuracy: 0.5309 - val_loss: 0.7142 - val_accuracy: 0.5425\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.7114 - accuracy: 0.5154 - val_loss: 0.6953 - val_accuracy: 0.5425\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.7296 - accuracy: 0.4992 - val_loss: 0.8660 - val_accuracy: 0.5425\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.7066 - accuracy: 0.5211 - val_loss: 0.6988 - val_accuracy: 0.5425\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.7107 - accuracy: 0.5098 - val_loss: 0.7043 - val_accuracy: 0.5425\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.7141 - accuracy: 0.5016 - val_loss: 0.6908 - val_accuracy: 0.5402\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.7036 - accuracy: 0.5301 - val_loss: 0.7275 - val_accuracy: 0.4575\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.7117 - accuracy: 0.5130 - val_loss: 0.7334 - val_accuracy: 0.4575\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.7075 - accuracy: 0.5163 - val_loss: 0.6966 - val_accuracy: 0.4575\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.7144 - accuracy: 0.5228 - val_loss: 0.6947 - val_accuracy: 0.5425\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.7056 - accuracy: 0.5285 - val_loss: 0.6962 - val_accuracy: 0.4575\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.7064 - accuracy: 0.5179 - val_loss: 0.6897 - val_accuracy: 0.5425\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.7007 - accuracy: 0.5260 - val_loss: 0.6962 - val_accuracy: 0.4575\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.7039 - accuracy: 0.5244 - val_loss: 0.6897 - val_accuracy: 0.5425\n",
      "2895/2895 [==============================] - 0s 23us/sample - loss: 0.6890 - accuracy: 0.5465\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 117us/sample - loss: 3.5256 - accuracy: 0.5411 - val_loss: 3.5243 - val_accuracy: 0.5425\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 3.5237 - accuracy: 0.5472 - val_loss: 3.5232 - val_accuracy: 0.5425\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.5227 - accuracy: 0.5472 - val_loss: 3.5223 - val_accuracy: 0.5425\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.5219 - accuracy: 0.5472 - val_loss: 3.5214 - val_accuracy: 0.5425\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.5211 - accuracy: 0.5472 - val_loss: 3.5207 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 3.5204 - accuracy: 0.5472 - val_loss: 3.5201 - val_accuracy: 0.5425\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 3.5198 - accuracy: 0.5472 - val_loss: 3.5194 - val_accuracy: 0.5425\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 3.5192 - accuracy: 0.5472 - val_loss: 3.5189 - val_accuracy: 0.5425\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.5186 - accuracy: 0.5472 - val_loss: 3.5183 - val_accuracy: 0.5425\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.5181 - accuracy: 0.5472 - val_loss: 3.5178 - val_accuracy: 0.5425\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.5176 - accuracy: 0.5472 - val_loss: 3.5173 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 36us/sample - loss: 3.5171 - accuracy: 0.5472 - val_loss: 3.5168 - val_accuracy: 0.5425\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 3.5166 - accuracy: 0.5472 - val_loss: 3.5164 - val_accuracy: 0.5425\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 3.5162 - accuracy: 0.5472 - val_loss: 3.5160 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 3.5157 - accuracy: 0.5472 - val_loss: 3.5155 - val_accuracy: 0.5425\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 3.5153 - accuracy: 0.5472 - val_loss: 3.5151 - val_accuracy: 0.5425\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 3.5149 - accuracy: 0.5472 - val_loss: 3.5147 - val_accuracy: 0.5425\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 3.5145 - accuracy: 0.5472 - val_loss: 3.5143 - val_accuracy: 0.5425\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.5142 - accuracy: 0.5472 - val_loss: 3.5140 - val_accuracy: 0.5425\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.5138 - accuracy: 0.5472 - val_loss: 3.5136 - val_accuracy: 0.5425\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 3.5134 - accuracy: 0.5472 - val_loss: 3.5132 - val_accuracy: 0.5425\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 3.5131 - accuracy: 0.5472 - val_loss: 3.5129 - val_accuracy: 0.5425\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 3.5127 - accuracy: 0.5472 - val_loss: 3.5125 - val_accuracy: 0.5425\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 3.5124 - accuracy: 0.5472 - val_loss: 3.5122 - val_accuracy: 0.5425\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 3.5120 - accuracy: 0.5472 - val_loss: 3.5119 - val_accuracy: 0.5425\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 3.5117 - accuracy: 0.5476 - val_loss: 3.5116 - val_accuracy: 0.5425\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 3.5114 - accuracy: 0.5472 - val_loss: 3.5112 - val_accuracy: 0.5402\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 3.5111 - accuracy: 0.5504 - val_loss: 3.5109 - val_accuracy: 0.5425\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.5108 - accuracy: 0.5512 - val_loss: 3.5106 - val_accuracy: 0.5402\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.5105 - accuracy: 0.5533 - val_loss: 3.5103 - val_accuracy: 0.5356\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.5102 - accuracy: 0.5512 - val_loss: 3.5100 - val_accuracy: 0.5287\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 3.5099 - accuracy: 0.5520 - val_loss: 3.5097 - val_accuracy: 0.5356\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 3.5096 - accuracy: 0.5541 - val_loss: 3.5094 - val_accuracy: 0.5425\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.5093 - accuracy: 0.5537 - val_loss: 3.5092 - val_accuracy: 0.5494\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.5090 - accuracy: 0.5508 - val_loss: 3.5089 - val_accuracy: 0.5471\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.5087 - accuracy: 0.5549 - val_loss: 3.5086 - val_accuracy: 0.5494\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.5085 - accuracy: 0.5541 - val_loss: 3.5083 - val_accuracy: 0.5471\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.5082 - accuracy: 0.5565 - val_loss: 3.5081 - val_accuracy: 0.5471\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 97us/sample - loss: 3.5079 - accuracy: 0.5585 - val_loss: 3.5078 - val_accuracy: 0.5425\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 3.5077 - accuracy: 0.5589 - val_loss: 3.5075 - val_accuracy: 0.5448\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 3.5074 - accuracy: 0.5598 - val_loss: 3.5073 - val_accuracy: 0.5448\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 3.5071 - accuracy: 0.5606 - val_loss: 3.5070 - val_accuracy: 0.5494\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 116us/sample - loss: 3.5069 - accuracy: 0.5589 - val_loss: 3.5068 - val_accuracy: 0.5471\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 3.5066 - accuracy: 0.5622 - val_loss: 3.5065 - val_accuracy: 0.5448\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.5064 - accuracy: 0.5614 - val_loss: 3.5063 - val_accuracy: 0.5402\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.5061 - accuracy: 0.5610 - val_loss: 3.5060 - val_accuracy: 0.5448\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.5059 - accuracy: 0.5593 - val_loss: 3.5058 - val_accuracy: 0.5425\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 3.5056 - accuracy: 0.5589 - val_loss: 3.5055 - val_accuracy: 0.5425\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.5054 - accuracy: 0.5577 - val_loss: 3.5053 - val_accuracy: 0.5241\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 3.5052 - accuracy: 0.5593 - val_loss: 3.5050 - val_accuracy: 0.5218\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.5049 - accuracy: 0.5573 - val_loss: 3.5048 - val_accuracy: 0.5218\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.5047 - accuracy: 0.5573 - val_loss: 3.5046 - val_accuracy: 0.5241\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.5045 - accuracy: 0.5593 - val_loss: 3.5043 - val_accuracy: 0.5287\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 3.5042 - accuracy: 0.5602 - val_loss: 3.5041 - val_accuracy: 0.5310\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.5040 - accuracy: 0.5614 - val_loss: 3.5039 - val_accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 3.5038 - accuracy: 0.5577 - val_loss: 3.5037 - val_accuracy: 0.5287\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 3.5035 - accuracy: 0.5545 - val_loss: 3.5034 - val_accuracy: 0.5264\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 3.5033 - accuracy: 0.5537 - val_loss: 3.5032 - val_accuracy: 0.5241\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.5031 - accuracy: 0.5553 - val_loss: 3.5030 - val_accuracy: 0.5264\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 3.5029 - accuracy: 0.5537 - val_loss: 3.5028 - val_accuracy: 0.5264\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.5027 - accuracy: 0.5541 - val_loss: 3.5025 - val_accuracy: 0.5241\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.5024 - accuracy: 0.5541 - val_loss: 3.5023 - val_accuracy: 0.5287\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 3.5022 - accuracy: 0.5516 - val_loss: 3.5021 - val_accuracy: 0.5310\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 3.5020 - accuracy: 0.5541 - val_loss: 3.5019 - val_accuracy: 0.5310\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 3.5018 - accuracy: 0.5545 - val_loss: 3.5017 - val_accuracy: 0.5287\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.5016 - accuracy: 0.5561 - val_loss: 3.5015 - val_accuracy: 0.5264\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.5014 - accuracy: 0.5545 - val_loss: 3.5013 - val_accuracy: 0.5356\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 3.5012 - accuracy: 0.5549 - val_loss: 3.5011 - val_accuracy: 0.5379\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.5010 - accuracy: 0.5528 - val_loss: 3.5008 - val_accuracy: 0.5310\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 3.5008 - accuracy: 0.5533 - val_loss: 3.5006 - val_accuracy: 0.5356\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 3.5005 - accuracy: 0.5520 - val_loss: 3.5004 - val_accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 3.5003 - accuracy: 0.5524 - val_loss: 3.5002 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 3.5001 - accuracy: 0.5512 - val_loss: 3.5000 - val_accuracy: 0.5356\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 3.4999 - accuracy: 0.5524 - val_loss: 3.4998 - val_accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 3.4997 - accuracy: 0.5508 - val_loss: 3.4996 - val_accuracy: 0.5379\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 3.4995 - accuracy: 0.5480 - val_loss: 3.4994 - val_accuracy: 0.5356\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 3.4993 - accuracy: 0.5516 - val_loss: 3.4992 - val_accuracy: 0.5379\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 3.4991 - accuracy: 0.5496 - val_loss: 3.4990 - val_accuracy: 0.5379\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.4989 - accuracy: 0.5488 - val_loss: 3.4988 - val_accuracy: 0.5379\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.4987 - accuracy: 0.5516 - val_loss: 3.4986 - val_accuracy: 0.5379\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.4985 - accuracy: 0.5504 - val_loss: 3.4984 - val_accuracy: 0.5402\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 3.4983 - accuracy: 0.5488 - val_loss: 3.4982 - val_accuracy: 0.5402\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 3.4981 - accuracy: 0.5500 - val_loss: 3.4980 - val_accuracy: 0.5402\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 3.4979 - accuracy: 0.5504 - val_loss: 3.4978 - val_accuracy: 0.5402\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 3.4978 - accuracy: 0.5492 - val_loss: 3.4976 - val_accuracy: 0.5425\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.4976 - accuracy: 0.5512 - val_loss: 3.4975 - val_accuracy: 0.5425\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.4974 - accuracy: 0.5500 - val_loss: 3.4973 - val_accuracy: 0.5425\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.4972 - accuracy: 0.5496 - val_loss: 3.4971 - val_accuracy: 0.5425\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.4970 - accuracy: 0.5500 - val_loss: 3.4969 - val_accuracy: 0.5402\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 3.4968 - accuracy: 0.5508 - val_loss: 3.4967 - val_accuracy: 0.5402\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 3.4966 - accuracy: 0.5504 - val_loss: 3.4965 - val_accuracy: 0.5402\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.4964 - accuracy: 0.5524 - val_loss: 3.4963 - val_accuracy: 0.5402\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.4962 - accuracy: 0.5520 - val_loss: 3.4961 - val_accuracy: 0.5402\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4960 - accuracy: 0.5524 - val_loss: 3.4959 - val_accuracy: 0.5402\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 3.4958 - accuracy: 0.5524 - val_loss: 3.4957 - val_accuracy: 0.5402\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 3.4956 - accuracy: 0.5520 - val_loss: 3.4955 - val_accuracy: 0.5402\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 3.4955 - accuracy: 0.5516 - val_loss: 3.4953 - val_accuracy: 0.5402\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 3.4953 - accuracy: 0.5516 - val_loss: 3.4952 - val_accuracy: 0.5402\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 3.4951 - accuracy: 0.5504 - val_loss: 3.4950 - val_accuracy: 0.5379\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 3.4949 - accuracy: 0.5512 - val_loss: 3.4948 - val_accuracy: 0.5379\n",
      "2895/2895 [==============================] - 0s 34us/sample - loss: 3.4948 - accuracy: 0.5496\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 193us/sample - loss: 3.5149 - accuracy: 0.4695 - val_loss: 3.5059 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.4999 - accuracy: 0.4504 - val_loss: 3.4943 - val_accuracy: 0.4759\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 3.4896 - accuracy: 0.4553 - val_loss: 3.4850 - val_accuracy: 0.4690\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 3.4810 - accuracy: 0.5199 - val_loss: 3.4769 - val_accuracy: 0.5448\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 3.4733 - accuracy: 0.5484 - val_loss: 3.4697 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 3.4664 - accuracy: 0.5362 - val_loss: 3.4630 - val_accuracy: 0.5425\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.4599 - accuracy: 0.5472 - val_loss: 3.4568 - val_accuracy: 0.5425\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 3.4538 - accuracy: 0.5472 - val_loss: 3.4508 - val_accuracy: 0.5425\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 3.4480 - accuracy: 0.5472 - val_loss: 3.4451 - val_accuracy: 0.5425\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 3.4424 - accuracy: 0.5472 - val_loss: 3.4396 - val_accuracy: 0.5425\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 3.4370 - accuracy: 0.5472 - val_loss: 3.4342 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 3.4315 - accuracy: 0.5472 - val_loss: 3.4287 - val_accuracy: 0.5425\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 3.4260 - accuracy: 0.5472 - val_loss: 3.4232 - val_accuracy: 0.5425\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 3.4205 - accuracy: 0.5472 - val_loss: 3.4175 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.4146 - accuracy: 0.5472 - val_loss: 3.4115 - val_accuracy: 0.5425\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 3.4085 - accuracy: 0.5472 - val_loss: 3.4051 - val_accuracy: 0.5425\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 3.4020 - accuracy: 0.5472 - val_loss: 3.3983 - val_accuracy: 0.5425\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.3949 - accuracy: 0.5472 - val_loss: 3.3908 - val_accuracy: 0.5425\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 32us/sample - loss: 3.3872 - accuracy: 0.5472 - val_loss: 3.3827 - val_accuracy: 0.5425\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 3.3787 - accuracy: 0.5472 - val_loss: 3.3737 - val_accuracy: 0.5425\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 3.3694 - accuracy: 0.5472 - val_loss: 3.3638 - val_accuracy: 0.5425\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 3.3591 - accuracy: 0.5472 - val_loss: 3.3529 - val_accuracy: 0.5425\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 3.3478 - accuracy: 0.5472 - val_loss: 3.3408 - val_accuracy: 0.5425\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 33us/sample - loss: 3.3353 - accuracy: 0.5472 - val_loss: 3.3275 - val_accuracy: 0.5425\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 3.3216 - accuracy: 0.5472 - val_loss: 3.3129 - val_accuracy: 0.5425\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 3.3065 - accuracy: 0.5472 - val_loss: 3.2969 - val_accuracy: 0.5425\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.2900 - accuracy: 0.5472 - val_loss: 3.2794 - val_accuracy: 0.5425\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 3.2721 - accuracy: 0.5472 - val_loss: 3.2605 - val_accuracy: 0.5425\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.2528 - accuracy: 0.5472 - val_loss: 3.2400 - val_accuracy: 0.5425\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 3.2318 - accuracy: 0.5472 - val_loss: 3.2179 - val_accuracy: 0.5425\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 3.2093 - accuracy: 0.5472 - val_loss: 3.1942 - val_accuracy: 0.5425\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 3.1853 - accuracy: 0.5472 - val_loss: 3.1689 - val_accuracy: 0.5425\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 3.1596 - accuracy: 0.5472 - val_loss: 3.1420 - val_accuracy: 0.5425\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 3.1325 - accuracy: 0.5472 - val_loss: 3.1136 - val_accuracy: 0.5425\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 3.1038 - accuracy: 0.5472 - val_loss: 3.0837 - val_accuracy: 0.5425\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 3.0738 - accuracy: 0.5472 - val_loss: 3.0524 - val_accuracy: 0.5425\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 3.0423 - accuracy: 0.5472 - val_loss: 3.0196 - val_accuracy: 0.5425\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 107us/sample - loss: 3.0095 - accuracy: 0.5472 - val_loss: 2.9856 - val_accuracy: 0.5425\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 2.9755 - accuracy: 0.5472 - val_loss: 2.9503 - val_accuracy: 0.5425\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.9402 - accuracy: 0.5472 - val_loss: 2.9138 - val_accuracy: 0.5425\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 106us/sample - loss: 2.9039 - accuracy: 0.5472 - val_loss: 2.8763 - val_accuracy: 0.5425\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 2.8665 - accuracy: 0.5472 - val_loss: 2.8378 - val_accuracy: 0.5425\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 2.8282 - accuracy: 0.5472 - val_loss: 2.7983 - val_accuracy: 0.5425\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 62us/sample - loss: 2.7890 - accuracy: 0.5472 - val_loss: 2.7580 - val_accuracy: 0.5425\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 2.7491 - accuracy: 0.5472 - val_loss: 2.7170 - val_accuracy: 0.5425\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.7085 - accuracy: 0.5472 - val_loss: 2.6754 - val_accuracy: 0.5425\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 2.6673 - accuracy: 0.5472 - val_loss: 2.6332 - val_accuracy: 0.5425\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 2.6256 - accuracy: 0.5472 - val_loss: 2.5906 - val_accuracy: 0.5425\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 2.5836 - accuracy: 0.5472 - val_loss: 2.5478 - val_accuracy: 0.5425\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 2.5413 - accuracy: 0.5472 - val_loss: 2.5047 - val_accuracy: 0.5425\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 2.4989 - accuracy: 0.5472 - val_loss: 2.4616 - val_accuracy: 0.5425\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 2.4564 - accuracy: 0.5472 - val_loss: 2.4184 - val_accuracy: 0.5425\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 2.4140 - accuracy: 0.5472 - val_loss: 2.3754 - val_accuracy: 0.5425\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 2.3717 - accuracy: 0.5472 - val_loss: 2.3326 - val_accuracy: 0.5425\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 2.3297 - accuracy: 0.5472 - val_loss: 2.2901 - val_accuracy: 0.5425\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 2.2879 - accuracy: 0.5472 - val_loss: 2.2480 - val_accuracy: 0.5425\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 2.2466 - accuracy: 0.5472 - val_loss: 2.2064 - val_accuracy: 0.5425\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 2.2058 - accuracy: 0.5472 - val_loss: 2.1654 - val_accuracy: 0.5425\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 2.1656 - accuracy: 0.5472 - val_loss: 2.1249 - val_accuracy: 0.5425\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 2.1260 - accuracy: 0.5472 - val_loss: 2.0852 - val_accuracy: 0.5425\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 2.0871 - accuracy: 0.5472 - val_loss: 2.0463 - val_accuracy: 0.5425\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 2.0489 - accuracy: 0.5472 - val_loss: 2.0081 - val_accuracy: 0.5425\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 2.0115 - accuracy: 0.5472 - val_loss: 1.9708 - val_accuracy: 0.5425\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 1.9749 - accuracy: 0.5472 - val_loss: 1.9343 - val_accuracy: 0.5425\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 1.9391 - accuracy: 0.5472 - val_loss: 1.8987 - val_accuracy: 0.5425\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 1.9042 - accuracy: 0.5472 - val_loss: 1.8640 - val_accuracy: 0.5425\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 1.8701 - accuracy: 0.5472 - val_loss: 1.8302 - val_accuracy: 0.5425\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 1.8370 - accuracy: 0.5472 - val_loss: 1.7973 - val_accuracy: 0.5425\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 1.8047 - accuracy: 0.5472 - val_loss: 1.7654 - val_accuracy: 0.5425\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 1.7733 - accuracy: 0.5472 - val_loss: 1.7344 - val_accuracy: 0.5425\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 1.7428 - accuracy: 0.5472 - val_loss: 1.7042 - val_accuracy: 0.5425\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 1.7131 - accuracy: 0.5472 - val_loss: 1.6750 - val_accuracy: 0.5425\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 1.6843 - accuracy: 0.5472 - val_loss: 1.6467 - val_accuracy: 0.5425\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 1.6564 - accuracy: 0.5472 - val_loss: 1.6192 - val_accuracy: 0.5425\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 1.6293 - accuracy: 0.5472 - val_loss: 1.5926 - val_accuracy: 0.5425\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 1.6030 - accuracy: 0.5472 - val_loss: 1.5669 - val_accuracy: 0.5425\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 1.5776 - accuracy: 0.5472 - val_loss: 1.5419 - val_accuracy: 0.5425\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 1.5529 - accuracy: 0.5472 - val_loss: 1.5178 - val_accuracy: 0.5425\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 1.5290 - accuracy: 0.5472 - val_loss: 1.4944 - val_accuracy: 0.5425\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 31us/sample - loss: 1.5058 - accuracy: 0.5472 - val_loss: 1.4718 - val_accuracy: 0.5425\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 1.4834 - accuracy: 0.5472 - val_loss: 1.4500 - val_accuracy: 0.5425\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 1.4617 - accuracy: 0.5472 - val_loss: 1.4288 - val_accuracy: 0.5425\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 1.4406 - accuracy: 0.5472 - val_loss: 1.4084 - val_accuracy: 0.5425\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 1.4203 - accuracy: 0.5472 - val_loss: 1.3886 - val_accuracy: 0.5425\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 1.4006 - accuracy: 0.5472 - val_loss: 1.3694 - val_accuracy: 0.5425\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 1.3815 - accuracy: 0.5472 - val_loss: 1.3509 - val_accuracy: 0.5425\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 1.3630 - accuracy: 0.5472 - val_loss: 1.3330 - val_accuracy: 0.5425\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 1.3452 - accuracy: 0.5472 - val_loss: 1.3157 - val_accuracy: 0.5425\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 1.3279 - accuracy: 0.5472 - val_loss: 1.2990 - val_accuracy: 0.5425\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 1.3111 - accuracy: 0.5472 - val_loss: 1.2828 - val_accuracy: 0.5425\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 1.2949 - accuracy: 0.5472 - val_loss: 1.2672 - val_accuracy: 0.5425\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 1.2792 - accuracy: 0.5472 - val_loss: 1.2520 - val_accuracy: 0.5425\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 1.2641 - accuracy: 0.5472 - val_loss: 1.2374 - val_accuracy: 0.5425\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 1.2494 - accuracy: 0.5472 - val_loss: 1.2232 - val_accuracy: 0.5425\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 1.2351 - accuracy: 0.5472 - val_loss: 1.2095 - val_accuracy: 0.5425\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 113us/sample - loss: 1.2214 - accuracy: 0.5472 - val_loss: 1.1962 - val_accuracy: 0.5425\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 1.2080 - accuracy: 0.5472 - val_loss: 1.1834 - val_accuracy: 0.5425\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 1.1951 - accuracy: 0.5472 - val_loss: 1.1710 - val_accuracy: 0.5425\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 1.1826 - accuracy: 0.5472 - val_loss: 1.1590 - val_accuracy: 0.5425\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 1.1705 - accuracy: 0.5472 - val_loss: 1.1474 - val_accuracy: 0.5425\n",
      "2895/2895 [==============================] - 0s 32us/sample - loss: 1.1619 - accuracy: 0.5465\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 0s 127us/sample - loss: 3.4018 - accuracy: 0.5276 - val_loss: 3.3112 - val_accuracy: 0.5379\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 3.1984 - accuracy: 0.5504 - val_loss: 3.0198 - val_accuracy: 0.5379\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 2.6195 - accuracy: 0.5459 - val_loss: 2.0565 - val_accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 1.5873 - accuracy: 0.5443 - val_loss: 1.1981 - val_accuracy: 0.5310\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 1.0432 - accuracy: 0.5500 - val_loss: 0.9121 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 109us/sample - loss: 0.8613 - accuracy: 0.5561 - val_loss: 0.8115 - val_accuracy: 0.5425\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.7909 - accuracy: 0.5463 - val_loss: 0.7670 - val_accuracy: 0.5310\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.7569 - accuracy: 0.5480 - val_loss: 0.7440 - val_accuracy: 0.5402\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.7385 - accuracy: 0.5500 - val_loss: 0.7301 - val_accuracy: 0.5241\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.7268 - accuracy: 0.5455 - val_loss: 0.7213 - val_accuracy: 0.5310\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.7189 - accuracy: 0.5443 - val_loss: 0.7153 - val_accuracy: 0.5241\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.7132 - accuracy: 0.5484 - val_loss: 0.7107 - val_accuracy: 0.5402\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.7094 - accuracy: 0.5411 - val_loss: 0.7074 - val_accuracy: 0.5287\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.7056 - accuracy: 0.5455 - val_loss: 0.7048 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.7032 - accuracy: 0.5541 - val_loss: 0.7024 - val_accuracy: 0.5195\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.7011 - accuracy: 0.5512 - val_loss: 0.7007 - val_accuracy: 0.5264\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.6992 - accuracy: 0.5545 - val_loss: 0.6990 - val_accuracy: 0.5425\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.6974 - accuracy: 0.5492 - val_loss: 0.6978 - val_accuracy: 0.5563\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.6959 - accuracy: 0.5581 - val_loss: 0.6963 - val_accuracy: 0.5264\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.6944 - accuracy: 0.5561 - val_loss: 0.6951 - val_accuracy: 0.5264\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.6926 - accuracy: 0.5606 - val_loss: 0.6941 - val_accuracy: 0.5563\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.6912 - accuracy: 0.5589 - val_loss: 0.6928 - val_accuracy: 0.5540\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.6898 - accuracy: 0.5642 - val_loss: 0.6910 - val_accuracy: 0.5379\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6879 - accuracy: 0.5626 - val_loss: 0.6894 - val_accuracy: 0.5586\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 65us/sample - loss: 0.6859 - accuracy: 0.5622 - val_loss: 0.6876 - val_accuracy: 0.5563\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.6837 - accuracy: 0.5715 - val_loss: 0.6858 - val_accuracy: 0.5471\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.6809 - accuracy: 0.5728 - val_loss: 0.6839 - val_accuracy: 0.5540\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.6782 - accuracy: 0.5809 - val_loss: 0.6808 - val_accuracy: 0.5747\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.6749 - accuracy: 0.5878 - val_loss: 0.6779 - val_accuracy: 0.5793\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.6711 - accuracy: 0.5972 - val_loss: 0.6752 - val_accuracy: 0.5908\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.6678 - accuracy: 0.5951 - val_loss: 0.6715 - val_accuracy: 0.5885\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.6636 - accuracy: 0.6049 - val_loss: 0.6679 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.6593 - accuracy: 0.6098 - val_loss: 0.6641 - val_accuracy: 0.6138\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.6549 - accuracy: 0.6252 - val_loss: 0.6603 - val_accuracy: 0.6115\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.6500 - accuracy: 0.6390 - val_loss: 0.6572 - val_accuracy: 0.6161\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.6458 - accuracy: 0.6427 - val_loss: 0.6529 - val_accuracy: 0.6253\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.6411 - accuracy: 0.6545 - val_loss: 0.6491 - val_accuracy: 0.6322\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.6366 - accuracy: 0.6569 - val_loss: 0.6454 - val_accuracy: 0.6414\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.6322 - accuracy: 0.6598 - val_loss: 0.6417 - val_accuracy: 0.6506\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6280 - accuracy: 0.6634 - val_loss: 0.6389 - val_accuracy: 0.6529\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.6239 - accuracy: 0.6703 - val_loss: 0.6357 - val_accuracy: 0.6575\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.6205 - accuracy: 0.6728 - val_loss: 0.6326 - val_accuracy: 0.6621\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.6168 - accuracy: 0.6744 - val_loss: 0.6298 - val_accuracy: 0.6598\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6135 - accuracy: 0.6780 - val_loss: 0.6271 - val_accuracy: 0.6552\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.6103 - accuracy: 0.6813 - val_loss: 0.6255 - val_accuracy: 0.6529\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6077 - accuracy: 0.6837 - val_loss: 0.6228 - val_accuracy: 0.6552\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.6052 - accuracy: 0.6833 - val_loss: 0.6209 - val_accuracy: 0.6575\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.6031 - accuracy: 0.6805 - val_loss: 0.6192 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 115us/sample - loss: 0.6009 - accuracy: 0.6886 - val_loss: 0.6177 - val_accuracy: 0.6621\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5989 - accuracy: 0.6854 - val_loss: 0.6169 - val_accuracy: 0.6621\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5973 - accuracy: 0.6846 - val_loss: 0.6157 - val_accuracy: 0.6575\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5954 - accuracy: 0.6894 - val_loss: 0.6139 - val_accuracy: 0.6529\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5941 - accuracy: 0.6927 - val_loss: 0.6140 - val_accuracy: 0.6621\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5931 - accuracy: 0.6927 - val_loss: 0.6125 - val_accuracy: 0.6529\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5917 - accuracy: 0.6907 - val_loss: 0.6119 - val_accuracy: 0.6506\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5908 - accuracy: 0.6886 - val_loss: 0.6105 - val_accuracy: 0.6575\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.5899 - accuracy: 0.6915 - val_loss: 0.6099 - val_accuracy: 0.6621\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5891 - accuracy: 0.6907 - val_loss: 0.6094 - val_accuracy: 0.6598\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 73us/sample - loss: 0.5880 - accuracy: 0.6943 - val_loss: 0.6089 - val_accuracy: 0.6552\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5875 - accuracy: 0.6919 - val_loss: 0.6084 - val_accuracy: 0.6529\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5865 - accuracy: 0.6943 - val_loss: 0.6077 - val_accuracy: 0.6690\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5863 - accuracy: 0.6939 - val_loss: 0.6077 - val_accuracy: 0.6552\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5855 - accuracy: 0.6972 - val_loss: 0.6078 - val_accuracy: 0.6598\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5852 - accuracy: 0.6955 - val_loss: 0.6073 - val_accuracy: 0.6575\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5847 - accuracy: 0.6939 - val_loss: 0.6065 - val_accuracy: 0.6598\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5843 - accuracy: 0.6972 - val_loss: 0.6066 - val_accuracy: 0.6575\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5839 - accuracy: 0.6943 - val_loss: 0.6065 - val_accuracy: 0.6552\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.5837 - accuracy: 0.6972 - val_loss: 0.6061 - val_accuracy: 0.6575\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5831 - accuracy: 0.6951 - val_loss: 0.6057 - val_accuracy: 0.6598\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5832 - accuracy: 0.6972 - val_loss: 0.6057 - val_accuracy: 0.6598\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5828 - accuracy: 0.6963 - val_loss: 0.6056 - val_accuracy: 0.6598\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5823 - accuracy: 0.6959 - val_loss: 0.6057 - val_accuracy: 0.6552\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5822 - accuracy: 0.6967 - val_loss: 0.6056 - val_accuracy: 0.6529\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5821 - accuracy: 0.6980 - val_loss: 0.6052 - val_accuracy: 0.6621\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5819 - accuracy: 0.6976 - val_loss: 0.6051 - val_accuracy: 0.6598\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5813 - accuracy: 0.6992 - val_loss: 0.6059 - val_accuracy: 0.6621\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5814 - accuracy: 0.6951 - val_loss: 0.6053 - val_accuracy: 0.6575\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5813 - accuracy: 0.7000 - val_loss: 0.6054 - val_accuracy: 0.6598\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 102us/sample - loss: 0.5812 - accuracy: 0.6972 - val_loss: 0.6050 - val_accuracy: 0.6621\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5809 - accuracy: 0.6959 - val_loss: 0.6054 - val_accuracy: 0.6598\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5810 - accuracy: 0.6935 - val_loss: 0.6049 - val_accuracy: 0.6621\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 40us/sample - loss: 0.5808 - accuracy: 0.6963 - val_loss: 0.6051 - val_accuracy: 0.6621\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.5807 - accuracy: 0.6947 - val_loss: 0.6051 - val_accuracy: 0.6621\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5803 - accuracy: 0.6980 - val_loss: 0.6048 - val_accuracy: 0.6644\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5802 - accuracy: 0.6972 - val_loss: 0.6047 - val_accuracy: 0.6621\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5802 - accuracy: 0.6955 - val_loss: 0.6050 - val_accuracy: 0.6621\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5801 - accuracy: 0.6943 - val_loss: 0.6049 - val_accuracy: 0.6644\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5799 - accuracy: 0.6943 - val_loss: 0.6045 - val_accuracy: 0.6621\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5800 - accuracy: 0.6951 - val_loss: 0.6049 - val_accuracy: 0.6621\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5797 - accuracy: 0.6947 - val_loss: 0.6052 - val_accuracy: 0.6598\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5798 - accuracy: 0.6947 - val_loss: 0.6047 - val_accuracy: 0.6644\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5793 - accuracy: 0.6976 - val_loss: 0.6055 - val_accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5795 - accuracy: 0.6988 - val_loss: 0.6051 - val_accuracy: 0.6621\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5795 - accuracy: 0.6939 - val_loss: 0.6045 - val_accuracy: 0.6598\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5796 - accuracy: 0.6988 - val_loss: 0.6047 - val_accuracy: 0.6644\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5793 - accuracy: 0.6959 - val_loss: 0.6047 - val_accuracy: 0.6644\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5792 - accuracy: 0.6955 - val_loss: 0.6049 - val_accuracy: 0.6690\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5792 - accuracy: 0.6935 - val_loss: 0.6048 - val_accuracy: 0.6644\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5792 - accuracy: 0.6976 - val_loss: 0.6049 - val_accuracy: 0.6713\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5789 - accuracy: 0.6955 - val_loss: 0.6045 - val_accuracy: 0.6667\n",
      "2895/2895 [==============================] - 0s 24us/sample - loss: 0.5822 - accuracy: 0.6905\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 267us/sample - loss: 1.1789 - accuracy: 0.5187 - val_loss: 0.6973 - val_accuracy: 0.5402\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.6996 - accuracy: 0.5480 - val_loss: 0.6819 - val_accuracy: 0.5747\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.6669 - accuracy: 0.5996 - val_loss: 0.6574 - val_accuracy: 0.6046\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 104us/sample - loss: 0.6291 - accuracy: 0.6528 - val_loss: 0.6323 - val_accuracy: 0.6391\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.6116 - accuracy: 0.6756 - val_loss: 0.6138 - val_accuracy: 0.6506\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.6060 - accuracy: 0.6703 - val_loss: 0.6138 - val_accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5987 - accuracy: 0.6789 - val_loss: 0.6049 - val_accuracy: 0.6575\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5931 - accuracy: 0.6821 - val_loss: 0.6069 - val_accuracy: 0.6644\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5869 - accuracy: 0.6841 - val_loss: 0.6201 - val_accuracy: 0.6575\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5889 - accuracy: 0.6821 - val_loss: 0.6142 - val_accuracy: 0.6759\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5872 - accuracy: 0.6923 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5866 - accuracy: 0.6919 - val_loss: 0.6124 - val_accuracy: 0.6644\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5866 - accuracy: 0.6882 - val_loss: 0.6057 - val_accuracy: 0.6598\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.5832 - accuracy: 0.6951 - val_loss: 0.6113 - val_accuracy: 0.6782\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5812 - accuracy: 0.6984 - val_loss: 0.6082 - val_accuracy: 0.6621\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5786 - accuracy: 0.6939 - val_loss: 0.6187 - val_accuracy: 0.6759\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5807 - accuracy: 0.6898 - val_loss: 0.6115 - val_accuracy: 0.6736\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.5782 - accuracy: 0.6992 - val_loss: 0.6125 - val_accuracy: 0.6713\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5778 - accuracy: 0.6947 - val_loss: 0.6158 - val_accuracy: 0.6644\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5760 - accuracy: 0.6996 - val_loss: 0.6181 - val_accuracy: 0.6529\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5741 - accuracy: 0.6959 - val_loss: 0.6137 - val_accuracy: 0.6644\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5775 - accuracy: 0.6939 - val_loss: 0.6089 - val_accuracy: 0.6506\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5738 - accuracy: 0.6943 - val_loss: 0.6127 - val_accuracy: 0.6506\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 100us/sample - loss: 0.5698 - accuracy: 0.7020 - val_loss: 0.6143 - val_accuracy: 0.6736\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5715 - accuracy: 0.6996 - val_loss: 0.6107 - val_accuracy: 0.6529\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 101us/sample - loss: 0.5712 - accuracy: 0.6951 - val_loss: 0.6158 - val_accuracy: 0.6782\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5710 - accuracy: 0.6963 - val_loss: 0.6143 - val_accuracy: 0.6598\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5694 - accuracy: 0.6992 - val_loss: 0.6133 - val_accuracy: 0.6598\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5669 - accuracy: 0.7049 - val_loss: 0.6275 - val_accuracy: 0.6851\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5685 - accuracy: 0.6959 - val_loss: 0.6181 - val_accuracy: 0.6759\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5651 - accuracy: 0.7110 - val_loss: 0.6173 - val_accuracy: 0.6621\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5658 - accuracy: 0.6988 - val_loss: 0.6165 - val_accuracy: 0.6644\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5643 - accuracy: 0.7049 - val_loss: 0.6189 - val_accuracy: 0.6483\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5630 - accuracy: 0.7004 - val_loss: 0.6177 - val_accuracy: 0.6575\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5627 - accuracy: 0.7061 - val_loss: 0.6195 - val_accuracy: 0.6713\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5622 - accuracy: 0.7004 - val_loss: 0.6325 - val_accuracy: 0.6759\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5627 - accuracy: 0.7037 - val_loss: 0.6197 - val_accuracy: 0.6506\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5593 - accuracy: 0.7069 - val_loss: 0.6194 - val_accuracy: 0.6552\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5563 - accuracy: 0.7037 - val_loss: 0.6313 - val_accuracy: 0.6529\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5563 - accuracy: 0.7061 - val_loss: 0.6375 - val_accuracy: 0.6644\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5574 - accuracy: 0.7102 - val_loss: 0.6215 - val_accuracy: 0.6575\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5557 - accuracy: 0.7110 - val_loss: 0.6241 - val_accuracy: 0.6598\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5527 - accuracy: 0.7102 - val_loss: 0.6299 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5529 - accuracy: 0.7179 - val_loss: 0.6242 - val_accuracy: 0.6621\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5530 - accuracy: 0.7085 - val_loss: 0.6265 - val_accuracy: 0.6690\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5525 - accuracy: 0.7118 - val_loss: 0.6244 - val_accuracy: 0.6529\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5503 - accuracy: 0.7126 - val_loss: 0.6294 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5489 - accuracy: 0.7102 - val_loss: 0.6272 - val_accuracy: 0.6713\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5486 - accuracy: 0.7073 - val_loss: 0.6253 - val_accuracy: 0.6506\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5467 - accuracy: 0.7085 - val_loss: 0.6251 - val_accuracy: 0.6690\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5461 - accuracy: 0.7171 - val_loss: 0.6261 - val_accuracy: 0.6437\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 41us/sample - loss: 0.5434 - accuracy: 0.7175 - val_loss: 0.6259 - val_accuracy: 0.6506\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5427 - accuracy: 0.7215 - val_loss: 0.6271 - val_accuracy: 0.6575\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.5393 - accuracy: 0.7236 - val_loss: 0.6268 - val_accuracy: 0.6552\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5409 - accuracy: 0.7256 - val_loss: 0.6300 - val_accuracy: 0.6575\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5393 - accuracy: 0.7195 - val_loss: 0.6286 - val_accuracy: 0.6506\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5390 - accuracy: 0.7220 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5390 - accuracy: 0.7248 - val_loss: 0.6299 - val_accuracy: 0.6506\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.5375 - accuracy: 0.7260 - val_loss: 0.6292 - val_accuracy: 0.6621\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5345 - accuracy: 0.7244 - val_loss: 0.6318 - val_accuracy: 0.6621\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5332 - accuracy: 0.7211 - val_loss: 0.6412 - val_accuracy: 0.6368\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5340 - accuracy: 0.7220 - val_loss: 0.6455 - val_accuracy: 0.6621\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5297 - accuracy: 0.7378 - val_loss: 0.6493 - val_accuracy: 0.6621\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5308 - accuracy: 0.7293 - val_loss: 0.6390 - val_accuracy: 0.6552\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.5287 - accuracy: 0.7317 - val_loss: 0.6415 - val_accuracy: 0.6621\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5287 - accuracy: 0.7337 - val_loss: 0.6426 - val_accuracy: 0.6552\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5274 - accuracy: 0.7341 - val_loss: 0.6436 - val_accuracy: 0.6598\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5239 - accuracy: 0.7435 - val_loss: 0.6379 - val_accuracy: 0.6483\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5260 - accuracy: 0.7337 - val_loss: 0.6438 - val_accuracy: 0.6322\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5215 - accuracy: 0.7386 - val_loss: 0.6423 - val_accuracy: 0.6598\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5223 - accuracy: 0.7362 - val_loss: 0.6390 - val_accuracy: 0.6552\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.5244 - accuracy: 0.7305 - val_loss: 0.6412 - val_accuracy: 0.6460\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5191 - accuracy: 0.7362 - val_loss: 0.6478 - val_accuracy: 0.6414\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5167 - accuracy: 0.7374 - val_loss: 0.6607 - val_accuracy: 0.6575\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5172 - accuracy: 0.7407 - val_loss: 0.6442 - val_accuracy: 0.6345\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.5159 - accuracy: 0.7354 - val_loss: 0.6440 - val_accuracy: 0.6460\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5148 - accuracy: 0.7419 - val_loss: 0.6470 - val_accuracy: 0.6391\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5137 - accuracy: 0.7362 - val_loss: 0.6469 - val_accuracy: 0.6460\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.5124 - accuracy: 0.7463 - val_loss: 0.6510 - val_accuracy: 0.6460\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5117 - accuracy: 0.7512 - val_loss: 0.6478 - val_accuracy: 0.6506\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 98us/sample - loss: 0.5122 - accuracy: 0.7378 - val_loss: 0.6518 - val_accuracy: 0.6529\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5098 - accuracy: 0.7439 - val_loss: 0.6518 - val_accuracy: 0.6460\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5100 - accuracy: 0.7431 - val_loss: 0.6541 - val_accuracy: 0.6506\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 112us/sample - loss: 0.5053 - accuracy: 0.7524 - val_loss: 0.6702 - val_accuracy: 0.6322\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.5060 - accuracy: 0.7528 - val_loss: 0.6560 - val_accuracy: 0.6506\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5049 - accuracy: 0.7451 - val_loss: 0.6543 - val_accuracy: 0.6506\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5033 - accuracy: 0.7504 - val_loss: 0.6659 - val_accuracy: 0.6414\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 85us/sample - loss: 0.5018 - accuracy: 0.7569 - val_loss: 0.6555 - val_accuracy: 0.6414\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.4991 - accuracy: 0.7618 - val_loss: 0.6625 - val_accuracy: 0.6529\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 68us/sample - loss: 0.5005 - accuracy: 0.7484 - val_loss: 0.6620 - val_accuracy: 0.6460\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 61us/sample - loss: 0.4960 - accuracy: 0.7589 - val_loss: 0.6641 - val_accuracy: 0.6506\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4991 - accuracy: 0.7561 - val_loss: 0.6657 - val_accuracy: 0.6345\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 92us/sample - loss: 0.4956 - accuracy: 0.7581 - val_loss: 0.6652 - val_accuracy: 0.6391\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 77us/sample - loss: 0.4923 - accuracy: 0.7577 - val_loss: 0.6745 - val_accuracy: 0.6230\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.4931 - accuracy: 0.7589 - val_loss: 0.6666 - val_accuracy: 0.6345\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.4906 - accuracy: 0.7626 - val_loss: 0.6698 - val_accuracy: 0.6437\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4916 - accuracy: 0.7589 - val_loss: 0.6750 - val_accuracy: 0.6460\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4893 - accuracy: 0.7541 - val_loss: 0.6703 - val_accuracy: 0.6391\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.4895 - accuracy: 0.7569 - val_loss: 0.6728 - val_accuracy: 0.6414\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.4897 - accuracy: 0.7618 - val_loss: 0.6720 - val_accuracy: 0.6460\n",
      "2895/2895 [==============================] - 0s 60us/sample - loss: 0.5016 - accuracy: 0.7585\n",
      "Train on 2460 samples, validate on 435 samples\n",
      "Epoch 1/100\n",
      "2460/2460 [==============================] - 1s 229us/sample - loss: 0.9322 - accuracy: 0.5280 - val_loss: 0.6417 - val_accuracy: 0.6460\n",
      "Epoch 2/100\n",
      "2460/2460 [==============================] - 0s 39us/sample - loss: 0.6588 - accuracy: 0.6309 - val_loss: 0.6548 - val_accuracy: 0.6529\n",
      "Epoch 3/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.6179 - accuracy: 0.6537 - val_loss: 0.6280 - val_accuracy: 0.6690\n",
      "Epoch 4/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.6098 - accuracy: 0.6760 - val_loss: 0.6447 - val_accuracy: 0.6483\n",
      "Epoch 5/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.6063 - accuracy: 0.6593 - val_loss: 0.6237 - val_accuracy: 0.6644\n",
      "Epoch 6/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5886 - accuracy: 0.6785 - val_loss: 0.6287 - val_accuracy: 0.6621\n",
      "Epoch 7/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5815 - accuracy: 0.6862 - val_loss: 0.6675 - val_accuracy: 0.6368\n",
      "Epoch 8/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.5807 - accuracy: 0.6927 - val_loss: 0.6333 - val_accuracy: 0.6437\n",
      "Epoch 9/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5761 - accuracy: 0.6907 - val_loss: 0.6425 - val_accuracy: 0.6368\n",
      "Epoch 10/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5779 - accuracy: 0.6935 - val_loss: 0.6213 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5777 - accuracy: 0.6841 - val_loss: 0.6340 - val_accuracy: 0.6621\n",
      "Epoch 12/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.5732 - accuracy: 0.7045 - val_loss: 0.6475 - val_accuracy: 0.6299\n",
      "Epoch 13/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5653 - accuracy: 0.7057 - val_loss: 0.6225 - val_accuracy: 0.6598\n",
      "Epoch 14/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.5667 - accuracy: 0.7045 - val_loss: 0.6351 - val_accuracy: 0.6391\n",
      "Epoch 15/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5643 - accuracy: 0.7085 - val_loss: 0.6380 - val_accuracy: 0.6552\n",
      "Epoch 16/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.5626 - accuracy: 0.7004 - val_loss: 0.6266 - val_accuracy: 0.6644\n",
      "Epoch 17/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5588 - accuracy: 0.7024 - val_loss: 0.6558 - val_accuracy: 0.6529\n",
      "Epoch 18/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5581 - accuracy: 0.7077 - val_loss: 0.6666 - val_accuracy: 0.6483\n",
      "Epoch 19/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5592 - accuracy: 0.7187 - val_loss: 0.6568 - val_accuracy: 0.6230\n",
      "Epoch 20/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.5547 - accuracy: 0.7171 - val_loss: 0.6520 - val_accuracy: 0.6575\n",
      "Epoch 21/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5540 - accuracy: 0.7130 - val_loss: 0.6482 - val_accuracy: 0.6621\n",
      "Epoch 22/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5510 - accuracy: 0.7183 - val_loss: 0.6497 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "2460/2460 [==============================] - 0s 51us/sample - loss: 0.5555 - accuracy: 0.7142 - val_loss: 0.6728 - val_accuracy: 0.6368\n",
      "Epoch 24/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.5508 - accuracy: 0.7195 - val_loss: 0.6576 - val_accuracy: 0.6299\n",
      "Epoch 25/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5489 - accuracy: 0.7240 - val_loss: 0.6609 - val_accuracy: 0.6437\n",
      "Epoch 26/100\n",
      "2460/2460 [==============================] - 0s 47us/sample - loss: 0.5453 - accuracy: 0.7236 - val_loss: 0.6595 - val_accuracy: 0.6644\n",
      "Epoch 27/100\n",
      "2460/2460 [==============================] - 0s 89us/sample - loss: 0.5427 - accuracy: 0.7268 - val_loss: 0.6605 - val_accuracy: 0.6483\n",
      "Epoch 28/100\n",
      "2460/2460 [==============================] - 0s 48us/sample - loss: 0.5435 - accuracy: 0.7280 - val_loss: 0.6574 - val_accuracy: 0.6345\n",
      "Epoch 29/100\n",
      "2460/2460 [==============================] - 0s 83us/sample - loss: 0.5409 - accuracy: 0.7264 - val_loss: 0.6517 - val_accuracy: 0.6460\n",
      "Epoch 30/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.5413 - accuracy: 0.7280 - val_loss: 0.6636 - val_accuracy: 0.6276\n",
      "Epoch 31/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.5383 - accuracy: 0.7285 - val_loss: 0.6837 - val_accuracy: 0.6483\n",
      "Epoch 32/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.5365 - accuracy: 0.7244 - val_loss: 0.6658 - val_accuracy: 0.6437\n",
      "Epoch 33/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.5331 - accuracy: 0.7305 - val_loss: 0.6635 - val_accuracy: 0.6368\n",
      "Epoch 34/100\n",
      "2460/2460 [==============================] - 0s 78us/sample - loss: 0.5369 - accuracy: 0.7301 - val_loss: 0.6746 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2460/2460 [==============================] - 0s 42us/sample - loss: 0.5310 - accuracy: 0.7370 - val_loss: 0.6746 - val_accuracy: 0.6575\n",
      "Epoch 36/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5356 - accuracy: 0.7289 - val_loss: 0.6748 - val_accuracy: 0.6506\n",
      "Epoch 37/100\n",
      "2460/2460 [==============================] - 0s 56us/sample - loss: 0.5321 - accuracy: 0.7317 - val_loss: 0.6969 - val_accuracy: 0.6437\n",
      "Epoch 38/100\n",
      "2460/2460 [==============================] - 0s 93us/sample - loss: 0.5296 - accuracy: 0.7244 - val_loss: 0.6708 - val_accuracy: 0.6575\n",
      "Epoch 39/100\n",
      "2460/2460 [==============================] - 0s 55us/sample - loss: 0.5278 - accuracy: 0.7362 - val_loss: 0.6834 - val_accuracy: 0.6299\n",
      "Epoch 40/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.5306 - accuracy: 0.7354 - val_loss: 0.6898 - val_accuracy: 0.6230\n",
      "Epoch 41/100\n",
      "2460/2460 [==============================] - 0s 80us/sample - loss: 0.5270 - accuracy: 0.7378 - val_loss: 0.6808 - val_accuracy: 0.6299\n",
      "Epoch 42/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5239 - accuracy: 0.7374 - val_loss: 0.7004 - val_accuracy: 0.6345\n",
      "Epoch 43/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5219 - accuracy: 0.7341 - val_loss: 0.6971 - val_accuracy: 0.6483\n",
      "Epoch 44/100\n",
      "2460/2460 [==============================] - 0s 45us/sample - loss: 0.5205 - accuracy: 0.7415 - val_loss: 0.7033 - val_accuracy: 0.6575\n",
      "Epoch 45/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.5233 - accuracy: 0.7366 - val_loss: 0.6977 - val_accuracy: 0.6322\n",
      "Epoch 46/100\n",
      "2460/2460 [==============================] - 0s 95us/sample - loss: 0.5221 - accuracy: 0.7362 - val_loss: 0.6852 - val_accuracy: 0.6575\n",
      "Epoch 47/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.5220 - accuracy: 0.7346 - val_loss: 0.6881 - val_accuracy: 0.6644\n",
      "Epoch 48/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.5158 - accuracy: 0.7427 - val_loss: 0.6948 - val_accuracy: 0.6345\n",
      "Epoch 49/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.5184 - accuracy: 0.7451 - val_loss: 0.6982 - val_accuracy: 0.6483\n",
      "Epoch 50/100\n",
      "2460/2460 [==============================] - 0s 64us/sample - loss: 0.5159 - accuracy: 0.7419 - val_loss: 0.7062 - val_accuracy: 0.6575\n",
      "Epoch 51/100\n",
      "2460/2460 [==============================] - 0s 63us/sample - loss: 0.5132 - accuracy: 0.7411 - val_loss: 0.7095 - val_accuracy: 0.6368\n",
      "Epoch 52/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.5154 - accuracy: 0.7455 - val_loss: 0.7042 - val_accuracy: 0.6483\n",
      "Epoch 53/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.5116 - accuracy: 0.7484 - val_loss: 0.7192 - val_accuracy: 0.6368\n",
      "Epoch 54/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.5121 - accuracy: 0.7451 - val_loss: 0.7086 - val_accuracy: 0.6345\n",
      "Epoch 55/100\n",
      "2460/2460 [==============================] - 0s 49us/sample - loss: 0.5076 - accuracy: 0.7549 - val_loss: 0.7283 - val_accuracy: 0.6161\n",
      "Epoch 56/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.5077 - accuracy: 0.7382 - val_loss: 0.7400 - val_accuracy: 0.6138\n",
      "Epoch 57/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.5055 - accuracy: 0.7386 - val_loss: 0.7060 - val_accuracy: 0.6529\n",
      "Epoch 58/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.5067 - accuracy: 0.7508 - val_loss: 0.7253 - val_accuracy: 0.6138\n",
      "Epoch 59/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.5055 - accuracy: 0.7565 - val_loss: 0.7259 - val_accuracy: 0.6414\n",
      "Epoch 60/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.5065 - accuracy: 0.7480 - val_loss: 0.7258 - val_accuracy: 0.6161\n",
      "Epoch 61/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.5030 - accuracy: 0.7533 - val_loss: 0.7218 - val_accuracy: 0.6345\n",
      "Epoch 62/100\n",
      "2460/2460 [==============================] - 0s 66us/sample - loss: 0.5002 - accuracy: 0.7492 - val_loss: 0.7590 - val_accuracy: 0.6207\n",
      "Epoch 63/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.5012 - accuracy: 0.7642 - val_loss: 0.7369 - val_accuracy: 0.6253\n",
      "Epoch 64/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.4951 - accuracy: 0.7549 - val_loss: 0.7470 - val_accuracy: 0.6230\n",
      "Epoch 65/100\n",
      "2460/2460 [==============================] - 0s 54us/sample - loss: 0.4961 - accuracy: 0.7553 - val_loss: 0.7282 - val_accuracy: 0.6460\n",
      "Epoch 66/100\n",
      "2460/2460 [==============================] - 0s 50us/sample - loss: 0.4973 - accuracy: 0.7614 - val_loss: 0.7670 - val_accuracy: 0.6092\n",
      "Epoch 67/100\n",
      "2460/2460 [==============================] - 0s 88us/sample - loss: 0.4966 - accuracy: 0.7598 - val_loss: 0.7363 - val_accuracy: 0.6368\n",
      "Epoch 68/100\n",
      "2460/2460 [==============================] - 0s 76us/sample - loss: 0.4950 - accuracy: 0.7545 - val_loss: 0.7416 - val_accuracy: 0.6437\n",
      "Epoch 69/100\n",
      "2460/2460 [==============================] - 0s 72us/sample - loss: 0.4953 - accuracy: 0.7569 - val_loss: 0.7329 - val_accuracy: 0.6368\n",
      "Epoch 70/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4901 - accuracy: 0.7557 - val_loss: 0.7417 - val_accuracy: 0.6299\n",
      "Epoch 71/100\n",
      "2460/2460 [==============================] - 0s 94us/sample - loss: 0.4938 - accuracy: 0.7533 - val_loss: 0.7645 - val_accuracy: 0.6207\n",
      "Epoch 72/100\n",
      "2460/2460 [==============================] - 0s 67us/sample - loss: 0.4963 - accuracy: 0.7508 - val_loss: 0.7794 - val_accuracy: 0.6138\n",
      "Epoch 73/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4953 - accuracy: 0.7533 - val_loss: 0.7356 - val_accuracy: 0.6414\n",
      "Epoch 74/100\n",
      "2460/2460 [==============================] - 0s 38us/sample - loss: 0.4908 - accuracy: 0.7537 - val_loss: 0.7635 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "2460/2460 [==============================] - 0s 69us/sample - loss: 0.4920 - accuracy: 0.7593 - val_loss: 0.7559 - val_accuracy: 0.6552\n",
      "Epoch 76/100\n",
      "2460/2460 [==============================] - 0s 103us/sample - loss: 0.4915 - accuracy: 0.7634 - val_loss: 0.7532 - val_accuracy: 0.6483\n",
      "Epoch 77/100\n",
      "2460/2460 [==============================] - 0s 70us/sample - loss: 0.4884 - accuracy: 0.7553 - val_loss: 0.7680 - val_accuracy: 0.6460\n",
      "Epoch 78/100\n",
      "2460/2460 [==============================] - 0s 82us/sample - loss: 0.4900 - accuracy: 0.7618 - val_loss: 0.7598 - val_accuracy: 0.6414\n",
      "Epoch 79/100\n",
      "2460/2460 [==============================] - 0s 52us/sample - loss: 0.4915 - accuracy: 0.7512 - val_loss: 0.7666 - val_accuracy: 0.6460\n",
      "Epoch 80/100\n",
      "2460/2460 [==============================] - 0s 87us/sample - loss: 0.4907 - accuracy: 0.7557 - val_loss: 0.7819 - val_accuracy: 0.6046\n",
      "Epoch 81/100\n",
      "2460/2460 [==============================] - 0s 99us/sample - loss: 0.4889 - accuracy: 0.7598 - val_loss: 0.7601 - val_accuracy: 0.6483\n",
      "Epoch 82/100\n",
      "2460/2460 [==============================] - 0s 60us/sample - loss: 0.4879 - accuracy: 0.7606 - val_loss: 0.7700 - val_accuracy: 0.6598\n",
      "Epoch 83/100\n",
      "2460/2460 [==============================] - 0s 84us/sample - loss: 0.4868 - accuracy: 0.7630 - val_loss: 0.7749 - val_accuracy: 0.6414\n",
      "Epoch 84/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4858 - accuracy: 0.7606 - val_loss: 0.7723 - val_accuracy: 0.6391\n",
      "Epoch 85/100\n",
      "2460/2460 [==============================] - 0s 90us/sample - loss: 0.4856 - accuracy: 0.7634 - val_loss: 0.7557 - val_accuracy: 0.6184\n",
      "Epoch 86/100\n",
      "2460/2460 [==============================] - 0s 58us/sample - loss: 0.4830 - accuracy: 0.7610 - val_loss: 0.7634 - val_accuracy: 0.6345\n",
      "Epoch 87/100\n",
      "2460/2460 [==============================] - 0s 74us/sample - loss: 0.4875 - accuracy: 0.7699 - val_loss: 0.7862 - val_accuracy: 0.6230\n",
      "Epoch 88/100\n",
      "2460/2460 [==============================] - 0s 71us/sample - loss: 0.4838 - accuracy: 0.7626 - val_loss: 0.8059 - val_accuracy: 0.5931\n",
      "Epoch 89/100\n",
      "2460/2460 [==============================] - 0s 57us/sample - loss: 0.4855 - accuracy: 0.7671 - val_loss: 0.7981 - val_accuracy: 0.6322\n",
      "Epoch 90/100\n",
      "2460/2460 [==============================] - 0s 43us/sample - loss: 0.4825 - accuracy: 0.7650 - val_loss: 0.8019 - val_accuracy: 0.6207\n",
      "Epoch 91/100\n",
      "2460/2460 [==============================] - 0s 79us/sample - loss: 0.4824 - accuracy: 0.7679 - val_loss: 0.7903 - val_accuracy: 0.6368\n",
      "Epoch 92/100\n",
      "2460/2460 [==============================] - 0s 75us/sample - loss: 0.4818 - accuracy: 0.7642 - val_loss: 0.7813 - val_accuracy: 0.6345\n",
      "Epoch 93/100\n",
      "2460/2460 [==============================] - 0s 46us/sample - loss: 0.4821 - accuracy: 0.7646 - val_loss: 0.7750 - val_accuracy: 0.6391\n",
      "Epoch 94/100\n",
      "2460/2460 [==============================] - 0s 81us/sample - loss: 0.4806 - accuracy: 0.7630 - val_loss: 0.8159 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "2460/2460 [==============================] - 0s 59us/sample - loss: 0.4831 - accuracy: 0.7679 - val_loss: 0.8030 - val_accuracy: 0.6230\n",
      "Epoch 96/100\n",
      "2460/2460 [==============================] - 0s 86us/sample - loss: 0.4840 - accuracy: 0.7646 - val_loss: 0.7892 - val_accuracy: 0.6299\n",
      "Epoch 97/100\n",
      "2460/2460 [==============================] - 0s 44us/sample - loss: 0.4826 - accuracy: 0.7638 - val_loss: 0.7881 - val_accuracy: 0.6322\n",
      "Epoch 98/100\n",
      "2460/2460 [==============================] - 0s 91us/sample - loss: 0.4772 - accuracy: 0.7634 - val_loss: 0.8159 - val_accuracy: 0.5816\n",
      "Epoch 99/100\n",
      "2460/2460 [==============================] - 0s 53us/sample - loss: 0.4781 - accuracy: 0.7687 - val_loss: 0.8301 - val_accuracy: 0.5885\n",
      "Epoch 100/100\n",
      "2460/2460 [==============================] - 0s 96us/sample - loss: 0.4809 - accuracy: 0.7659 - val_loss: 0.7894 - val_accuracy: 0.6000\n",
      "2895/2895 [==============================] - 0s 29us/sample - loss: 0.5151 - accuracy: 0.7478\n"
     ]
    }
   ],
   "source": [
    "# List of optimizers and learning rates to be looped through\n",
    "list_optimizers = ['Adam', 'SGD', 'Adadelta', 'RMSprop', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# Number of epochs per model\n",
    "nn_epochs = 100\n",
    "\n",
    "# Validation Split\n",
    "val_split = 0.15\n",
    "\n",
    "# Initializing a DataFrame to save each model results\n",
    "nn_results = pd.DataFrame()\n",
    "\n",
    "# Loop\n",
    "for opt in list_optimizers:\n",
    "    for lr in learning_rates:\n",
    "        \n",
    "        # Building a multilayer neural network using Keras\n",
    "        model = Sequential()\n",
    "        model.add(Dense(68, input_dim = dims, activation = 'relu'))\n",
    "        model.add(Dense(34, activation = 'softmax'))\n",
    "        \n",
    "        # Compile the model to provide the training parameters\n",
    "        model.compile(optimizer = select_optimizer(opt, lr), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        nn_history = model.fit(X_train, y_train, epochs = nn_epochs, verbose = 1, validation_split = val_split)\n",
    "        \n",
    "        # Evaluate the trained model\n",
    "        nn_eval = model.evaluate(X_train, y_train)\n",
    "        \n",
    "        # Preicting using the testing data\n",
    "        y_test_pred = model.predict_classes(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        \n",
    "        # New row for results dataframe containing model hyperparameters and results\n",
    "        new_row = {'epochs': nn_epochs,\n",
    "                   'validation_split': val_split,\n",
    "                   'training accuracy': nn_eval[1],\n",
    "                   'training loss': nn_eval[0],\n",
    "                   'testing accuracy': test_accuracy,\n",
    "                   'optimizer': str(opt),\n",
    "                   'learning_rate': lr\n",
    "                   }\n",
    "        nn_results = nn_results.append(new_row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>testing accuracy</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.564879</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.678177</td>\n",
       "      <td>0.709154</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.633978</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.528608</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.595304</td>\n",
       "      <td>0.892228</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.805166</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.631215</td>\n",
       "      <td>0.748187</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.722055</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.571823</td>\n",
       "      <td>0.547841</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.585864</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.564767</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.692104</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.650552</td>\n",
       "      <td>0.629706</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.575305</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.702245</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.482840</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.636740</td>\n",
       "      <td>0.780656</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.399955</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.627072</td>\n",
       "      <td>0.867357</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.742974</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.205871</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.273575</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.767739</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.586874</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.568651</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.680939</td>\n",
       "      <td>0.705700</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.454682</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.638122</td>\n",
       "      <td>0.787910</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.564768</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.667127</td>\n",
       "      <td>0.705354</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.435087</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.646409</td>\n",
       "      <td>0.803109</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.536596</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.604972</td>\n",
       "      <td>0.912262</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.925323</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.785492</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.823091</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.571823</td>\n",
       "      <td>0.546459</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.312656</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.174033</td>\n",
       "      <td>0.192746</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.894793</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.610497</td>\n",
       "      <td>0.615544</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.564692</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.669890</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.367163</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.854922</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.475125</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.861831</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.597547</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.683702</td>\n",
       "      <td>0.681174</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.522963</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.664365</td>\n",
       "      <td>0.735060</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.599448</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.539191</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.961901</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.633978</td>\n",
       "      <td>0.763731</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.564750</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.676796</td>\n",
       "      <td>0.706045</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.391336</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.624309</td>\n",
       "      <td>0.841451</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.459566</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.589779</td>\n",
       "      <td>0.911572</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.918190</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.610497</td>\n",
       "      <td>0.762349</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.688998</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.571823</td>\n",
       "      <td>0.546459</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>Ftrl</td>\n",
       "      <td>0.569061</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.161863</td>\n",
       "      <td>Ftrl</td>\n",
       "      <td>0.571823</td>\n",
       "      <td>0.546459</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.582185</td>\n",
       "      <td>Ftrl</td>\n",
       "      <td>0.675414</td>\n",
       "      <td>0.690501</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.501641</td>\n",
       "      <td>Ftrl</td>\n",
       "      <td>0.646409</td>\n",
       "      <td>0.758549</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.515092</td>\n",
       "      <td>Ftrl</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.747841</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  learning_rate      loss optimizer  testing accuracy  training accuracy  validation_split\n",
       "0    100.0         0.0001  0.564879      Adam          0.678177           0.709154              0.15\n",
       "1    100.0         0.0010  0.386847      Adam          0.633978           0.837651              0.15\n",
       "2    100.0         0.0100  0.528608      Adam          0.595304           0.892228              0.15\n",
       "3    100.0         0.1000  0.805166      Adam          0.631215           0.748187              0.15\n",
       "4    100.0         1.0000  0.722055      Adam          0.571823           0.547841              0.15\n",
       "5    100.0         0.0001  2.585864       SGD          0.558011           0.564767              0.15\n",
       "6    100.0         0.0010  0.692104       SGD          0.650552           0.629706              0.15\n",
       "7    100.0         0.0100  0.575305       SGD          0.668508           0.702245              0.15\n",
       "8    100.0         0.1000  0.482840       SGD          0.636740           0.780656              0.15\n",
       "9    100.0         1.0000  0.399955       SGD          0.627072           0.867357              0.15\n",
       "10   100.0         0.0001  3.742974  Adadelta          0.001381           0.005872              0.15\n",
       "11   100.0         0.0010  3.205871  Adadelta          0.301105           0.273575              0.15\n",
       "12   100.0         0.0100  0.767739  Adadelta          0.602210           0.586874              0.15\n",
       "13   100.0         0.1000  0.568651  Adadelta          0.680939           0.705700              0.15\n",
       "14   100.0         1.0000  0.454682  Adadelta          0.638122           0.787910              0.15\n",
       "15   100.0         0.0001  0.564768   RMSprop          0.667127           0.705354              0.15\n",
       "16   100.0         0.0010  0.435087   RMSprop          0.646409           0.803109              0.15\n",
       "17   100.0         0.0100  0.536596   RMSprop          0.604972           0.912262              0.15\n",
       "18   100.0         0.1000  0.925323   RMSprop          0.575967           0.785492              0.15\n",
       "19   100.0         1.0000  0.823091   RMSprop          0.571823           0.546459              0.15\n",
       "20   100.0         0.0001  3.312656   Adagrad          0.174033           0.192746              0.15\n",
       "21   100.0         0.0010  0.894793   Adagrad          0.610497           0.615544              0.15\n",
       "22   100.0         0.0100  0.564692   Adagrad          0.669890           0.709499              0.15\n",
       "23   100.0         0.1000  0.367163   Adagrad          0.629834           0.854922              0.15\n",
       "24   100.0         1.0000  0.475125   Adagrad          0.602210           0.861831              0.15\n",
       "25   100.0         0.0001  0.597547    Adamax          0.683702           0.681174              0.15\n",
       "26   100.0         0.0010  0.522963    Adamax          0.664365           0.735060              0.15\n",
       "27   100.0         0.0100  0.332341    Adamax          0.599448           0.895682              0.15\n",
       "28   100.0         0.1000  0.539191    Adamax          0.602210           0.917789              0.15\n",
       "29   100.0         1.0000  0.961901    Adamax          0.633978           0.763731              0.15\n",
       "30   100.0         0.0001  0.564750     Nadam          0.676796           0.706045              0.15\n",
       "31   100.0         0.0010  0.391336     Nadam          0.624309           0.841451              0.15\n",
       "32   100.0         0.0100  0.459566     Nadam          0.589779           0.911572              0.15\n",
       "33   100.0         0.1000  0.918190     Nadam          0.610497           0.762349              0.15\n",
       "34   100.0         1.0000  0.688998     Nadam          0.571823           0.546459              0.15\n",
       "35   100.0         0.0001  3.494798      Ftrl          0.569061           0.549568              0.15\n",
       "36   100.0         0.0010  1.161863      Ftrl          0.571823           0.546459              0.15\n",
       "37   100.0         0.0100  0.582185      Ftrl          0.675414           0.690501              0.15\n",
       "38   100.0         0.1000  0.501641      Ftrl          0.646409           0.758549              0.15\n",
       "39   100.0         1.0000  0.515092      Ftrl          0.620166           0.747841              0.15"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(nn_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = select_optimizer('SGD', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fce36ec6dd0>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model to provide the training parameters\n",
    "model.compile(optimizer = a, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c599e81ace37994bed7b9bbd7d108e9889c61d697bcdc0abde22622452708644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
